# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/en_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,sound --valid_shape_file exp/asr_stats_raw_en_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir exp/asr_train_asr_conformer_raw_en_char_sp --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_sp/wav.scp,speech,sound --train_shape_file exp/asr_stats_raw_en_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_char_sp/valid/text_shape.char --ngpu 4 --multiprocessing_distributed True 
# Started at Sat Jan 27 23:17:34 KST 2024
#
/home/bootcamp/dd/espnet/tools/anaconda/envs/espnet2/bin/python3 /home/bootcamp/dd/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/en_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,sound --valid_shape_file exp/asr_stats_raw_en_char_sp/valid/speech_shape --resume true --ignore_init_mismatch false --fold_length 80000 --output_dir exp/asr_train_asr_conformer_raw_en_char_sp --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_en_char_sp/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train_sp/wav.scp,speech,sound --train_shape_file exp/asr_stats_raw_en_char_sp/train/speech_shape --fold_length 150 --train_data_path_and_name_and_type dump/raw/train_sp/text,text,text --train_shape_file exp/asr_stats_raw_en_char_sp/train/text_shape.char --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_en_char_sp/valid/text_shape.char --ngpu 4 --multiprocessing_distributed True
[seoultech:0/4] 2024-01-27 23:17:44,811 (distributed_c10d:442) INFO: Added key: store_based_barrier_key:1 to store for rank: 0
[seoultech:0/4] 2024-01-27 23:17:44,811 (distributed_c10d:476) INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[seoultech:0/4] 2024-01-27 23:17:44,857 (asr:523) INFO: Vocabulary size: 2512
[seoultech:0/4] 2024-01-27 23:17:46,890 (abs_task:1260) INFO: pytorch.version=2.0.1, cuda.available=True, cudnn.version=8500, cudnn.benchmark=False, cudnn.deterministic=True
[seoultech:0/4] 2024-01-27 23:17:46,895 (abs_task:1261) INFO: Model structure:
ESPnetASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=160, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 27], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxisVariableMaxWidth(mask_width_ratio_range=[0.0, 0.05], num_mask=10, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp/asr_stats_raw_en_char_sp/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=9728, out_features=512, bias=True)
        (1): RelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(2512, 512)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=512, out_features=2512, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=2512, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Total Number of model parameters: 112.32 M
    Number of trainable parameters: 112.32 M (100.0%)
    Size: 449.28 MB
    Type: torch.float32
[seoultech:0/4] 2024-01-27 23:17:46,896 (abs_task:1264) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0025
    lr: 6.25e-08
    maximize: False
    weight_decay: 1e-06
)
[seoultech:0/4] 2024-01-27 23:17:46,896 (abs_task:1265) INFO: Scheduler: WarmupLR(warmup_steps=40000)
[seoultech:0/4] 2024-01-27 23:17:46,896 (abs_task:1274) INFO: Saving the configuration in exp/asr_train_asr_conformer_raw_en_char_sp/config.yaml
[seoultech:0/4] 2024-01-27 23:17:49,914 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/4] 2024-01-27 23:18:01,927 (abs_task:1650) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train_sp/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train_sp/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f8ac0972800>)
[seoultech:0/4] 2024-01-27 23:18:01,927 (abs_task:1651) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=12033, batch_bins=35000000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/4] 2024-01-27 23:18:01,929 (abs_task:1652) INFO: [train] mini-batch sizes summary: N-batch=12033, mean=124.5, min=14, max=1075
[seoultech:0/4] 2024-01-27 23:18:02,335 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/4] 2024-01-27 23:18:03,498 (abs_task:1650) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f8ac1aaee90>)
[seoultech:0/4] 2024-01-27 23:18:03,498 (abs_task:1651) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=1534, batch_bins=35000000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/4] 2024-01-27 23:18:03,499 (abs_task:1652) INFO: [valid] mini-batch sizes summary: N-batch=1534, mean=124.2, min=17, max=925
[seoultech:0/4] 2024-01-27 23:18:03,816 (asr:494) INFO: Optional Data Names: ('text_spk2', 'text_spk3', 'text_spk4', 'prompt')
[seoultech:0/4] 2024-01-27 23:18:04,133 (abs_task:1650) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7f8adef19450>)
[seoultech:0/4] 2024-01-27 23:18:04,133 (abs_task:1651) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=190471, batch_size=1, key_file=exp/asr_stats_raw_en_char_sp/valid/speech_shape, 
[seoultech:0/4] 2024-01-27 23:18:04,133 (abs_task:1652) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
seoultech:215312:215312 [0] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:215312:215312 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:215312:215312 [0] NCCL INFO cudaDriverVersion 11070
NCCL version 2.14.3+cuda11.7
[seoultech:0/4] 2024-01-27 23:18:05,389 (trainer:298) INFO: 1/50epoch started
seoultech:215314:215314 [2] NCCL INFO cudaDriverVersion 11070
seoultech:215314:215314 [2] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:215314:215314 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:215314:215350 [2] NCCL INFO NET/IB : No device found.
seoultech:215314:215350 [2] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:215314:215350 [2] NCCL INFO Using network Socket
seoultech:215314:215350 [2] NCCL INFO Setting affinity for GPU 2 to fff0,00fff000
seoultech:215314:215350 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
seoultech:215314:215350 [2] NCCL INFO Channel 00 : 2[b1000] -> 3[ca000] via SHM/direct/direct
seoultech:215314:215350 [2] NCCL INFO Channel 01 : 2[b1000] -> 3[ca000] via SHM/direct/direct
seoultech:215314:215350 [2] NCCL INFO Connected all rings
seoultech:215314:215350 [2] NCCL INFO Channel 00 : 2[b1000] -> 1[4b000] via SHM/direct/direct
seoultech:215314:215350 [2] NCCL INFO Channel 01 : 2[b1000] -> 1[4b000] via SHM/direct/direct
seoultech:215314:215350 [2] NCCL INFO Connected all trees
seoultech:215314:215350 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:215314:215350 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:215314:215350 [2] NCCL INFO comm 0x45d12920 rank 2 nranks 4 cudaDev 2 busId b1000 - Init COMPLETE
seoultech:215312:215351 [0] NCCL INFO NET/IB : No device found.
seoultech:215312:215351 [0] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:215312:215351 [0] NCCL INFO Using network Socket
seoultech:215312:215351 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
seoultech:215312:215351 [0] NCCL INFO Channel 00/02 :    0   1   2   3
seoultech:215312:215351 [0] NCCL INFO Channel 01/02 :    0   1   2   3
seoultech:215312:215351 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
seoultech:215312:215351 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via SHM/direct/direct
seoultech:215312:215351 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via SHM/direct/direct
seoultech:215312:215351 [0] NCCL INFO Connected all rings
seoultech:215312:215351 [0] NCCL INFO Connected all trees
seoultech:215312:215351 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:215312:215351 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:215312:215351 [0] NCCL INFO comm 0xb8c7710 rank 0 nranks 4 cudaDev 0 busId 31000 - Init COMPLETE
seoultech:215313:215313 [1] NCCL INFO cudaDriverVersion 11070
seoultech:215313:215313 [1] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:215313:215313 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:215313:215353 [1] NCCL INFO NET/IB : No device found.
seoultech:215313:215353 [1] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:215313:215353 [1] NCCL INFO Using network Socket
seoultech:215313:215353 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
seoultech:215313:215353 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
seoultech:215313:215353 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[b1000] via SHM/direct/direct
seoultech:215313:215353 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[b1000] via SHM/direct/direct
seoultech:215313:215353 [1] NCCL INFO Connected all rings
seoultech:215313:215353 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via SHM/direct/direct
seoultech:215313:215353 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via SHM/direct/direct
seoultech:215313:215353 [1] NCCL INFO Connected all trees
seoultech:215313:215353 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:215313:215353 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:215313:215353 [1] NCCL INFO comm 0xa863be0 rank 1 nranks 4 cudaDev 1 busId 4b000 - Init COMPLETE
seoultech:215315:215315 [3] NCCL INFO cudaDriverVersion 11070
seoultech:215315:215315 [3] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:215315:215315 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:215315:215352 [3] NCCL INFO NET/IB : No device found.
seoultech:215315:215352 [3] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:215315:215352 [3] NCCL INFO Using network Socket
seoultech:215315:215352 [3] NCCL INFO Setting affinity for GPU 3 to fff0,00fff000
seoultech:215315:215352 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
seoultech:215315:215352 [3] NCCL INFO Channel 00 : 3[ca000] -> 0[31000] via SHM/direct/direct
seoultech:215315:215352 [3] NCCL INFO Channel 01 : 3[ca000] -> 0[31000] via SHM/direct/direct
seoultech:215315:215352 [3] NCCL INFO Connected all rings
seoultech:215315:215352 [3] NCCL INFO Channel 00 : 3[ca000] -> 2[b1000] via SHM/direct/direct
seoultech:215315:215352 [3] NCCL INFO Channel 01 : 3[ca000] -> 2[b1000] via SHM/direct/direct
seoultech:215315:215352 [3] NCCL INFO Connected all trees
seoultech:215315:215352 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
seoultech:215315:215352 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:215315:215352 [3] NCCL INFO comm 0xa5e0a60 rank 3 nranks 4 cudaDev 3 busId ca000 - Init COMPLETE
[seoultech:0/4] 2024-01-27 23:18:47,611 (distributed:1140) INFO: Reducer buckets have been rebuilt in this iteration.
[seoultech:0/4] 2024-01-27 23:23:44,779 (trainer:753) INFO: 1epoch:train:1-601batch: iter_time=0.001, forward_time=0.178, loss_ctc=515.216, loss_att=299.265, acc=0.054, loss=364.050, backward_time=0.183, grad_norm=761.721, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.047, optim0_lr0=4.781e-06, train_time=2.258
[seoultech:0/4] 2024-01-27 23:28:39,088 (trainer:753) INFO: 1epoch:train:602-1202batch: iter_time=2.858e-04, forward_time=0.174, loss_ctc=243.735, loss_att=224.500, acc=0.212, loss=230.270, backward_time=0.171, grad_norm=65.178, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.041, optim0_lr0=1.416e-05, train_time=1.959
[seoultech:0/4] 2024-01-27 23:33:35,981 (trainer:753) INFO: 1epoch:train:1203-1803batch: iter_time=2.762e-04, forward_time=0.175, loss_ctc=231.959, loss_att=188.364, acc=0.282, loss=201.442, backward_time=0.199, grad_norm=31.589, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.043, optim0_lr0=2.353e-05, train_time=1.976
[seoultech:0/4] 2024-01-27 23:38:28,892 (trainer:753) INFO: 1epoch:train:1804-2404batch: iter_time=2.546e-04, forward_time=0.158, loss_ctc=209.120, loss_att=157.753, acc=0.332, loss=173.163, backward_time=0.187, grad_norm=29.635, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.039, optim0_lr0=3.294e-05, train_time=1.948
[seoultech:0/4] 2024-01-27 23:43:27,400 (trainer:753) INFO: 1epoch:train:2405-3005batch: iter_time=2.709e-04, forward_time=0.179, loss_ctc=204.026, loss_att=148.039, acc=0.352, loss=164.835, backward_time=0.208, grad_norm=25.463, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.044, optim0_lr0=4.234e-05, train_time=1.986
[seoultech:0/4] 2024-01-27 23:48:24,129 (trainer:753) INFO: 1epoch:train:3006-3606batch: iter_time=2.827e-04, forward_time=0.175, loss_ctc=201.791, loss_att=142.800, acc=0.361, loss=160.497, backward_time=0.180, grad_norm=22.762, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.044, optim0_lr0=5.172e-05, train_time=1.974
[seoultech:0/4] 2024-01-27 23:53:20,202 (trainer:753) INFO: 1epoch:train:3607-4207batch: iter_time=2.762e-04, forward_time=0.164, loss_ctc=188.033, loss_att=130.809, acc=0.372, loss=147.976, backward_time=0.197, grad_norm=23.482, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.042, optim0_lr0=6.109e-05, train_time=1.970
[seoultech:0/4] 2024-01-27 23:58:15,257 (trainer:753) INFO: 1epoch:train:4208-4808batch: iter_time=2.671e-04, forward_time=0.156, loss_ctc=186.942, loss_att=128.514, acc=0.380, loss=146.043, backward_time=0.205, grad_norm=20.523, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.041, optim0_lr0=7.050e-05, train_time=1.962
[seoultech:0/4] 2024-01-28 00:03:13,565 (trainer:753) INFO: 1epoch:train:4809-5409batch: iter_time=2.622e-04, forward_time=0.155, loss_ctc=190.605, loss_att=129.931, acc=0.382, loss=148.133, backward_time=0.168, grad_norm=24.518, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.038, optim0_lr0=7.991e-05, train_time=1.984
[seoultech:0/4] 2024-01-28 00:08:08,868 (trainer:753) INFO: 1epoch:train:5410-6010batch: iter_time=2.639e-04, forward_time=0.163, loss_ctc=194.172, loss_att=132.106, acc=0.389, loss=150.726, backward_time=0.159, grad_norm=24.253, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.037, optim0_lr0=8.928e-05, train_time=1.965
[seoultech:0/4] 2024-01-28 00:12:58,503 (trainer:753) INFO: 1epoch:train:6011-6611batch: iter_time=2.825e-04, forward_time=0.175, loss_ctc=184.648, loss_att=126.639, acc=0.394, loss=144.042, backward_time=0.174, grad_norm=26.726, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.043, optim0_lr0=9.866e-05, train_time=1.926
[seoultech:0/4] 2024-01-28 00:17:44,507 (trainer:753) INFO: 1epoch:train:6612-7212batch: iter_time=2.673e-04, forward_time=0.159, loss_ctc=187.712, loss_att=131.827, acc=0.400, loss=148.593, backward_time=0.179, grad_norm=28.303, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.043, optim0_lr0=1.081e-04, train_time=1.903
[seoultech:0/4] 2024-01-28 00:22:28,844 (trainer:753) INFO: 1epoch:train:7213-7813batch: iter_time=2.855e-04, forward_time=0.173, loss_ctc=166.133, loss_att=120.969, acc=0.411, loss=134.518, backward_time=0.154, grad_norm=29.298, clip=100.000, loss_scale=6.554e+04, optim_step_time=0.044, optim0_lr0=1.175e-04, train_time=1.892
[seoultech:0/4] 2024-01-28 00:27:17,942 (trainer:753) INFO: 1epoch:train:7814-8414batch: iter_time=2.753e-04, forward_time=0.169, loss_ctc=157.909, loss_att=121.377, acc=0.418, loss=132.337, backward_time=0.195, grad_norm=33.631, clip=100.000, loss_scale=1.105e+05, optim_step_time=0.045, optim0_lr0=1.268e-04, train_time=1.923
[seoultech:0/4] 2024-01-28 00:32:07,961 (trainer:753) INFO: 1epoch:train:8415-9015batch: iter_time=2.676e-04, forward_time=0.165, loss_ctc=144.641, loss_att=117.892, acc=0.428, loss=125.917, backward_time=0.201, grad_norm=36.568, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.040, optim0_lr0=1.362e-04, train_time=1.930
[seoultech:0/4] 2024-01-28 00:36:50,376 (trainer:753) INFO: 1epoch:train:9016-9616batch: iter_time=2.745e-04, forward_time=0.169, loss_ctc=135.209, loss_att=115.456, acc=0.434, loss=121.382, backward_time=0.165, grad_norm=34.526, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.042, optim0_lr0=1.456e-04, train_time=1.878
[seoultech:0/4] 2024-01-28 00:41:36,646 (trainer:753) INFO: 1epoch:train:9617-10217batch: iter_time=2.688e-04, forward_time=0.171, loss_ctc=136.104, loss_att=121.905, acc=0.440, loss=126.165, backward_time=0.163, grad_norm=40.448, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.043, optim0_lr0=1.550e-04, train_time=1.905
[seoultech:0/4] 2024-01-28 00:46:31,243 (trainer:753) INFO: 1epoch:train:10218-10818batch: iter_time=2.743e-04, forward_time=0.165, loss_ctc=121.748, loss_att=112.663, acc=0.452, loss=115.389, backward_time=0.200, grad_norm=39.201, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.045, optim0_lr0=1.644e-04, train_time=1.960
[seoultech:0/4] 2024-01-28 00:51:17,324 (trainer:753) INFO: 1epoch:train:10819-11419batch: iter_time=2.773e-04, forward_time=0.152, loss_ctc=112.689, loss_att=106.643, acc=0.463, loss=108.457, backward_time=0.205, grad_norm=38.215, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.041, optim0_lr0=1.738e-04, train_time=1.904
[seoultech:0/4] 2024-01-28 00:56:07,333 (trainer:753) INFO: 1epoch:train:11420-12020batch: iter_time=2.769e-04, forward_time=0.174, loss_ctc=111.731, loss_att=107.611, acc=0.477, loss=108.847, backward_time=0.189, grad_norm=40.394, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.043, optim0_lr0=1.832e-04, train_time=1.929
[seoultech:0/4] 2024-01-28 01:08:22,013 (trainer:352) INFO: 1epoch results: [train] iter_time=3.304e-04, forward_time=0.167, loss_ctc=191.168, loss_att=143.142, acc=0.372, loss=157.550, backward_time=0.184, grad_norm=68.733, clip=100.000, loss_scale=8.750e+04, optim_step_time=0.042, optim0_lr0=9.409e-05, train_time=1.957, time=1 hour, 38 minutes and 10.63 seconds, total_count=12033, gpu_max_cached_mem_GB=21.611, [valid] loss_ctc=75.618, cer_ctc=0.442, loss_att=104.349, acc=0.502, cer=0.641, wer=0.966, loss=95.729, time=10 minutes and 22.5 seconds, total_count=1534, gpu_max_cached_mem_GB=38.732, [att_plot] time=1 minute and 43.47 seconds, total_count=0, gpu_max_cached_mem_GB=38.732
[seoultech:0/4] 2024-01-28 01:08:27,378 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 01:08:27,378 (trainer:286) INFO: 2/50epoch started. Estimated time to finish: 3 days, 18 hours and 7 minutes
[seoultech:0/4] 2024-01-28 01:13:29,138 (trainer:753) INFO: 2epoch:train:1-601batch: iter_time=0.001, forward_time=0.140, loss_ctc=109.164, loss_att=105.446, acc=0.493, loss=106.562, backward_time=0.158, grad_norm=43.385, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.043, optim0_lr0=1.928e-04, train_time=2.008
[seoultech:0/4] 2024-01-28 01:18:04,468 (trainer:753) INFO: 2epoch:train:602-1202batch: iter_time=2.770e-04, forward_time=0.157, loss_ctc=105.371, loss_att=100.516, acc=0.515, loss=101.972, backward_time=0.189, grad_norm=46.003, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.042, optim0_lr0=2.022e-04, train_time=1.831
[seoultech:0/4] 2024-01-28 01:22:46,188 (trainer:753) INFO: 2epoch:train:1203-1803batch: iter_time=2.753e-04, forward_time=0.160, loss_ctc=102.159, loss_att=94.963, acc=0.536, loss=97.122, backward_time=0.211, grad_norm=54.182, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.046, optim0_lr0=2.115e-04, train_time=1.876
[seoultech:0/4] 2024-01-28 01:27:23,759 (trainer:753) INFO: 2epoch:train:1804-2404batch: iter_time=2.782e-04, forward_time=0.138, loss_ctc=102.794, loss_att=92.365, acc=0.561, loss=95.494, backward_time=0.192, grad_norm=62.691, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.038, optim0_lr0=2.209e-04, train_time=1.846
[seoultech:0/4] 2024-01-28 01:32:01,931 (trainer:753) INFO: 2epoch:train:2405-3005batch: iter_time=2.881e-04, forward_time=0.157, loss_ctc=99.051, loss_att=84.518, acc=0.587, loss=88.878, backward_time=0.208, grad_norm=68.157, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.045, optim0_lr0=2.303e-04, train_time=1.851
[seoultech:0/4] 2024-01-28 01:36:38,164 (trainer:753) INFO: 2epoch:train:3006-3606batch: iter_time=2.629e-04, forward_time=0.135, loss_ctc=98.545, loss_att=80.403, acc=0.607, loss=85.846, backward_time=0.203, grad_norm=73.365, clip=100.000, loss_scale=1.311e+05, optim_step_time=0.037, optim0_lr0=2.397e-04, train_time=1.838
[seoultech:0/4] 2024-01-28 01:41:11,359 (trainer:753) INFO: 2epoch:train:3607-4207batch: iter_time=2.734e-04, forward_time=0.136, loss_ctc=98.665, loss_att=76.448, acc=0.630, loss=83.113, backward_time=0.186, grad_norm=77.760, clip=100.000, loss_scale=1.826e+05, optim_step_time=0.037, optim0_lr0=2.491e-04, train_time=1.817
[seoultech:0/4] 2024-01-28 01:45:48,273 (trainer:753) INFO: 2epoch:train:4208-4808batch: iter_time=2.677e-04, forward_time=0.147, loss_ctc=93.408, loss_att=69.292, acc=0.648, loss=76.527, backward_time=0.161, grad_norm=67.298, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.037, optim0_lr0=2.585e-04, train_time=1.842
[seoultech:0/4] 2024-01-28 01:50:25,584 (trainer:753) INFO: 2epoch:train:4809-5409batch: iter_time=2.794e-04, forward_time=0.163, loss_ctc=91.938, loss_att=66.183, acc=0.664, loss=73.910, backward_time=0.171, grad_norm=70.940, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.043, optim0_lr0=2.679e-04, train_time=1.845
[seoultech:0/4] 2024-01-28 01:55:08,871 (trainer:753) INFO: 2epoch:train:5410-6010batch: iter_time=2.739e-04, forward_time=0.165, loss_ctc=89.539, loss_att=62.087, acc=0.678, loss=70.323, backward_time=0.205, grad_norm=60.773, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.044, optim0_lr0=2.773e-04, train_time=1.885
[seoultech:0/4] 2024-01-28 01:59:48,230 (trainer:753) INFO: 2epoch:train:6011-6611batch: iter_time=2.719e-04, forward_time=0.160, loss_ctc=90.296, loss_att=61.065, acc=0.690, loss=69.834, backward_time=0.196, grad_norm=59.774, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.043, optim0_lr0=2.867e-04, train_time=1.859
[seoultech:0/4] 2024-01-28 02:04:26,682 (trainer:753) INFO: 2epoch:train:6612-7212batch: iter_time=2.900e-04, forward_time=0.151, loss_ctc=92.917, loss_att=61.543, acc=0.700, loss=70.955, backward_time=0.161, grad_norm=57.022, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.041, optim0_lr0=2.961e-04, train_time=1.852
[seoultech:0/4] 2024-01-28 02:09:09,487 (trainer:753) INFO: 2epoch:train:7213-7813batch: iter_time=2.785e-04, forward_time=0.154, loss_ctc=82.903, loss_att=54.106, acc=0.708, loss=62.745, backward_time=0.180, grad_norm=56.821, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.041, optim0_lr0=3.055e-04, train_time=1.882
[seoultech:0/4] 2024-01-28 02:13:53,568 (trainer:753) INFO: 2epoch:train:7814-8414batch: iter_time=2.706e-04, forward_time=0.159, loss_ctc=85.479, loss_att=54.826, acc=0.716, loss=64.022, backward_time=0.184, grad_norm=56.027, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.043, optim0_lr0=3.148e-04, train_time=1.890
[seoultech:0/4] 2024-01-28 02:18:38,381 (trainer:753) INFO: 2epoch:train:8415-9015batch: iter_time=2.779e-04, forward_time=0.162, loss_ctc=81.450, loss_att=51.890, acc=0.723, loss=60.758, backward_time=0.155, grad_norm=51.603, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.041, optim0_lr0=3.242e-04, train_time=1.895
[seoultech:0/4] 2024-01-28 02:23:27,882 (trainer:753) INFO: 2epoch:train:9016-9616batch: iter_time=2.697e-04, forward_time=0.142, loss_ctc=82.132, loss_att=51.501, acc=0.732, loss=60.690, backward_time=0.207, grad_norm=48.515, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.041, optim0_lr0=3.336e-04, train_time=1.926
[seoultech:0/4] 2024-01-28 02:28:17,351 (trainer:753) INFO: 2epoch:train:9617-10217batch: iter_time=2.678e-04, forward_time=0.155, loss_ctc=77.708, loss_att=48.280, acc=0.735, loss=57.109, backward_time=0.168, grad_norm=48.300, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.041, optim0_lr0=3.430e-04, train_time=1.926
[seoultech:0/4] 2024-01-28 02:33:02,727 (trainer:753) INFO: 2epoch:train:10218-10818batch: iter_time=2.666e-04, forward_time=0.153, loss_ctc=82.514, loss_att=50.848, acc=0.742, loss=60.347, backward_time=0.163, grad_norm=46.570, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.039, optim0_lr0=3.524e-04, train_time=1.899
[seoultech:0/4] 2024-01-28 02:37:50,324 (trainer:753) INFO: 2epoch:train:10819-11419batch: iter_time=2.699e-04, forward_time=0.159, loss_ctc=77.522, loss_att=46.995, acc=0.748, loss=56.153, backward_time=0.182, grad_norm=43.172, clip=100.000, loss_scale=2.621e+05, optim_step_time=0.041, optim0_lr0=3.618e-04, train_time=1.914
[seoultech:0/4] 2024-01-28 02:42:42,070 (trainer:753) INFO: 2epoch:train:11420-12020batch: iter_time=2.700e-04, forward_time=0.160, loss_ctc=78.261, loss_att=47.335, acc=0.752, loss=56.613, backward_time=0.166, grad_norm=45.493, clip=100.000, loss_scale=2.847e+05, optim_step_time=0.041, optim0_lr0=3.712e-04, train_time=1.940
[seoultech:0/4] 2024-01-28 02:54:37,584 (trainer:352) INFO: 2epoch results: [train] iter_time=3.199e-04, forward_time=0.153, loss_ctc=91.069, loss_att=68.050, acc=0.658, loss=74.955, backward_time=0.182, grad_norm=56.879, clip=100.000, loss_scale=2.203e+05, optim_step_time=0.041, optim0_lr0=2.821e-04, train_time=1.881, time=1 hour, 34 minutes and 22.8 seconds, total_count=24066, gpu_max_cached_mem_GB=38.734, [valid] loss_ctc=39.568, cer_ctc=0.244, loss_att=24.146, acc=0.862, cer=0.180, wer=0.418, loss=28.773, time=10 minutes and 26.8 seconds, total_count=3068, gpu_max_cached_mem_GB=38.734, [att_plot] time=1 minute and 20.6 seconds, total_count=0, gpu_max_cached_mem_GB=38.734
[seoultech:0/4] 2024-01-28 02:54:44,491 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 02:54:44,492 (trainer:286) INFO: 3/50epoch started. Estimated time to finish: 3 days, 14 hours and 39 minutes
[seoultech:0/4] 2024-01-28 03:00:17,696 (trainer:753) INFO: 3epoch:train:1-601batch: iter_time=0.001, forward_time=0.166, loss_ctc=72.138, loss_att=43.145, acc=0.756, loss=51.843, backward_time=0.200, grad_norm=43.390, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.044, optim0_lr0=3.808e-04, train_time=2.217
[seoultech:0/4] 2024-01-28 03:05:01,079 (trainer:753) INFO: 3epoch:train:602-1202batch: iter_time=2.740e-04, forward_time=0.155, loss_ctc=74.488, loss_att=44.412, acc=0.760, loss=53.435, backward_time=0.206, grad_norm=43.712, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.045, optim0_lr0=3.902e-04, train_time=1.886
[seoultech:0/4] 2024-01-28 03:09:40,207 (trainer:753) INFO: 3epoch:train:1203-1803batch: iter_time=2.836e-04, forward_time=0.156, loss_ctc=73.768, loss_att=43.472, acc=0.765, loss=52.560, backward_time=0.192, grad_norm=40.578, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.046, optim0_lr0=3.995e-04, train_time=1.857
[seoultech:0/4] 2024-01-28 03:14:13,927 (trainer:753) INFO: 3epoch:train:1804-2404batch: iter_time=2.761e-04, forward_time=0.153, loss_ctc=77.209, loss_att=45.437, acc=0.768, loss=54.969, backward_time=0.156, grad_norm=41.173, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.042, optim0_lr0=4.089e-04, train_time=1.820
[seoultech:0/4] 2024-01-28 03:18:48,530 (trainer:753) INFO: 3epoch:train:2405-3005batch: iter_time=2.806e-04, forward_time=0.151, loss_ctc=72.897, loss_att=42.571, acc=0.771, loss=51.669, backward_time=0.168, grad_norm=38.268, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.042, optim0_lr0=4.183e-04, train_time=1.827
[seoultech:0/4] 2024-01-28 03:23:31,734 (trainer:753) INFO: 3epoch:train:3006-3606batch: iter_time=3.000e-04, forward_time=0.152, loss_ctc=73.261, loss_att=42.678, acc=0.773, loss=51.853, backward_time=0.202, grad_norm=39.572, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.043, optim0_lr0=4.277e-04, train_time=1.884
[seoultech:0/4] 2024-01-28 03:28:03,349 (trainer:753) INFO: 3epoch:train:3607-4207batch: iter_time=2.813e-04, forward_time=0.155, loss_ctc=71.265, loss_att=41.115, acc=0.778, loss=50.160, backward_time=0.187, grad_norm=36.210, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.044, optim0_lr0=4.371e-04, train_time=1.808
[seoultech:0/4] 2024-01-28 03:32:49,468 (trainer:753) INFO: 3epoch:train:4208-4808batch: iter_time=2.779e-04, forward_time=0.167, loss_ctc=70.075, loss_att=40.263, acc=0.780, loss=49.206, backward_time=0.208, grad_norm=35.116, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.044, optim0_lr0=4.465e-04, train_time=1.902
[seoultech:0/4] 2024-01-28 03:37:30,968 (trainer:753) INFO: 3epoch:train:4809-5409batch: iter_time=2.796e-04, forward_time=0.162, loss_ctc=67.831, loss_att=38.767, acc=0.784, loss=47.486, backward_time=0.164, grad_norm=37.405, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.045, optim0_lr0=4.559e-04, train_time=1.873
[seoultech:0/4] 2024-01-28 03:42:17,310 (trainer:753) INFO: 3epoch:train:5410-6010batch: iter_time=2.698e-04, forward_time=0.160, loss_ctc=68.368, loss_att=38.778, acc=0.787, loss=47.655, backward_time=0.177, grad_norm=33.379, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.042, optim0_lr0=4.653e-04, train_time=1.906
[seoultech:0/4] 2024-01-28 03:47:06,590 (trainer:753) INFO: 3epoch:train:6011-6611batch: iter_time=2.749e-04, forward_time=0.167, loss_ctc=69.079, loss_att=39.131, acc=0.789, loss=48.115, backward_time=0.210, grad_norm=34.394, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.046, optim0_lr0=4.747e-04, train_time=1.923
[seoultech:0/4] 2024-01-28 03:51:54,250 (trainer:753) INFO: 3epoch:train:6612-7212batch: iter_time=2.732e-04, forward_time=0.155, loss_ctc=68.770, loss_att=38.679, acc=0.792, loss=47.706, backward_time=0.199, grad_norm=32.572, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.047, optim0_lr0=4.841e-04, train_time=1.914
[seoultech:0/4] 2024-01-28 03:56:43,771 (trainer:753) INFO: 3epoch:train:7213-7813batch: iter_time=2.702e-04, forward_time=0.153, loss_ctc=66.766, loss_att=37.232, acc=0.793, loss=46.093, backward_time=0.218, grad_norm=30.760, clip=100.000, loss_scale=5.243e+05, optim_step_time=0.041, optim0_lr0=4.935e-04, train_time=1.926
[seoultech:0/4] 2024-01-28 04:01:26,075 (trainer:753) INFO: 3epoch:train:7814-8414batch: iter_time=2.580e-04, forward_time=0.149, loss_ctc=66.802, loss_att=37.196, acc=0.796, loss=46.078, backward_time=0.188, grad_norm=32.874, clip=100.000, loss_scale=9.402e+05, optim_step_time=0.042, optim0_lr0=5.028e-04, train_time=1.879
[seoultech:0/4] 2024-01-28 04:06:13,020 (trainer:753) INFO: 3epoch:train:8415-9015batch: iter_time=2.646e-04, forward_time=0.151, loss_ctc=68.959, loss_att=38.279, acc=0.797, loss=47.483, backward_time=0.182, grad_norm=33.759, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.044, optim0_lr0=5.122e-04, train_time=1.908
[seoultech:0/4] 2024-01-28 04:10:59,504 (trainer:753) INFO: 3epoch:train:9016-9616batch: iter_time=2.851e-04, forward_time=0.161, loss_ctc=66.349, loss_att=36.609, acc=0.798, loss=45.531, backward_time=0.173, grad_norm=32.549, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.043, optim0_lr0=5.216e-04, train_time=1.906
[seoultech:0/4] 2024-01-28 04:15:44,877 (trainer:753) INFO: 3epoch:train:9617-10217batch: iter_time=2.745e-04, forward_time=0.151, loss_ctc=64.970, loss_att=35.697, acc=0.798, loss=44.479, backward_time=0.155, grad_norm=31.634, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.038, optim0_lr0=5.310e-04, train_time=1.899
[seoultech:0/4] 2024-01-28 04:20:21,404 (trainer:753) INFO: 3epoch:train:10218-10818batch: iter_time=2.648e-04, forward_time=0.151, loss_ctc=67.394, loss_att=36.987, acc=0.803, loss=46.109, backward_time=0.153, grad_norm=30.225, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.043, optim0_lr0=5.404e-04, train_time=1.840
[seoultech:0/4] 2024-01-28 04:25:12,576 (trainer:753) INFO: 3epoch:train:10819-11419batch: iter_time=2.812e-04, forward_time=0.166, loss_ctc=61.833, loss_att=33.667, acc=0.804, loss=42.117, backward_time=0.217, grad_norm=27.825, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.044, optim0_lr0=5.498e-04, train_time=1.937
[seoultech:0/4] 2024-01-28 04:29:58,835 (trainer:753) INFO: 3epoch:train:11420-12020batch: iter_time=2.721e-04, forward_time=0.144, loss_ctc=66.724, loss_att=36.216, acc=0.807, loss=45.369, backward_time=0.211, grad_norm=29.832, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.044, optim0_lr0=5.592e-04, train_time=1.904
[seoultech:0/4] 2024-01-28 04:41:24,400 (trainer:352) INFO: 3epoch results: [train] iter_time=3.288e-04, forward_time=0.156, loss_ctc=69.398, loss_att=39.487, acc=0.785, loss=48.460, backward_time=0.188, grad_norm=35.246, clip=100.000, loss_scale=7.028e+05, optim_step_time=0.043, optim0_lr0=4.701e-04, train_time=1.901, time=1 hour, 35 minutes and 22.06 seconds, total_count=36099, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=30.568, cer_ctc=0.194, loss_att=16.346, acc=0.899, cer=0.132, wer=0.335, loss=20.613, time=9 minutes and 59.23 seconds, total_count=4602, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 18.61 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 04:41:32,793 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 04:41:32,794 (trainer:286) INFO: 4/50epoch started. Estimated time to finish: 3 days, 12 hours and 27 minutes
[seoultech:0/4] 2024-01-28 04:46:52,891 (trainer:753) INFO: 4epoch:train:1-601batch: iter_time=0.001, forward_time=0.159, loss_ctc=58.097, loss_att=31.283, acc=0.806, loss=39.327, backward_time=0.156, grad_norm=28.592, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.041, optim0_lr0=5.688e-04, train_time=2.130
[seoultech:0/4] 2024-01-28 04:51:28,177 (trainer:753) INFO: 4epoch:train:602-1202batch: iter_time=2.698e-04, forward_time=0.152, loss_ctc=63.766, loss_att=34.326, acc=0.810, loss=43.158, backward_time=0.173, grad_norm=28.932, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.043, optim0_lr0=5.782e-04, train_time=1.831
[seoultech:0/4] 2024-01-28 04:56:02,728 (trainer:753) INFO: 4epoch:train:1203-1803batch: iter_time=2.771e-04, forward_time=0.163, loss_ctc=63.337, loss_att=34.223, acc=0.810, loss=42.957, backward_time=0.180, grad_norm=30.071, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.043, optim0_lr0=5.875e-04, train_time=1.828
[seoultech:0/4] 2024-01-28 05:00:28,152 (trainer:753) INFO: 4epoch:train:1804-2404batch: iter_time=2.816e-04, forward_time=0.159, loss_ctc=63.751, loss_att=34.290, acc=0.811, loss=43.129, backward_time=0.154, grad_norm=28.990, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.044, optim0_lr0=5.969e-04, train_time=1.765
[seoultech:0/4] 2024-01-28 05:05:02,748 (trainer:753) INFO: 4epoch:train:2405-3005batch: iter_time=2.595e-04, forward_time=0.149, loss_ctc=64.254, loss_att=34.261, acc=0.814, loss=43.259, backward_time=0.165, grad_norm=27.052, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.043, optim0_lr0=6.063e-04, train_time=1.827
[seoultech:0/4] 2024-01-28 05:09:42,914 (trainer:753) INFO: 4epoch:train:3006-3606batch: iter_time=2.548e-04, forward_time=0.150, loss_ctc=61.335, loss_att=32.630, acc=0.814, loss=41.242, backward_time=0.186, grad_norm=28.673, clip=100.000, loss_scale=1.049e+06, optim_step_time=0.040, optim0_lr0=6.157e-04, train_time=1.865
[seoultech:0/4] 2024-01-28 05:14:14,901 (trainer:753) INFO: 4epoch:train:3607-4207batch: iter_time=2.788e-04, forward_time=0.166, loss_ctc=64.713, loss_att=34.398, acc=0.815, loss=43.492, backward_time=0.158, grad_norm=27.723, clip=100.000, loss_scale=1.573e+06, optim_step_time=0.046, optim0_lr0=6.251e-04, train_time=1.809
[seoultech:0/4] 2024-01-28 05:18:56,962 (trainer:753) INFO: 4epoch:train:4208-4808batch: iter_time=2.738e-04, forward_time=0.159, loss_ctc=61.747, loss_att=32.889, acc=0.818, loss=41.546, backward_time=0.155, grad_norm=27.156, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.044, optim0_lr0=6.345e-04, train_time=1.875
[seoultech:0/4] 2024-01-28 05:23:35,803 (trainer:753) INFO: 4epoch:train:4809-5409batch: iter_time=2.735e-04, forward_time=0.153, loss_ctc=62.184, loss_att=32.789, acc=0.815, loss=41.608, backward_time=0.180, grad_norm=26.943, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.043, optim0_lr0=6.439e-04, train_time=1.856
[seoultech:0/4] 2024-01-28 05:28:14,806 (trainer:753) INFO: 4epoch:train:5410-6010batch: iter_time=2.763e-04, forward_time=0.147, loss_ctc=64.594, loss_att=34.015, acc=0.818, loss=43.188, backward_time=0.190, grad_norm=27.526, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.042, optim0_lr0=6.533e-04, train_time=1.856
[seoultech:0/4] 2024-01-28 05:32:50,759 (trainer:753) INFO: 4epoch:train:6011-6611batch: iter_time=2.578e-04, forward_time=0.153, loss_ctc=61.727, loss_att=32.444, acc=0.819, loss=41.229, backward_time=0.173, grad_norm=27.094, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.040, optim0_lr0=6.627e-04, train_time=1.837
[seoultech:0/4] 2024-01-28 05:37:24,271 (trainer:753) INFO: 4epoch:train:6612-7212batch: iter_time=2.454e-04, forward_time=0.135, loss_ctc=61.250, loss_att=32.123, acc=0.820, loss=40.861, backward_time=0.153, grad_norm=26.105, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.031, optim0_lr0=6.721e-04, train_time=1.818
[seoultech:0/4] 2024-01-28 05:42:04,874 (trainer:753) INFO: 4epoch:train:7213-7813batch: iter_time=2.696e-04, forward_time=0.152, loss_ctc=61.698, loss_att=32.313, acc=0.821, loss=41.129, backward_time=0.154, grad_norm=26.448, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.040, optim0_lr0=6.815e-04, train_time=1.867
[seoultech:0/4] 2024-01-28 05:46:50,282 (trainer:753) INFO: 4epoch:train:7814-8414batch: iter_time=2.632e-04, forward_time=0.149, loss_ctc=59.431, loss_att=31.105, acc=0.821, loss=39.603, backward_time=0.159, grad_norm=26.369, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.043, optim0_lr0=6.908e-04, train_time=1.899
[seoultech:0/4] 2024-01-28 05:51:43,719 (trainer:753) INFO: 4epoch:train:8415-9015batch: iter_time=2.810e-04, forward_time=0.141, loss_ctc=57.947, loss_att=30.168, acc=0.825, loss=38.502, backward_time=0.205, grad_norm=24.925, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.041, optim0_lr0=7.002e-04, train_time=1.952
[seoultech:0/4] 2024-01-28 05:56:31,444 (trainer:753) INFO: 4epoch:train:9016-9616batch: iter_time=2.493e-04, forward_time=0.135, loss_ctc=63.673, loss_att=33.014, acc=0.826, loss=42.212, backward_time=0.215, grad_norm=25.372, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.038, optim0_lr0=7.096e-04, train_time=1.914
[seoultech:0/4] 2024-01-28 06:01:08,065 (trainer:753) INFO: 4epoch:train:9617-10217batch: iter_time=2.535e-04, forward_time=0.139, loss_ctc=60.147, loss_att=31.043, acc=0.826, loss=39.775, backward_time=0.184, grad_norm=24.075, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.041, optim0_lr0=7.190e-04, train_time=1.841
[seoultech:0/4] 2024-01-28 06:05:41,228 (trainer:753) INFO: 4epoch:train:10218-10818batch: iter_time=2.624e-04, forward_time=0.148, loss_ctc=60.012, loss_att=30.965, acc=0.827, loss=39.679, backward_time=0.192, grad_norm=24.163, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.039, optim0_lr0=7.284e-04, train_time=1.816
[seoultech:0/4] 2024-01-28 06:10:20,927 (trainer:753) INFO: 4epoch:train:10819-11419batch: iter_time=2.769e-04, forward_time=0.165, loss_ctc=61.391, loss_att=31.687, acc=0.826, loss=40.599, backward_time=0.164, grad_norm=25.282, clip=100.000, loss_scale=2.097e+06, optim_step_time=0.043, optim0_lr0=7.378e-04, train_time=1.862
[seoultech:0/4] 2024-01-28 06:15:07,535 (trainer:753) INFO: 4epoch:train:11420-12020batch: iter_time=2.691e-04, forward_time=0.144, loss_ctc=60.484, loss_att=31.200, acc=0.828, loss=39.985, backward_time=0.183, grad_norm=24.795, clip=100.000, loss_scale=2.500e+06, optim_step_time=0.041, optim0_lr0=7.472e-04, train_time=1.906
[seoultech:0/4] 2024-01-28 06:27:24,352 (trainer:352) INFO: 4epoch results: [train] iter_time=3.222e-04, forward_time=0.151, loss_ctc=61.713, loss_att=32.529, acc=0.818, loss=41.284, backward_time=0.174, grad_norm=26.808, clip=100.000, loss_scale=1.779e+06, optim_step_time=0.041, optim0_lr0=6.581e-04, train_time=1.868, time=1 hour, 33 minutes and 43.02 seconds, total_count=48132, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=27.308, cer_ctc=0.177, loss_att=13.664, acc=0.913, cer=0.116, wer=0.301, loss=17.757, time=10 minutes and 23.59 seconds, total_count=6136, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 44.94 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 06:27:31,906 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 06:27:31,907 (trainer:286) INFO: 5/50epoch started. Estimated time to finish: 3 days, 10 hours and 18 minutes
[seoultech:0/4] 2024-01-28 06:33:03,366 (trainer:753) INFO: 5epoch:train:1-601batch: iter_time=0.001, forward_time=0.154, loss_ctc=59.575, loss_att=30.520, acc=0.829, loss=39.236, backward_time=0.183, grad_norm=24.243, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.040, optim0_lr0=7.568e-04, train_time=2.206
[seoultech:0/4] 2024-01-28 06:37:43,810 (trainer:753) INFO: 5epoch:train:602-1202batch: iter_time=2.794e-04, forward_time=0.148, loss_ctc=60.337, loss_att=30.975, acc=0.829, loss=39.784, backward_time=0.153, grad_norm=24.650, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.041, optim0_lr0=7.662e-04, train_time=1.865
[seoultech:0/4] 2024-01-28 06:42:23,012 (trainer:753) INFO: 5epoch:train:1203-1803batch: iter_time=2.642e-04, forward_time=0.148, loss_ctc=60.755, loss_att=31.067, acc=0.830, loss=39.973, backward_time=0.178, grad_norm=24.927, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.043, optim0_lr0=7.755e-04, train_time=1.858
[seoultech:0/4] 2024-01-28 06:47:00,473 (trainer:753) INFO: 5epoch:train:1804-2404batch: iter_time=2.816e-04, forward_time=0.148, loss_ctc=59.758, loss_att=30.586, acc=0.832, loss=39.338, backward_time=0.186, grad_norm=24.167, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.044, optim0_lr0=7.849e-04, train_time=1.845
[seoultech:0/4] 2024-01-28 06:51:46,532 (trainer:753) INFO: 5epoch:train:2405-3005batch: iter_time=2.845e-04, forward_time=0.147, loss_ctc=56.165, loss_att=28.599, acc=0.830, loss=36.869, backward_time=0.209, grad_norm=23.504, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.046, optim0_lr0=7.943e-04, train_time=1.903
[seoultech:0/4] 2024-01-28 06:56:26,743 (trainer:753) INFO: 5epoch:train:3006-3606batch: iter_time=2.896e-04, forward_time=0.149, loss_ctc=62.500, loss_att=31.831, acc=0.833, loss=41.032, backward_time=0.157, grad_norm=24.408, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.038, optim0_lr0=8.037e-04, train_time=1.865
[seoultech:0/4] 2024-01-28 07:01:05,321 (trainer:753) INFO: 5epoch:train:3607-4207batch: iter_time=2.796e-04, forward_time=0.159, loss_ctc=56.027, loss_att=28.442, acc=0.833, loss=36.717, backward_time=0.157, grad_norm=22.610, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.043, optim0_lr0=8.131e-04, train_time=1.853
[seoultech:0/4] 2024-01-28 07:05:45,832 (trainer:753) INFO: 5epoch:train:4208-4808batch: iter_time=2.655e-04, forward_time=0.150, loss_ctc=58.485, loss_att=29.708, acc=0.833, loss=38.341, backward_time=0.174, grad_norm=23.906, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.042, optim0_lr0=8.225e-04, train_time=1.865
[seoultech:0/4] 2024-01-28 07:10:08,520 (trainer:753) INFO: 5epoch:train:4809-5409batch: iter_time=2.819e-04, forward_time=0.160, loss_ctc=55.095, loss_att=27.774, acc=0.833, loss=35.970, backward_time=0.156, grad_norm=21.689, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.044, optim0_lr0=8.319e-04, train_time=1.748
[seoultech:0/4] 2024-01-28 07:14:43,861 (trainer:753) INFO: 5epoch:train:5410-6010batch: iter_time=2.886e-04, forward_time=0.168, loss_ctc=58.348, loss_att=29.553, acc=0.834, loss=38.192, backward_time=0.159, grad_norm=23.012, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.047, optim0_lr0=8.413e-04, train_time=1.832
[seoultech:0/4] 2024-01-28 07:19:20,322 (trainer:753) INFO: 5epoch:train:6011-6611batch: iter_time=2.747e-04, forward_time=0.163, loss_ctc=55.720, loss_att=28.171, acc=0.837, loss=36.436, backward_time=0.170, grad_norm=21.543, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.044, optim0_lr0=8.507e-04, train_time=1.839
[seoultech:0/4] 2024-01-28 07:23:56,537 (trainer:753) INFO: 5epoch:train:6612-7212batch: iter_time=2.762e-04, forward_time=0.166, loss_ctc=54.921, loss_att=27.716, acc=0.835, loss=35.877, backward_time=0.170, grad_norm=21.894, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.047, optim0_lr0=8.601e-04, train_time=1.837
[seoultech:0/4] 2024-01-28 07:28:35,724 (trainer:753) INFO: 5epoch:train:7213-7813batch: iter_time=2.917e-04, forward_time=0.165, loss_ctc=57.540, loss_att=29.158, acc=0.835, loss=37.673, backward_time=0.167, grad_norm=22.559, clip=100.000, loss_scale=4.194e+06, optim_step_time=0.043, optim0_lr0=8.695e-04, train_time=1.857
[seoultech:0/4] 2024-01-28 07:33:31,598 (trainer:753) INFO: 5epoch:train:7814-8414batch: iter_time=2.684e-04, forward_time=0.158, loss_ctc=58.366, loss_att=29.375, acc=0.839, loss=38.072, backward_time=0.215, grad_norm=21.595, clip=100.000, loss_scale=7.969e+06, optim_step_time=0.044, optim0_lr0=8.788e-04, train_time=1.968
[seoultech:0/4] 2024-01-28 07:38:25,157 (trainer:753) INFO: 5epoch:train:8415-9015batch: iter_time=2.792e-04, forward_time=0.170, loss_ctc=54.192, loss_att=27.130, acc=0.836, loss=35.249, backward_time=0.194, grad_norm=21.856, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.043, optim0_lr0=8.882e-04, train_time=1.954
[seoultech:0/4] 2024-01-28 07:43:16,312 (trainer:753) INFO: 5epoch:train:9016-9616batch: iter_time=2.725e-04, forward_time=0.158, loss_ctc=58.301, loss_att=29.247, acc=0.839, loss=37.963, backward_time=0.201, grad_norm=22.580, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.042, optim0_lr0=8.976e-04, train_time=1.936
[seoultech:0/4] 2024-01-28 07:48:00,238 (trainer:753) INFO: 5epoch:train:9617-10217batch: iter_time=2.724e-04, forward_time=0.166, loss_ctc=58.667, loss_att=29.576, acc=0.839, loss=38.303, backward_time=0.155, grad_norm=22.802, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.044, optim0_lr0=9.070e-04, train_time=1.889
[seoultech:0/4] 2024-01-28 07:52:51,234 (trainer:753) INFO: 5epoch:train:10218-10818batch: iter_time=2.758e-04, forward_time=0.150, loss_ctc=57.080, loss_att=28.515, acc=0.838, loss=37.084, backward_time=0.169, grad_norm=22.478, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.038, optim0_lr0=9.164e-04, train_time=1.936
[seoultech:0/4] 2024-01-28 07:57:40,176 (trainer:753) INFO: 5epoch:train:10819-11419batch: iter_time=2.812e-04, forward_time=0.155, loss_ctc=56.928, loss_att=28.268, acc=0.840, loss=36.866, backward_time=0.170, grad_norm=21.923, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.039, optim0_lr0=9.258e-04, train_time=1.924
[seoultech:0/4] 2024-01-28 08:02:22,262 (trainer:753) INFO: 5epoch:train:11420-12020batch: iter_time=2.368e-04, forward_time=0.134, loss_ctc=57.438, loss_att=28.652, acc=0.842, loss=37.288, backward_time=0.178, grad_norm=21.950, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.033, optim0_lr0=9.352e-04, train_time=1.876
[seoultech:0/4] 2024-01-28 08:13:37,192 (trainer:352) INFO: 5epoch results: [train] iter_time=3.255e-04, forward_time=0.156, loss_ctc=57.770, loss_att=29.222, acc=0.835, loss=37.786, backward_time=0.175, grad_norm=22.914, clip=100.000, loss_scale=5.644e+06, optim_step_time=0.042, optim0_lr0=8.461e-04, train_time=1.893, time=1 hour, 34 minutes and 58.63 seconds, total_count=60165, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=25.434, cer_ctc=0.168, loss_att=12.178, acc=0.920, cer=0.107, wer=0.285, loss=16.155, time=9 minutes and 46.46 seconds, total_count=7670, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 20.2 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 08:13:45,143 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 08:13:45,143 (trainer:286) INFO: 6/50epoch started. Estimated time to finish: 3 days, 8 hours and 20 minutes
[seoultech:0/4] 2024-01-28 08:19:14,365 (trainer:753) INFO: 6epoch:train:1-601batch: iter_time=0.001, forward_time=0.158, loss_ctc=56.525, loss_att=28.065, acc=0.841, loss=36.603, backward_time=0.175, grad_norm=21.795, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.045, optim0_lr0=9.448e-04, train_time=2.191
[seoultech:0/4] 2024-01-28 08:23:59,334 (trainer:753) INFO: 6epoch:train:602-1202batch: iter_time=2.671e-04, forward_time=0.153, loss_ctc=57.063, loss_att=28.356, acc=0.841, loss=36.968, backward_time=0.187, grad_norm=21.147, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.042, optim0_lr0=9.542e-04, train_time=1.894
[seoultech:0/4] 2024-01-28 08:28:36,419 (trainer:753) INFO: 6epoch:train:1203-1803batch: iter_time=2.658e-04, forward_time=0.151, loss_ctc=56.555, loss_att=28.074, acc=0.841, loss=36.618, backward_time=0.154, grad_norm=21.369, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.043, optim0_lr0=9.635e-04, train_time=1.845
[seoultech:0/4] 2024-01-28 08:33:17,873 (trainer:753) INFO: 6epoch:train:1804-2404batch: iter_time=2.725e-04, forward_time=0.146, loss_ctc=59.734, loss_att=29.461, acc=0.843, loss=38.543, backward_time=0.185, grad_norm=21.636, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.044, optim0_lr0=9.729e-04, train_time=1.873
[seoultech:0/4] 2024-01-28 08:37:58,446 (trainer:753) INFO: 6epoch:train:2405-3005batch: iter_time=2.706e-04, forward_time=0.153, loss_ctc=57.969, loss_att=28.747, acc=0.843, loss=37.514, backward_time=0.177, grad_norm=21.594, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.043, optim0_lr0=9.823e-04, train_time=1.866
[seoultech:0/4] 2024-01-28 08:42:40,264 (trainer:753) INFO: 6epoch:train:3006-3606batch: iter_time=2.754e-04, forward_time=0.147, loss_ctc=54.198, loss_att=26.948, acc=0.843, loss=35.123, backward_time=0.169, grad_norm=20.664, clip=100.000, loss_scale=8.389e+06, optim_step_time=0.042, optim0_lr0=9.917e-04, train_time=1.875
[seoultech:0/4] 2024-01-28 08:47:17,671 (trainer:753) INFO: 6epoch:train:3607-4207batch: iter_time=2.741e-04, forward_time=0.158, loss_ctc=53.406, loss_att=26.403, acc=0.843, loss=34.504, backward_time=0.150, grad_norm=20.832, clip=100.000, loss_scale=1.348e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.846
[seoultech:0/4] 2024-01-28 08:52:01,147 (trainer:753) INFO: 6epoch:train:4208-4808batch: iter_time=2.857e-04, forward_time=0.164, loss_ctc=54.788, loss_att=27.093, acc=0.845, loss=35.402, backward_time=0.183, grad_norm=20.316, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.885
[seoultech:0/4] 2024-01-28 08:56:52,876 (trainer:753) INFO: 6epoch:train:4809-5409batch: iter_time=2.901e-04, forward_time=0.158, loss_ctc=53.451, loss_att=26.259, acc=0.845, loss=34.417, backward_time=0.205, grad_norm=19.989, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.046, optim0_lr0=0.001, train_time=1.941
[seoultech:0/4] 2024-01-28 09:01:37,357 (trainer:753) INFO: 6epoch:train:5410-6010batch: iter_time=2.715e-04, forward_time=0.150, loss_ctc=53.192, loss_att=26.192, acc=0.846, loss=34.292, backward_time=0.207, grad_norm=20.517, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.893
[seoultech:0/4] 2024-01-28 09:06:25,659 (trainer:753) INFO: 6epoch:train:6011-6611batch: iter_time=2.757e-04, forward_time=0.151, loss_ctc=54.596, loss_att=26.900, acc=0.843, loss=35.209, backward_time=0.202, grad_norm=20.964, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.918
[seoultech:0/4] 2024-01-28 09:11:04,269 (trainer:753) INFO: 6epoch:train:6612-7212batch: iter_time=2.755e-04, forward_time=0.165, loss_ctc=55.076, loss_att=27.171, acc=0.849, loss=35.543, backward_time=0.184, grad_norm=20.320, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.046, optim0_lr0=0.001, train_time=1.853
[seoultech:0/4] 2024-01-28 09:15:50,139 (trainer:753) INFO: 6epoch:train:7213-7813batch: iter_time=2.795e-04, forward_time=0.170, loss_ctc=54.341, loss_att=26.700, acc=0.844, loss=34.992, backward_time=0.200, grad_norm=21.369, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.902
[seoultech:0/4] 2024-01-28 09:20:32,565 (trainer:753) INFO: 6epoch:train:7814-8414batch: iter_time=2.690e-04, forward_time=0.163, loss_ctc=55.859, loss_att=27.606, acc=0.846, loss=36.082, backward_time=0.191, grad_norm=21.060, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.880
[seoultech:0/4] 2024-01-28 09:25:15,962 (trainer:753) INFO: 6epoch:train:8415-9015batch: iter_time=2.736e-04, forward_time=0.166, loss_ctc=55.284, loss_att=27.126, acc=0.847, loss=35.573, backward_time=0.149, grad_norm=20.443, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.884
[seoultech:0/4] 2024-01-28 09:30:05,490 (trainer:753) INFO: 6epoch:train:9016-9616batch: iter_time=2.685e-04, forward_time=0.164, loss_ctc=54.549, loss_att=26.671, acc=0.847, loss=35.034, backward_time=0.163, grad_norm=19.944, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.926
[seoultech:0/4] 2024-01-28 09:34:55,471 (trainer:753) INFO: 6epoch:train:9617-10217batch: iter_time=2.750e-04, forward_time=0.172, loss_ctc=52.860, loss_att=25.879, acc=0.847, loss=33.973, backward_time=0.203, grad_norm=20.486, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.047, optim0_lr0=0.001, train_time=1.930
[seoultech:0/4] 2024-01-28 09:39:52,354 (trainer:753) INFO: 6epoch:train:10218-10818batch: iter_time=2.834e-04, forward_time=0.170, loss_ctc=57.661, loss_att=28.260, acc=0.846, loss=37.080, backward_time=0.215, grad_norm=21.142, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.045, optim0_lr0=0.001, train_time=1.975
[seoultech:0/4] 2024-01-28 09:44:45,429 (trainer:753) INFO: 6epoch:train:10819-11419batch: iter_time=2.931e-04, forward_time=0.166, loss_ctc=54.540, loss_att=26.579, acc=0.849, loss=34.967, backward_time=0.152, grad_norm=19.490, clip=100.000, loss_scale=1.678e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.950
[seoultech:0/4] 2024-01-28 09:49:40,751 (trainer:753) INFO: 6epoch:train:11420-12020batch: iter_time=2.777e-04, forward_time=0.155, loss_ctc=54.047, loss_att=26.413, acc=0.847, loss=34.703, backward_time=0.154, grad_norm=20.265, clip=100.000, loss_scale=2.178e+07, optim_step_time=0.040, optim0_lr0=0.001, train_time=1.964
[seoultech:0/4] 2024-01-28 10:01:20,765 (trainer:352) INFO: 6epoch results: [train] iter_time=3.279e-04, forward_time=0.159, loss_ctc=55.231, loss_att=27.217, acc=0.845, loss=35.621, backward_time=0.180, grad_norm=20.761, clip=100.000, loss_scale=1.437e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.915, time=1 hour, 36 minutes and 3.69 seconds, total_count=72198, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=23.981, cer_ctc=0.161, loss_att=11.390, acc=0.924, cer=0.100, wer=0.273, loss=15.167, time=10 minutes and 10.51 seconds, total_count=9204, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 21.43 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 10:01:29,704 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 10:01:29,704 (trainer:286) INFO: 7/50epoch started. Estimated time to finish: 3 days, 6 hours and 38 minutes
[seoultech:0/4] 2024-01-28 10:06:53,178 (trainer:753) INFO: 7epoch:train:1-601batch: iter_time=0.002, forward_time=0.146, loss_ctc=55.119, loss_att=26.842, acc=0.851, loss=35.325, backward_time=0.155, grad_norm=20.555, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.036, optim0_lr0=0.001, train_time=2.153
[seoultech:0/4] 2024-01-28 10:11:37,934 (trainer:753) INFO: 7epoch:train:602-1202batch: iter_time=2.943e-04, forward_time=0.166, loss_ctc=53.095, loss_att=25.790, acc=0.849, loss=33.982, backward_time=0.159, grad_norm=19.879, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.045, optim0_lr0=0.001, train_time=1.894
[seoultech:0/4] 2024-01-28 10:16:14,615 (trainer:753) INFO: 7epoch:train:1203-1803batch: iter_time=2.800e-04, forward_time=0.150, loss_ctc=55.086, loss_att=26.844, acc=0.851, loss=35.317, backward_time=0.159, grad_norm=19.828, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.841
[seoultech:0/4] 2024-01-28 10:20:53,831 (trainer:753) INFO: 7epoch:train:1804-2404batch: iter_time=2.680e-04, forward_time=0.156, loss_ctc=55.344, loss_att=26.892, acc=0.850, loss=35.428, backward_time=0.162, grad_norm=20.103, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.857
[seoultech:0/4] 2024-01-28 10:25:43,707 (trainer:753) INFO: 7epoch:train:2405-3005batch: iter_time=2.777e-04, forward_time=0.169, loss_ctc=52.129, loss_att=25.274, acc=0.851, loss=33.330, backward_time=0.195, grad_norm=20.826, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.929
[seoultech:0/4] 2024-01-28 10:30:27,002 (trainer:753) INFO: 7epoch:train:3006-3606batch: iter_time=2.879e-04, forward_time=0.172, loss_ctc=53.891, loss_att=26.303, acc=0.851, loss=34.579, backward_time=0.155, grad_norm=20.191, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.046, optim0_lr0=0.001, train_time=1.885
[seoultech:0/4] 2024-01-28 10:35:07,713 (trainer:753) INFO: 7epoch:train:3607-4207batch: iter_time=2.785e-04, forward_time=0.165, loss_ctc=52.478, loss_att=25.471, acc=0.851, loss=33.573, backward_time=0.174, grad_norm=19.866, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.869
[seoultech:0/4] 2024-01-28 10:39:53,447 (trainer:753) INFO: 7epoch:train:4208-4808batch: iter_time=2.819e-04, forward_time=0.169, loss_ctc=54.119, loss_att=26.309, acc=0.851, loss=34.652, backward_time=0.190, grad_norm=19.564, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.899
[seoultech:0/4] 2024-01-28 10:44:29,577 (trainer:753) INFO: 7epoch:train:4809-5409batch: iter_time=2.741e-04, forward_time=0.152, loss_ctc=55.401, loss_att=26.968, acc=0.852, loss=35.498, backward_time=0.162, grad_norm=20.401, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.040, optim0_lr0=0.001, train_time=1.838
[seoultech:0/4] 2024-01-28 10:49:12,660 (trainer:753) INFO: 7epoch:train:5410-6010batch: iter_time=2.693e-04, forward_time=0.155, loss_ctc=53.492, loss_att=25.844, acc=0.852, loss=34.138, backward_time=0.192, grad_norm=19.915, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.883
[seoultech:0/4] 2024-01-28 10:54:03,840 (trainer:753) INFO: 7epoch:train:6011-6611batch: iter_time=2.704e-04, forward_time=0.160, loss_ctc=51.050, loss_att=24.731, acc=0.849, loss=32.627, backward_time=0.204, grad_norm=19.995, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.937
[seoultech:0/4] 2024-01-28 10:58:51,008 (trainer:753) INFO: 7epoch:train:6612-7212batch: iter_time=2.763e-04, forward_time=0.163, loss_ctc=53.923, loss_att=26.076, acc=0.853, loss=34.430, backward_time=0.171, grad_norm=19.435, clip=100.000, loss_scale=3.355e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.910
[seoultech:0/4] 2024-01-28 11:03:39,718 (trainer:753) INFO: 7epoch:train:7213-7813batch: iter_time=2.780e-04, forward_time=0.166, loss_ctc=52.740, loss_att=25.565, acc=0.852, loss=33.718, backward_time=0.206, grad_norm=19.841, clip=100.000, loss_scale=3.378e+07, optim_step_time=0.047, optim0_lr0=0.001, train_time=1.922
[seoultech:0/4] 2024-01-28 11:08:22,359 (trainer:753) INFO: 7epoch:train:7814-8414batch: iter_time=2.773e-04, forward_time=0.156, loss_ctc=53.309, loss_att=25.747, acc=0.851, loss=34.015, backward_time=0.180, grad_norm=20.892, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.880
[seoultech:0/4] 2024-01-28 11:13:15,910 (trainer:753) INFO: 7epoch:train:8415-9015batch: iter_time=2.763e-04, forward_time=0.160, loss_ctc=51.710, loss_att=24.947, acc=0.854, loss=32.976, backward_time=0.218, grad_norm=20.113, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.046, optim0_lr0=0.001, train_time=1.953
[seoultech:0/4] 2024-01-28 11:18:09,295 (trainer:753) INFO: 7epoch:train:9016-9616batch: iter_time=2.811e-04, forward_time=0.167, loss_ctc=51.206, loss_att=24.562, acc=0.853, loss=32.555, backward_time=0.217, grad_norm=19.383, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.047, optim0_lr0=0.001, train_time=1.951
[seoultech:0/4] 2024-01-28 11:22:50,966 (trainer:753) INFO: 7epoch:train:9617-10217batch: iter_time=2.752e-04, forward_time=0.168, loss_ctc=52.789, loss_att=25.409, acc=0.853, loss=33.623, backward_time=0.164, grad_norm=19.700, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.045, optim0_lr0=0.001, train_time=1.874
[seoultech:0/4] 2024-01-28 11:27:31,261 (trainer:753) INFO: 7epoch:train:10218-10818batch: iter_time=2.712e-04, forward_time=0.161, loss_ctc=54.819, loss_att=26.413, acc=0.853, loss=34.935, backward_time=0.169, grad_norm=19.523, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.041, optim0_lr0=0.001, train_time=1.863
[seoultech:0/4] 2024-01-28 11:32:16,080 (trainer:753) INFO: 7epoch:train:10819-11419batch: iter_time=2.740e-04, forward_time=0.165, loss_ctc=54.528, loss_att=26.322, acc=0.855, loss=34.784, backward_time=0.170, grad_norm=19.988, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.896
[seoultech:0/4] 2024-01-28 11:36:56,722 (trainer:753) INFO: 7epoch:train:11420-12020batch: iter_time=2.959e-04, forward_time=0.164, loss_ctc=52.924, loss_att=25.493, acc=0.852, loss=33.722, backward_time=0.178, grad_norm=19.758, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.867
[seoultech:0/4] 2024-01-28 11:48:34,830 (trainer:352) INFO: 7epoch results: [train] iter_time=3.620e-04, forward_time=0.162, loss_ctc=53.415, loss_att=25.868, acc=0.852, loss=34.132, backward_time=0.179, grad_norm=19.990, clip=100.000, loss_scale=4.533e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.905, time=1 hour, 35 minutes and 35.28 seconds, total_count=84231, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=23.658, cer_ctc=0.156, loss_att=10.927, acc=0.927, cer=0.096, wer=0.263, loss=14.746, time=9 minutes and 49.49 seconds, total_count=10738, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 40.35 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 11:48:43,867 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 11:48:43,868 (trainer:286) INFO: 8/50epoch started. Estimated time to finish: 3 days, 4 hours and 51 minutes
[seoultech:0/4] 2024-01-28 11:53:57,777 (trainer:753) INFO: 8epoch:train:1-601batch: iter_time=0.001, forward_time=0.163, loss_ctc=53.806, loss_att=25.757, acc=0.855, loss=34.172, backward_time=0.161, grad_norm=19.341, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.044, optim0_lr0=0.001, train_time=2.089
[seoultech:0/4] 2024-01-28 11:58:47,486 (trainer:753) INFO: 8epoch:train:602-1202batch: iter_time=2.646e-04, forward_time=0.142, loss_ctc=52.235, loss_att=25.024, acc=0.855, loss=33.187, backward_time=0.202, grad_norm=19.262, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.038, optim0_lr0=0.001, train_time=1.926
[seoultech:0/4] 2024-01-28 12:03:39,281 (trainer:753) INFO: 8epoch:train:1203-1803batch: iter_time=2.839e-04, forward_time=0.160, loss_ctc=53.482, loss_att=25.580, acc=0.854, loss=33.951, backward_time=0.202, grad_norm=20.319, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.046, optim0_lr0=0.001, train_time=1.942
[seoultech:0/4] 2024-01-28 12:08:28,162 (trainer:753) INFO: 8epoch:train:1804-2404batch: iter_time=2.559e-04, forward_time=0.144, loss_ctc=55.760, loss_att=26.762, acc=0.856, loss=35.461, backward_time=0.183, grad_norm=19.246, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.041, optim0_lr0=0.001, train_time=1.921
[seoultech:0/4] 2024-01-28 12:13:16,945 (trainer:753) INFO: 8epoch:train:2405-3005batch: iter_time=2.760e-04, forward_time=0.162, loss_ctc=53.635, loss_att=25.665, acc=0.856, loss=34.056, backward_time=0.157, grad_norm=19.564, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.921
[seoultech:0/4] 2024-01-28 12:18:03,712 (trainer:753) INFO: 8epoch:train:3006-3606batch: iter_time=2.738e-04, forward_time=0.160, loss_ctc=50.531, loss_att=24.132, acc=0.855, loss=32.052, backward_time=0.165, grad_norm=19.259, clip=100.000, loss_scale=6.711e+07, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.908
[seoultech:0/4] 2024-01-28 12:22:37,959 (trainer:753) INFO: 8epoch:train:3607-4207batch: iter_time=2.679e-04, forward_time=0.153, loss_ctc=54.846, loss_att=26.229, acc=0.857, loss=34.814, backward_time=0.154, grad_norm=19.523, clip=100.000, loss_scale=1.150e+08, optim_step_time=0.039, optim0_lr0=0.001, train_time=1.824
[seoultech:0/4] 2024-01-28 12:27:24,281 (trainer:753) INFO: 8epoch:train:4208-4808batch: iter_time=2.559e-04, forward_time=0.150, loss_ctc=53.143, loss_att=25.373, acc=0.856, loss=33.704, backward_time=0.175, grad_norm=19.549, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.039, optim0_lr0=0.001, train_time=1.905
[seoultech:0/4] 2024-01-28 12:32:09,989 (trainer:753) INFO: 8epoch:train:4809-5409batch: iter_time=2.523e-04, forward_time=0.142, loss_ctc=52.654, loss_att=25.219, acc=0.854, loss=33.450, backward_time=0.188, grad_norm=19.343, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.041, optim0_lr0=0.001, train_time=1.901
[seoultech:0/4] 2024-01-28 12:36:57,314 (trainer:753) INFO: 8epoch:train:5410-6010batch: iter_time=2.753e-04, forward_time=0.147, loss_ctc=52.682, loss_att=25.050, acc=0.856, loss=33.339, backward_time=0.188, grad_norm=21.018, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.041, optim0_lr0=0.001, train_time=1.912
[seoultech:0/4] 2024-01-28 12:41:37,284 (trainer:753) INFO: 8epoch:train:6011-6611batch: iter_time=2.679e-04, forward_time=0.146, loss_ctc=50.399, loss_att=24.028, acc=0.855, loss=31.939, backward_time=0.175, grad_norm=19.400, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.863
[seoultech:0/4] 2024-01-28 12:46:09,798 (trainer:753) INFO: 8epoch:train:6612-7212batch: iter_time=2.586e-04, forward_time=0.153, loss_ctc=50.401, loss_att=24.029, acc=0.856, loss=31.941, backward_time=0.155, grad_norm=19.219, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.045, optim0_lr0=0.001, train_time=1.813
[seoultech:0/4] 2024-01-28 12:50:58,027 (trainer:753) INFO: 8epoch:train:7213-7813batch: iter_time=2.736e-04, forward_time=0.161, loss_ctc=53.042, loss_att=25.190, acc=0.857, loss=33.545, backward_time=0.184, grad_norm=19.834, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.917
[seoultech:0/4] 2024-01-28 12:56:02,395 (trainer:753) INFO: 8epoch:train:7814-8414batch: iter_time=2.798e-04, forward_time=0.172, loss_ctc=51.642, loss_att=24.576, acc=0.857, loss=32.696, backward_time=0.214, grad_norm=19.056, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.044, optim0_lr0=0.001, train_time=2.024
[seoultech:0/4] 2024-01-28 13:00:52,384 (trainer:753) INFO: 8epoch:train:8415-9015batch: iter_time=2.654e-04, forward_time=0.159, loss_ctc=52.717, loss_att=25.024, acc=0.858, loss=33.332, backward_time=0.151, grad_norm=19.869, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.931
[seoultech:0/4] 2024-01-28 13:05:26,267 (trainer:753) INFO: 8epoch:train:9016-9616batch: iter_time=2.677e-04, forward_time=0.160, loss_ctc=52.642, loss_att=24.997, acc=0.859, loss=33.290, backward_time=0.152, grad_norm=19.417, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.046, optim0_lr0=0.001, train_time=1.822
[seoultech:0/4] 2024-01-28 13:10:03,724 (trainer:753) INFO: 8epoch:train:9617-10217batch: iter_time=2.523e-04, forward_time=0.145, loss_ctc=51.265, loss_att=24.438, acc=0.858, loss=32.486, backward_time=0.172, grad_norm=19.195, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.039, optim0_lr0=0.001, train_time=1.846
[seoultech:0/4] 2024-01-28 13:14:39,854 (trainer:753) INFO: 8epoch:train:10218-10818batch: iter_time=2.868e-04, forward_time=0.166, loss_ctc=54.232, loss_att=25.752, acc=0.857, loss=34.296, backward_time=0.164, grad_norm=20.766, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.837
[seoultech:0/4] 2024-01-28 13:19:14,148 (trainer:753) INFO: 8epoch:train:10819-11419batch: iter_time=2.794e-04, forward_time=0.166, loss_ctc=51.796, loss_att=24.615, acc=0.855, loss=32.770, backward_time=0.155, grad_norm=20.674, clip=100.000, loss_scale=1.342e+08, optim_step_time=0.043, optim0_lr0=0.001, train_time=1.824
[seoultech:0/4] 2024-01-28 13:23:47,732 (trainer:753) INFO: 8epoch:train:11420-12020batch: iter_time=2.780e-04, forward_time=0.168, loss_ctc=48.302, loss_att=22.897, acc=0.857, loss=30.519, backward_time=0.152, grad_norm=19.740, clip=100.000, loss_scale=1.884e+08, optim_step_time=0.044, optim0_lr0=0.001, train_time=1.820
[seoultech:0/4] 2024-01-28 13:35:36,198 (trainer:352) INFO: 8epoch results: [train] iter_time=3.253e-04, forward_time=0.156, loss_ctc=52.403, loss_att=24.989, acc=0.856, loss=33.213, backward_time=0.172, grad_norm=19.679, clip=100.000, loss_scale=1.160e+08, optim_step_time=0.042, optim0_lr0=0.001, train_time=1.897, time=1 hour, 35 minutes and 12.04 seconds, total_count=96264, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=23.544, cer_ctc=0.156, loss_att=10.883, acc=0.928, cer=0.095, wer=0.262, loss=14.681, time=9 minutes and 54.46 seconds, total_count=12272, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 45.83 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 13:35:43,881 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 13:35:43,882 (trainer:286) INFO: 9/50epoch started. Estimated time to finish: 3 days, 3 hours and 2 minutes
[seoultech:0/4] 2024-01-28 13:41:14,714 (trainer:753) INFO: 9epoch:train:1-601batch: iter_time=0.002, forward_time=0.162, loss_ctc=50.388, loss_att=23.900, acc=0.860, loss=31.846, backward_time=0.192, grad_norm=18.801, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=2.201
[seoultech:0/4] 2024-01-28 13:45:50,503 (trainer:753) INFO: 9epoch:train:602-1202batch: iter_time=2.819e-04, forward_time=0.157, loss_ctc=50.810, loss_att=24.086, acc=0.859, loss=32.103, backward_time=0.163, grad_norm=19.111, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.836
[seoultech:0/4] 2024-01-28 13:50:36,512 (trainer:753) INFO: 9epoch:train:1203-1803batch: iter_time=2.733e-04, forward_time=0.141, loss_ctc=49.730, loss_att=23.570, acc=0.861, loss=31.418, backward_time=0.207, grad_norm=18.836, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.903
[seoultech:0/4] 2024-01-28 13:55:20,387 (trainer:753) INFO: 9epoch:train:1804-2404batch: iter_time=2.869e-04, forward_time=0.160, loss_ctc=51.155, loss_att=24.315, acc=0.857, loss=32.367, backward_time=0.193, grad_norm=19.869, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.887
[seoultech:0/4] 2024-01-28 14:00:11,734 (trainer:753) INFO: 9epoch:train:2405-3005batch: iter_time=2.795e-04, forward_time=0.170, loss_ctc=48.958, loss_att=23.257, acc=0.859, loss=30.968, backward_time=0.206, grad_norm=19.571, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.939
[seoultech:0/4] 2024-01-28 14:05:00,636 (trainer:753) INFO: 9epoch:train:3006-3606batch: iter_time=2.761e-04, forward_time=0.167, loss_ctc=52.998, loss_att=25.054, acc=0.860, loss=33.437, backward_time=0.215, grad_norm=19.362, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.922
[seoultech:0/4] 2024-01-28 14:09:43,198 (trainer:753) INFO: 9epoch:train:3607-4207batch: iter_time=2.776e-04, forward_time=0.164, loss_ctc=50.452, loss_att=23.899, acc=0.859, loss=31.865, backward_time=0.171, grad_norm=19.626, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.880
[seoultech:0/4] 2024-01-28 14:14:33,584 (trainer:753) INFO: 9epoch:train:4208-4808batch: iter_time=2.805e-04, forward_time=0.150, loss_ctc=52.516, loss_att=24.956, acc=0.860, loss=33.224, backward_time=0.208, grad_norm=20.002, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.932
[seoultech:0/4] 2024-01-28 14:19:25,384 (trainer:753) INFO: 9epoch:train:4809-5409batch: iter_time=2.739e-04, forward_time=0.149, loss_ctc=49.767, loss_att=23.512, acc=0.858, loss=31.389, backward_time=0.213, grad_norm=19.775, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.941
[seoultech:0/4] 2024-01-28 14:24:13,544 (trainer:753) INFO: 9epoch:train:5410-6010batch: iter_time=2.596e-04, forward_time=0.152, loss_ctc=49.752, loss_att=23.429, acc=0.860, loss=31.326, backward_time=0.212, grad_norm=19.266, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.038, optim0_lr0=0.002, train_time=1.917
[seoultech:0/4] 2024-01-28 14:29:04,068 (trainer:753) INFO: 9epoch:train:6011-6611batch: iter_time=2.793e-04, forward_time=0.150, loss_ctc=52.299, loss_att=24.754, acc=0.859, loss=33.017, backward_time=0.211, grad_norm=19.736, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.932
[seoultech:0/4] 2024-01-28 14:33:57,370 (trainer:753) INFO: 9epoch:train:6612-7212batch: iter_time=2.781e-04, forward_time=0.165, loss_ctc=51.408, loss_att=24.281, acc=0.860, loss=32.419, backward_time=0.174, grad_norm=19.858, clip=100.000, loss_scale=2.684e+08, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.951
[seoultech:0/4] 2024-01-28 14:38:45,306 (trainer:753) INFO: 9epoch:train:7213-7813batch: iter_time=2.777e-04, forward_time=0.170, loss_ctc=53.945, loss_att=25.487, acc=0.858, loss=34.024, backward_time=0.157, grad_norm=20.140, clip=100.000, loss_scale=2.989e+08, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.916
[seoultech:0/4] 2024-01-28 14:43:33,783 (trainer:753) INFO: 9epoch:train:7814-8414batch: iter_time=2.956e-04, forward_time=0.170, loss_ctc=52.552, loss_att=24.808, acc=0.860, loss=33.131, backward_time=0.173, grad_norm=19.594, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.919
[seoultech:0/4] 2024-01-28 14:48:32,401 (trainer:753) INFO: 9epoch:train:8415-9015batch: iter_time=2.767e-04, forward_time=0.169, loss_ctc=50.710, loss_att=23.819, acc=0.860, loss=31.886, backward_time=0.217, grad_norm=20.081, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.986
[seoultech:0/4] 2024-01-28 14:53:19,769 (trainer:753) INFO: 9epoch:train:9016-9616batch: iter_time=2.776e-04, forward_time=0.169, loss_ctc=54.524, loss_att=25.585, acc=0.859, loss=34.267, backward_time=0.193, grad_norm=20.598, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.912
[seoultech:0/4] 2024-01-28 14:58:03,604 (trainer:753) INFO: 9epoch:train:9617-10217batch: iter_time=2.803e-04, forward_time=0.168, loss_ctc=52.155, loss_att=24.530, acc=0.860, loss=32.818, backward_time=0.183, grad_norm=20.207, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.047, optim0_lr0=0.002, train_time=1.888
[seoultech:0/4] 2024-01-28 15:02:46,036 (trainer:753) INFO: 9epoch:train:10218-10818batch: iter_time=2.640e-04, forward_time=0.153, loss_ctc=52.357, loss_att=24.521, acc=0.861, loss=32.872, backward_time=0.182, grad_norm=19.846, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.879
[seoultech:0/4] 2024-01-28 15:07:27,299 (trainer:753) INFO: 9epoch:train:10819-11419batch: iter_time=2.816e-04, forward_time=0.164, loss_ctc=52.442, loss_att=24.703, acc=0.861, loss=33.025, backward_time=0.189, grad_norm=20.421, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.871
[seoultech:0/4] 2024-01-28 15:12:16,256 (trainer:753) INFO: 9epoch:train:11420-12020batch: iter_time=2.760e-04, forward_time=0.168, loss_ctc=52.123, loss_att=24.526, acc=0.862, loss=32.805, backward_time=0.189, grad_norm=20.158, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.922
[seoultech:0/4] 2024-01-28 15:24:11,658 (trainer:352) INFO: 9epoch results: [train] iter_time=3.392e-04, forward_time=0.161, loss_ctc=51.518, loss_att=24.334, acc=0.860, loss=32.489, backward_time=0.192, grad_norm=19.744, clip=100.000, loss_scale=3.641e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.927, time=1 hour, 36 minutes and 40.41 seconds, total_count=108297, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=22.331, cer_ctc=0.151, loss_att=10.286, acc=0.931, cer=0.092, wer=0.255, loss=13.900, time=10 minutes and 1.94 seconds, total_count=13806, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 45.42 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 15:24:19,010 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 15:24:19,011 (trainer:286) INFO: 10/50epoch started. Estimated time to finish: 3 days, 1 hour and 21 minutes
[seoultech:0/4] 2024-01-28 15:29:47,871 (trainer:753) INFO: 10epoch:train:1-601batch: iter_time=0.001, forward_time=0.166, loss_ctc=51.462, loss_att=24.098, acc=0.860, loss=32.307, backward_time=0.216, grad_norm=20.656, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=2.188
[seoultech:0/4] 2024-01-28 15:34:22,649 (trainer:753) INFO: 10epoch:train:602-1202batch: iter_time=2.635e-04, forward_time=0.144, loss_ctc=49.438, loss_att=23.171, acc=0.861, loss=31.051, backward_time=0.176, grad_norm=19.507, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.829
[seoultech:0/4] 2024-01-28 15:39:12,140 (trainer:753) INFO: 10epoch:train:1203-1803batch: iter_time=2.592e-04, forward_time=0.139, loss_ctc=51.718, loss_att=24.276, acc=0.863, loss=32.509, backward_time=0.209, grad_norm=19.205, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.925
[seoultech:0/4] 2024-01-28 15:44:01,121 (trainer:753) INFO: 10epoch:train:1804-2404batch: iter_time=2.685e-04, forward_time=0.149, loss_ctc=53.586, loss_att=25.175, acc=0.862, loss=33.698, backward_time=0.213, grad_norm=19.750, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.922
[seoultech:0/4] 2024-01-28 15:48:38,889 (trainer:753) INFO: 10epoch:train:2405-3005batch: iter_time=2.576e-04, forward_time=0.150, loss_ctc=51.284, loss_att=24.135, acc=0.859, loss=32.280, backward_time=0.152, grad_norm=20.396, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.037, optim0_lr0=0.002, train_time=1.849
[seoultech:0/4] 2024-01-28 15:53:20,978 (trainer:753) INFO: 10epoch:train:3006-3606batch: iter_time=2.649e-04, forward_time=0.162, loss_ctc=52.828, loss_att=24.711, acc=0.861, loss=33.146, backward_time=0.154, grad_norm=20.687, clip=100.000, loss_scale=5.369e+08, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.877
[seoultech:0/4] 2024-01-28 15:58:02,729 (trainer:753) INFO: 10epoch:train:3607-4207batch: iter_time=2.729e-04, forward_time=0.168, loss_ctc=50.909, loss_att=23.820, acc=0.861, loss=31.946, backward_time=0.154, grad_norm=19.672, clip=100.000, loss_scale=9.771e+08, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.873
[seoultech:0/4] 2024-01-28 16:02:42,541 (trainer:753) INFO: 10epoch:train:4208-4808batch: iter_time=2.804e-04, forward_time=0.160, loss_ctc=51.352, loss_att=24.033, acc=0.862, loss=32.228, backward_time=0.155, grad_norm=19.767, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.862
[seoultech:0/4] 2024-01-28 16:07:25,554 (trainer:753) INFO: 10epoch:train:4809-5409batch: iter_time=2.579e-04, forward_time=0.146, loss_ctc=50.300, loss_att=23.529, acc=0.861, loss=31.560, backward_time=0.154, grad_norm=19.657, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.038, optim0_lr0=0.002, train_time=1.883
[seoultech:0/4] 2024-01-28 16:12:09,019 (trainer:753) INFO: 10epoch:train:5410-6010batch: iter_time=2.539e-04, forward_time=0.152, loss_ctc=49.644, loss_att=23.227, acc=0.863, loss=31.152, backward_time=0.173, grad_norm=19.249, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.039, optim0_lr0=0.002, train_time=1.885
[seoultech:0/4] 2024-01-28 16:17:02,729 (trainer:753) INFO: 10epoch:train:6011-6611batch: iter_time=2.701e-04, forward_time=0.163, loss_ctc=52.229, loss_att=24.481, acc=0.863, loss=32.806, backward_time=0.215, grad_norm=20.718, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.954
[seoultech:0/4] 2024-01-28 16:21:57,846 (trainer:753) INFO: 10epoch:train:6612-7212batch: iter_time=2.723e-04, forward_time=0.157, loss_ctc=48.586, loss_att=22.827, acc=0.861, loss=30.555, backward_time=0.216, grad_norm=19.849, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.963
[seoultech:0/4] 2024-01-28 16:26:36,307 (trainer:753) INFO: 10epoch:train:7213-7813batch: iter_time=2.725e-04, forward_time=0.166, loss_ctc=52.603, loss_att=24.619, acc=0.863, loss=33.014, backward_time=0.183, grad_norm=20.344, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.047, optim0_lr0=0.002, train_time=1.853
[seoultech:0/4] 2024-01-28 16:31:26,732 (trainer:753) INFO: 10epoch:train:7814-8414batch: iter_time=2.712e-04, forward_time=0.161, loss_ctc=48.842, loss_att=22.841, acc=0.862, loss=30.641, backward_time=0.175, grad_norm=19.265, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.931
[seoultech:0/4] 2024-01-28 16:36:14,861 (trainer:753) INFO: 10epoch:train:8415-9015batch: iter_time=2.737e-04, forward_time=0.159, loss_ctc=53.531, loss_att=24.982, acc=0.863, loss=33.546, backward_time=0.179, grad_norm=20.976, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.916
[seoultech:0/4] 2024-01-28 16:40:54,752 (trainer:753) INFO: 10epoch:train:9016-9616batch: iter_time=2.860e-04, forward_time=0.158, loss_ctc=47.115, loss_att=22.030, acc=0.860, loss=29.555, backward_time=0.179, grad_norm=18.865, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.863
[seoultech:0/4] 2024-01-28 16:45:48,870 (trainer:753) INFO: 10epoch:train:9617-10217batch: iter_time=2.666e-04, forward_time=0.151, loss_ctc=52.003, loss_att=24.353, acc=0.862, loss=32.648, backward_time=0.216, grad_norm=20.192, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.957
[seoultech:0/4] 2024-01-28 16:50:32,844 (trainer:753) INFO: 10epoch:train:10218-10818batch: iter_time=2.601e-04, forward_time=0.159, loss_ctc=52.695, loss_att=24.628, acc=0.863, loss=33.048, backward_time=0.172, grad_norm=20.208, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.889
[seoultech:0/4] 2024-01-28 16:55:10,075 (trainer:753) INFO: 10epoch:train:10819-11419batch: iter_time=2.655e-04, forward_time=0.158, loss_ctc=50.066, loss_att=23.385, acc=0.863, loss=31.389, backward_time=0.158, grad_norm=19.108, clip=100.000, loss_scale=1.074e+09, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.844
[seoultech:0/4] 2024-01-28 16:59:55,068 (trainer:753) INFO: 10epoch:train:11420-12020batch: iter_time=2.654e-04, forward_time=0.161, loss_ctc=52.031, loss_att=24.292, acc=0.862, loss=32.614, backward_time=0.153, grad_norm=20.076, clip=100.000, loss_scale=1.621e+09, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.896
[seoultech:0/4] 2024-01-28 17:12:00,938 (trainer:352) INFO: 10epoch results: [train] iter_time=3.289e-04, forward_time=0.156, loss_ctc=51.050, loss_att=23.902, acc=0.862, loss=32.046, backward_time=0.180, grad_norm=19.903, clip=100.000, loss_scale=9.367e+08, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.908, time=1 hour, 35 minutes and 43.61 seconds, total_count=120330, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=21.985, cer_ctc=0.148, loss_att=10.229, acc=0.932, cer=0.092, wer=0.253, loss=13.756, time=10 minutes and 21.06 seconds, total_count=15340, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 37.25 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 17:12:08,192 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 17:12:08,193 (trainer:286) INFO: 11/50epoch started. Estimated time to finish: 2 days, 23 hours and 36 minutes
[seoultech:0/4] 2024-01-28 17:17:28,036 (trainer:753) INFO: 11epoch:train:1-601batch: iter_time=0.001, forward_time=0.154, loss_ctc=50.371, loss_att=23.546, acc=0.864, loss=31.593, backward_time=0.158, grad_norm=19.090, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.041, optim0_lr0=0.002, train_time=2.128
[seoultech:0/4] 2024-01-28 17:22:10,317 (trainer:753) INFO: 11epoch:train:602-1202batch: iter_time=2.424e-04, forward_time=0.140, loss_ctc=48.763, loss_att=22.670, acc=0.864, loss=30.498, backward_time=0.157, grad_norm=19.305, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.036, optim0_lr0=0.002, train_time=1.879
[seoultech:0/4] 2024-01-28 17:26:45,464 (trainer:753) INFO: 11epoch:train:1203-1803batch: iter_time=2.749e-04, forward_time=0.169, loss_ctc=51.200, loss_att=23.965, acc=0.864, loss=32.136, backward_time=0.156, grad_norm=19.309, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.830
[seoultech:0/4] 2024-01-28 17:31:22,800 (trainer:753) INFO: 11epoch:train:1804-2404batch: iter_time=2.709e-04, forward_time=0.168, loss_ctc=49.943, loss_att=23.326, acc=0.863, loss=31.311, backward_time=0.152, grad_norm=20.574, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.844
[seoultech:0/4] 2024-01-28 17:35:56,014 (trainer:753) INFO: 11epoch:train:2405-3005batch: iter_time=2.946e-04, forward_time=0.150, loss_ctc=49.769, loss_att=23.225, acc=0.863, loss=31.188, backward_time=0.155, grad_norm=19.648, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.818
[seoultech:0/4] 2024-01-28 17:40:35,840 (trainer:753) INFO: 11epoch:train:3006-3606batch: iter_time=2.748e-04, forward_time=0.155, loss_ctc=49.619, loss_att=23.292, acc=0.865, loss=31.190, backward_time=0.184, grad_norm=18.400, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.862
[seoultech:0/4] 2024-01-28 17:45:09,618 (trainer:753) INFO: 11epoch:train:3607-4207batch: iter_time=2.814e-04, forward_time=0.153, loss_ctc=51.353, loss_att=23.993, acc=0.866, loss=32.201, backward_time=0.159, grad_norm=19.264, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.821
[seoultech:0/4] 2024-01-28 17:50:00,363 (trainer:753) INFO: 11epoch:train:4208-4808batch: iter_time=2.786e-04, forward_time=0.148, loss_ctc=49.982, loss_att=23.217, acc=0.864, loss=31.246, backward_time=0.204, grad_norm=19.614, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.934
[seoultech:0/4] 2024-01-28 17:54:33,893 (trainer:753) INFO: 11epoch:train:4809-5409batch: iter_time=2.924e-04, forward_time=0.162, loss_ctc=52.171, loss_att=24.401, acc=0.865, loss=32.732, backward_time=0.158, grad_norm=21.314, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.820
[seoultech:0/4] 2024-01-28 17:59:09,374 (trainer:753) INFO: 11epoch:train:5410-6010batch: iter_time=2.777e-04, forward_time=0.165, loss_ctc=48.971, loss_att=22.767, acc=0.864, loss=30.628, backward_time=0.184, grad_norm=19.156, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.832
[seoultech:0/4] 2024-01-28 18:03:58,764 (trainer:753) INFO: 11epoch:train:6011-6611batch: iter_time=2.709e-04, forward_time=0.168, loss_ctc=51.890, loss_att=24.267, acc=0.863, loss=32.554, backward_time=0.207, grad_norm=19.898, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.924
[seoultech:0/4] 2024-01-28 18:08:50,920 (trainer:753) INFO: 11epoch:train:6612-7212batch: iter_time=2.738e-04, forward_time=0.167, loss_ctc=53.193, loss_att=24.677, acc=0.864, loss=33.232, backward_time=0.215, grad_norm=20.613, clip=100.000, loss_scale=2.147e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.944
[seoultech:0/4] 2024-01-28 18:13:38,647 (trainer:753) INFO: 11epoch:train:7213-7813batch: iter_time=2.921e-04, forward_time=0.167, loss_ctc=49.540, loss_att=23.117, acc=0.864, loss=31.044, backward_time=0.214, grad_norm=19.556, clip=100.000, loss_scale=2.620e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.915
[seoultech:0/4] 2024-01-28 18:18:24,201 (trainer:753) INFO: 11epoch:train:7814-8414batch: iter_time=2.818e-04, forward_time=0.156, loss_ctc=47.745, loss_att=22.204, acc=0.864, loss=29.866, backward_time=0.196, grad_norm=20.028, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.900
[seoultech:0/4] 2024-01-28 18:23:13,381 (trainer:753) INFO: 11epoch:train:8415-9015batch: iter_time=2.857e-04, forward_time=0.154, loss_ctc=49.353, loss_att=22.977, acc=0.864, loss=30.889, backward_time=0.205, grad_norm=18.896, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.047, optim0_lr0=0.002, train_time=1.923
[seoultech:0/4] 2024-01-28 18:28:00,623 (trainer:753) INFO: 11epoch:train:9016-9616batch: iter_time=2.881e-04, forward_time=0.163, loss_ctc=50.194, loss_att=23.125, acc=0.863, loss=31.246, backward_time=0.212, grad_norm=20.158, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.911
[seoultech:0/4] 2024-01-28 18:32:53,282 (trainer:753) INFO: 11epoch:train:9617-10217batch: iter_time=2.668e-04, forward_time=0.167, loss_ctc=51.755, loss_att=24.034, acc=0.864, loss=32.351, backward_time=0.215, grad_norm=20.231, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.948
[seoultech:0/4] 2024-01-28 18:37:33,771 (trainer:753) INFO: 11epoch:train:10218-10818batch: iter_time=2.755e-04, forward_time=0.169, loss_ctc=50.795, loss_att=23.640, acc=0.866, loss=31.786, backward_time=0.160, grad_norm=19.821, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.865
[seoultech:0/4] 2024-01-28 18:42:20,378 (trainer:753) INFO: 11epoch:train:10819-11419batch: iter_time=2.704e-04, forward_time=0.170, loss_ctc=50.111, loss_att=23.336, acc=0.864, loss=31.369, backward_time=0.156, grad_norm=20.753, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.907
[seoultech:0/4] 2024-01-28 18:47:04,425 (trainer:753) INFO: 11epoch:train:11420-12020batch: iter_time=2.752e-04, forward_time=0.164, loss_ctc=50.117, loss_att=23.354, acc=0.864, loss=31.383, backward_time=0.183, grad_norm=20.908, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.889
[seoultech:0/4] 2024-01-28 18:59:17,625 (trainer:352) INFO: 11epoch results: [train] iter_time=3.144e-04, forward_time=0.160, loss_ctc=50.325, loss_att=23.448, acc=0.864, loss=31.511, backward_time=0.182, grad_norm=19.824, clip=100.000, loss_scale=2.924e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.895, time=1 hour, 35 minutes and 3.71 seconds, total_count=132363, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=21.688, cer_ctc=0.147, loss_att=9.801, acc=0.933, cer=0.089, wer=0.249, loss=13.367, time=10 minutes and 20.34 seconds, total_count=16874, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 45.38 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 18:59:27,488 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 18:59:27,498 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/1epoch.pth
[seoultech:0/4] 2024-01-28 18:59:27,499 (trainer:286) INFO: 12/50epoch started. Estimated time to finish: 2 days, 21 hours and 48 minutes
[seoultech:0/4] 2024-01-28 19:04:47,136 (trainer:753) INFO: 12epoch:train:1-601batch: iter_time=0.002, forward_time=0.149, loss_ctc=50.940, loss_att=23.671, acc=0.866, loss=31.852, backward_time=0.185, grad_norm=19.885, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.040, optim0_lr0=0.002, train_time=2.127
[seoultech:0/4] 2024-01-28 19:09:31,905 (trainer:753) INFO: 12epoch:train:602-1202batch: iter_time=2.685e-04, forward_time=0.152, loss_ctc=46.024, loss_att=21.419, acc=0.865, loss=28.801, backward_time=0.215, grad_norm=18.709, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.895
[seoultech:0/4] 2024-01-28 19:14:20,910 (trainer:753) INFO: 12epoch:train:1203-1803batch: iter_time=2.721e-04, forward_time=0.167, loss_ctc=51.661, loss_att=23.903, acc=0.866, loss=32.231, backward_time=0.214, grad_norm=20.988, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.923
[seoultech:0/4] 2024-01-28 19:19:10,059 (trainer:753) INFO: 12epoch:train:1804-2404batch: iter_time=2.714e-04, forward_time=0.168, loss_ctc=47.536, loss_att=22.167, acc=0.864, loss=29.778, backward_time=0.213, grad_norm=20.016, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.923
[seoultech:0/4] 2024-01-28 19:23:59,642 (trainer:753) INFO: 12epoch:train:2405-3005batch: iter_time=2.630e-04, forward_time=0.155, loss_ctc=49.654, loss_att=22.992, acc=0.866, loss=30.991, backward_time=0.215, grad_norm=19.828, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.927
[seoultech:0/4] 2024-01-28 19:28:49,725 (trainer:753) INFO: 12epoch:train:3006-3606batch: iter_time=2.906e-04, forward_time=0.168, loss_ctc=50.478, loss_att=23.358, acc=0.865, loss=31.494, backward_time=0.196, grad_norm=19.501, clip=100.000, loss_scale=4.295e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.930
[seoultech:0/4] 2024-01-28 19:33:35,347 (trainer:753) INFO: 12epoch:train:3607-4207batch: iter_time=2.672e-04, forward_time=0.145, loss_ctc=47.711, loss_att=22.215, acc=0.865, loss=29.864, backward_time=0.208, grad_norm=18.077, clip=100.000, loss_scale=8.275e+09, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.901
[seoultech:0/4] 2024-01-28 19:38:19,405 (trainer:753) INFO: 12epoch:train:4208-4808batch: iter_time=2.658e-04, forward_time=0.153, loss_ctc=48.571, loss_att=22.521, acc=0.866, loss=30.336, backward_time=0.207, grad_norm=20.567, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.889
[seoultech:0/4] 2024-01-28 19:42:55,491 (trainer:753) INFO: 12epoch:train:4809-5409batch: iter_time=2.828e-04, forward_time=0.168, loss_ctc=52.264, loss_att=24.193, acc=0.866, loss=32.614, backward_time=0.191, grad_norm=20.284, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.837
[seoultech:0/4] 2024-01-28 19:47:41,605 (trainer:753) INFO: 12epoch:train:5410-6010batch: iter_time=2.747e-04, forward_time=0.159, loss_ctc=49.984, loss_att=23.108, acc=0.867, loss=31.171, backward_time=0.178, grad_norm=19.911, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.903
[seoultech:0/4] 2024-01-28 19:52:21,642 (trainer:753) INFO: 12epoch:train:6011-6611batch: iter_time=2.583e-04, forward_time=0.153, loss_ctc=49.049, loss_att=22.788, acc=0.866, loss=30.666, backward_time=0.152, grad_norm=20.400, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.039, optim0_lr0=0.002, train_time=1.863
[seoultech:0/4] 2024-01-28 19:57:06,536 (trainer:753) INFO: 12epoch:train:6612-7212batch: iter_time=2.697e-04, forward_time=0.161, loss_ctc=50.307, loss_att=23.363, acc=0.865, loss=31.446, backward_time=0.176, grad_norm=22.499, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.895
[seoultech:0/4] 2024-01-28 20:01:48,889 (trainer:753) INFO: 12epoch:train:7213-7813batch: iter_time=2.686e-04, forward_time=0.143, loss_ctc=51.469, loss_att=23.837, acc=0.866, loss=32.126, backward_time=0.155, grad_norm=20.079, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.038, optim0_lr0=0.002, train_time=1.878
[seoultech:0/4] 2024-01-28 20:06:40,868 (trainer:753) INFO: 12epoch:train:7814-8414batch: iter_time=2.669e-04, forward_time=0.151, loss_ctc=51.070, loss_att=23.628, acc=0.866, loss=31.861, backward_time=0.176, grad_norm=20.570, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.943
[seoultech:0/4] 2024-01-28 20:11:25,804 (trainer:753) INFO: 12epoch:train:8415-9015batch: iter_time=2.631e-04, forward_time=0.166, loss_ctc=51.181, loss_att=23.698, acc=0.866, loss=31.943, backward_time=0.156, grad_norm=20.201, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.896
[seoultech:0/4] 2024-01-28 20:16:22,305 (trainer:753) INFO: 12epoch:train:9016-9616batch: iter_time=2.735e-04, forward_time=0.163, loss_ctc=50.081, loss_att=23.238, acc=0.865, loss=31.291, backward_time=0.205, grad_norm=19.522, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.971
[seoultech:0/4] 2024-01-28 20:21:15,799 (trainer:753) INFO: 12epoch:train:9617-10217batch: iter_time=2.838e-04, forward_time=0.160, loss_ctc=50.071, loss_att=23.231, acc=0.865, loss=31.283, backward_time=0.218, grad_norm=20.538, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.953
[seoultech:0/4] 2024-01-28 20:25:54,740 (trainer:753) INFO: 12epoch:train:10218-10818batch: iter_time=2.455e-04, forward_time=0.144, loss_ctc=52.709, loss_att=24.313, acc=0.865, loss=32.831, backward_time=0.167, grad_norm=21.082, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.037, optim0_lr0=0.002, train_time=1.856
[seoultech:0/4] 2024-01-28 20:30:31,780 (trainer:753) INFO: 12epoch:train:10819-11419batch: iter_time=2.644e-04, forward_time=0.150, loss_ctc=48.337, loss_att=22.494, acc=0.865, loss=30.247, backward_time=0.168, grad_norm=19.396, clip=100.000, loss_scale=8.590e+09, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.843
[seoultech:0/4] 2024-01-28 20:35:24,111 (trainer:753) INFO: 12epoch:train:11420-12020batch: iter_time=2.691e-04, forward_time=0.170, loss_ctc=52.618, loss_att=24.413, acc=0.867, loss=32.874, backward_time=0.195, grad_norm=20.895, clip=100.000, loss_scale=1.388e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.944
[seoultech:0/4] 2024-01-28 20:47:22,356 (trainer:352) INFO: 12epoch results: [train] iter_time=3.399e-04, forward_time=0.157, loss_ctc=50.041, loss_att=23.208, acc=0.866, loss=31.258, backward_time=0.189, grad_norm=20.146, clip=100.000, loss_scale=7.562e+09, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.915, time=1 hour, 36 minutes and 4.74 seconds, total_count=144396, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=21.725, cer_ctc=0.146, loss_att=9.871, acc=0.933, cer=0.089, wer=0.248, loss=13.427, time=10 minutes and 25.25 seconds, total_count=18408, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 24.87 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 20:47:29,404 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 20:47:29,415 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/2epoch.pth
[seoultech:0/4] 2024-01-28 20:47:29,416 (trainer:286) INFO: 13/50epoch started. Estimated time to finish: 2 days, 20 hours and 3 minutes
[seoultech:0/4] 2024-01-28 20:52:54,308 (trainer:753) INFO: 13epoch:train:1-601batch: iter_time=0.001, forward_time=0.164, loss_ctc=50.580, loss_att=23.330, acc=0.865, loss=31.505, backward_time=0.211, grad_norm=21.013, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=2.162
[seoultech:0/4] 2024-01-28 20:57:38,242 (trainer:753) INFO: 13epoch:train:602-1202batch: iter_time=2.801e-04, forward_time=0.150, loss_ctc=49.672, loss_att=22.901, acc=0.866, loss=30.932, backward_time=0.211, grad_norm=21.052, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.889
[seoultech:0/4] 2024-01-28 21:02:16,572 (trainer:753) INFO: 13epoch:train:1203-1803batch: iter_time=2.769e-04, forward_time=0.152, loss_ctc=49.868, loss_att=23.070, acc=0.867, loss=31.109, backward_time=0.213, grad_norm=19.303, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-28 21:06:53,070 (trainer:753) INFO: 13epoch:train:1804-2404batch: iter_time=2.811e-04, forward_time=0.163, loss_ctc=54.297, loss_att=25.092, acc=0.868, loss=33.854, backward_time=0.180, grad_norm=22.114, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.839
[seoultech:0/4] 2024-01-28 21:11:29,524 (trainer:753) INFO: 13epoch:train:2405-3005batch: iter_time=2.735e-04, forward_time=0.153, loss_ctc=50.643, loss_att=23.336, acc=0.864, loss=31.528, backward_time=0.149, grad_norm=21.990, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.840
[seoultech:0/4] 2024-01-28 21:16:10,955 (trainer:753) INFO: 13epoch:train:3006-3606batch: iter_time=3.003e-04, forward_time=0.163, loss_ctc=51.118, loss_att=23.522, acc=0.866, loss=31.801, backward_time=0.187, grad_norm=20.202, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.872
[seoultech:0/4] 2024-01-28 21:20:47,982 (trainer:753) INFO: 13epoch:train:3607-4207batch: iter_time=2.704e-04, forward_time=0.149, loss_ctc=52.111, loss_att=23.995, acc=0.867, loss=32.430, backward_time=0.157, grad_norm=21.706, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.843
[seoultech:0/4] 2024-01-28 21:25:26,425 (trainer:753) INFO: 13epoch:train:4208-4808batch: iter_time=2.786e-04, forward_time=0.164, loss_ctc=51.773, loss_att=23.895, acc=0.866, loss=32.259, backward_time=0.169, grad_norm=21.581, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-28 21:30:02,398 (trainer:753) INFO: 13epoch:train:4809-5409batch: iter_time=2.728e-04, forward_time=0.159, loss_ctc=51.767, loss_att=23.878, acc=0.865, loss=32.245, backward_time=0.165, grad_norm=21.129, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.836
[seoultech:0/4] 2024-01-28 21:34:40,706 (trainer:753) INFO: 13epoch:train:5410-6010batch: iter_time=2.846e-04, forward_time=0.161, loss_ctc=50.017, loss_att=23.144, acc=0.868, loss=31.206, backward_time=0.156, grad_norm=20.159, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.851
[seoultech:0/4] 2024-01-28 21:39:24,767 (trainer:753) INFO: 13epoch:train:6011-6611batch: iter_time=2.763e-04, forward_time=0.158, loss_ctc=50.457, loss_att=23.300, acc=0.866, loss=31.447, backward_time=0.184, grad_norm=21.159, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.891
[seoultech:0/4] 2024-01-28 21:44:09,204 (trainer:753) INFO: 13epoch:train:6612-7212batch: iter_time=2.765e-04, forward_time=0.153, loss_ctc=48.904, loss_att=22.561, acc=0.865, loss=30.464, backward_time=0.159, grad_norm=21.503, clip=100.000, loss_scale=1.718e+10, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.892
[seoultech:0/4] 2024-01-28 21:48:58,885 (trainer:753) INFO: 13epoch:train:7213-7813batch: iter_time=2.718e-04, forward_time=0.163, loss_ctc=49.496, loss_att=22.845, acc=0.867, loss=30.841, backward_time=0.195, grad_norm=19.379, clip=100.000, loss_scale=2.279e+10, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.927
[seoultech:0/4] 2024-01-28 21:54:02,960 (trainer:753) INFO: 13epoch:train:7814-8414batch: iter_time=2.659e-04, forward_time=0.162, loss_ctc=49.727, loss_att=23.042, acc=0.867, loss=31.048, backward_time=0.219, grad_norm=19.529, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.042, optim0_lr0=0.002, train_time=2.023
[seoultech:0/4] 2024-01-28 21:58:55,206 (trainer:753) INFO: 13epoch:train:8415-9015batch: iter_time=2.772e-04, forward_time=0.166, loss_ctc=49.043, loss_att=22.622, acc=0.868, loss=30.548, backward_time=0.172, grad_norm=19.552, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.946
[seoultech:0/4] 2024-01-28 22:03:42,711 (trainer:753) INFO: 13epoch:train:9016-9616batch: iter_time=2.733e-04, forward_time=0.155, loss_ctc=48.649, loss_att=22.434, acc=0.865, loss=30.298, backward_time=0.154, grad_norm=21.243, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.911
[seoultech:0/4] 2024-01-28 22:08:38,056 (trainer:753) INFO: 13epoch:train:9617-10217batch: iter_time=2.680e-04, forward_time=0.160, loss_ctc=48.352, loss_att=22.388, acc=0.865, loss=30.177, backward_time=0.210, grad_norm=20.595, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.965
[seoultech:0/4] 2024-01-28 22:13:26,907 (trainer:753) INFO: 13epoch:train:10218-10818batch: iter_time=2.730e-04, forward_time=0.170, loss_ctc=45.757, loss_att=21.137, acc=0.866, loss=28.523, backward_time=0.187, grad_norm=19.776, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.047, optim0_lr0=0.002, train_time=1.922
[seoultech:0/4] 2024-01-28 22:18:24,899 (trainer:753) INFO: 13epoch:train:10819-11419batch: iter_time=2.758e-04, forward_time=0.172, loss_ctc=49.436, loss_att=22.793, acc=0.865, loss=30.786, backward_time=0.173, grad_norm=20.732, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.983
[seoultech:0/4] 2024-01-28 22:23:13,241 (trainer:753) INFO: 13epoch:train:11420-12020batch: iter_time=2.737e-04, forward_time=0.169, loss_ctc=49.481, loss_att=22.858, acc=0.865, loss=30.845, backward_time=0.164, grad_norm=20.040, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.917
[seoultech:0/4] 2024-01-28 22:34:50,326 (trainer:352) INFO: 13epoch results: [train] iter_time=3.316e-04, forward_time=0.160, loss_ctc=50.017, loss_att=23.089, acc=0.866, loss=31.168, backward_time=0.181, grad_norm=20.692, clip=100.000, loss_scale=2.349e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.911, time=1 hour, 35 minutes and 52.6 seconds, total_count=156429, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=21.632, cer_ctc=0.147, loss_att=9.787, acc=0.934, cer=0.089, wer=0.248, loss=13.340, time=10 minutes and 8.45 seconds, total_count=19942, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 19.86 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-28 22:34:58,816 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-28 22:34:58,823 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/3epoch.pth
[seoultech:0/4] 2024-01-28 22:34:58,823 (trainer:286) INFO: 14/50epoch started. Estimated time to finish: 2 days, 18 hours and 15 minutes
[seoultech:0/4] 2024-01-28 22:40:27,522 (trainer:753) INFO: 14epoch:train:1-601batch: iter_time=0.001, forward_time=0.135, loss_ctc=50.146, loss_att=23.047, acc=0.867, loss=31.177, backward_time=0.197, grad_norm=21.385, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.041, optim0_lr0=0.002, train_time=2.187
[seoultech:0/4] 2024-01-28 22:45:10,513 (trainer:753) INFO: 14epoch:train:602-1202batch: iter_time=2.582e-04, forward_time=0.145, loss_ctc=49.283, loss_att=22.682, acc=0.867, loss=30.662, backward_time=0.150, grad_norm=19.510, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.037, optim0_lr0=0.002, train_time=1.883
[seoultech:0/4] 2024-01-28 22:49:56,383 (trainer:753) INFO: 14epoch:train:1203-1803batch: iter_time=2.662e-04, forward_time=0.161, loss_ctc=52.314, loss_att=24.090, acc=0.866, loss=32.558, backward_time=0.179, grad_norm=20.355, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.902
[seoultech:0/4] 2024-01-28 22:54:26,954 (trainer:753) INFO: 14epoch:train:1804-2404batch: iter_time=2.687e-04, forward_time=0.152, loss_ctc=51.626, loss_att=23.751, acc=0.869, loss=32.114, backward_time=0.171, grad_norm=20.627, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.800
[seoultech:0/4] 2024-01-28 22:58:54,194 (trainer:753) INFO: 14epoch:train:2405-3005batch: iter_time=2.746e-04, forward_time=0.151, loss_ctc=49.054, loss_att=22.550, acc=0.866, loss=30.501, backward_time=0.175, grad_norm=21.114, clip=100.000, loss_scale=3.436e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.778
[seoultech:0/4] 2024-01-28 23:03:35,029 (trainer:753) INFO: 14epoch:train:3006-3606batch: iter_time=2.725e-04, forward_time=0.147, loss_ctc=51.429, loss_att=23.642, acc=0.867, loss=31.978, backward_time=0.172, grad_norm=20.833, clip=100.000, loss_scale=3.551e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.869
[seoultech:0/4] 2024-01-28 23:08:24,776 (trainer:753) INFO: 14epoch:train:3607-4207batch: iter_time=2.723e-04, forward_time=0.144, loss_ctc=49.982, loss_att=23.038, acc=0.868, loss=31.121, backward_time=0.216, grad_norm=20.041, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.928
[seoultech:0/4] 2024-01-28 23:13:02,148 (trainer:753) INFO: 14epoch:train:4208-4808batch: iter_time=2.811e-04, forward_time=0.150, loss_ctc=50.434, loss_att=23.257, acc=0.868, loss=31.410, backward_time=0.184, grad_norm=19.626, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.845
[seoultech:0/4] 2024-01-28 23:17:41,938 (trainer:753) INFO: 14epoch:train:4809-5409batch: iter_time=2.776e-04, forward_time=0.162, loss_ctc=47.492, loss_att=21.970, acc=0.868, loss=29.627, backward_time=0.160, grad_norm=19.235, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.861
[seoultech:0/4] 2024-01-28 23:22:23,685 (trainer:753) INFO: 14epoch:train:5410-6010batch: iter_time=2.680e-04, forward_time=0.154, loss_ctc=47.010, loss_att=21.596, acc=0.866, loss=29.220, backward_time=0.174, grad_norm=19.137, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.875
[seoultech:0/4] 2024-01-28 23:27:14,103 (trainer:753) INFO: 14epoch:train:6011-6611batch: iter_time=2.770e-04, forward_time=0.145, loss_ctc=46.135, loss_att=21.327, acc=0.867, loss=28.770, backward_time=0.217, grad_norm=19.107, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.932
[seoultech:0/4] 2024-01-28 23:32:05,824 (trainer:753) INFO: 14epoch:train:6612-7212batch: iter_time=2.724e-04, forward_time=0.152, loss_ctc=50.172, loss_att=23.098, acc=0.868, loss=31.220, backward_time=0.215, grad_norm=22.131, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.940
[seoultech:0/4] 2024-01-28 23:36:55,753 (trainer:753) INFO: 14epoch:train:7213-7813batch: iter_time=2.711e-04, forward_time=0.161, loss_ctc=51.439, loss_att=23.587, acc=0.869, loss=31.942, backward_time=0.188, grad_norm=20.712, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.929
[seoultech:0/4] 2024-01-28 23:41:49,326 (trainer:753) INFO: 14epoch:train:7814-8414batch: iter_time=2.817e-04, forward_time=0.168, loss_ctc=48.831, loss_att=22.428, acc=0.869, loss=30.349, backward_time=0.200, grad_norm=20.262, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.953
[seoultech:0/4] 2024-01-28 23:46:31,715 (trainer:753) INFO: 14epoch:train:8415-9015batch: iter_time=2.728e-04, forward_time=0.171, loss_ctc=50.412, loss_att=23.231, acc=0.869, loss=31.385, backward_time=0.174, grad_norm=20.387, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.878
[seoultech:0/4] 2024-01-28 23:51:17,953 (trainer:753) INFO: 14epoch:train:9016-9616batch: iter_time=2.778e-04, forward_time=0.172, loss_ctc=47.391, loss_att=21.833, acc=0.867, loss=29.501, backward_time=0.190, grad_norm=19.953, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.904
[seoultech:0/4] 2024-01-28 23:56:00,043 (trainer:753) INFO: 14epoch:train:9617-10217batch: iter_time=2.924e-04, forward_time=0.157, loss_ctc=47.070, loss_att=21.684, acc=0.869, loss=29.300, backward_time=0.203, grad_norm=19.195, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.877
[seoultech:0/4] 2024-01-29 00:00:48,244 (trainer:753) INFO: 14epoch:train:10218-10818batch: iter_time=2.734e-04, forward_time=0.163, loss_ctc=49.930, loss_att=23.042, acc=0.868, loss=31.108, backward_time=0.192, grad_norm=20.456, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.917
[seoultech:0/4] 2024-01-29 00:05:31,075 (trainer:753) INFO: 14epoch:train:10819-11419batch: iter_time=2.677e-04, forward_time=0.161, loss_ctc=49.165, loss_att=22.652, acc=0.868, loss=30.606, backward_time=0.188, grad_norm=20.771, clip=100.000, loss_scale=6.872e+10, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.883
[seoultech:0/4] 2024-01-29 00:10:09,495 (trainer:753) INFO: 14epoch:train:11420-12020batch: iter_time=2.730e-04, forward_time=0.158, loss_ctc=51.366, loss_att=23.603, acc=0.868, loss=31.932, backward_time=0.171, grad_norm=21.042, clip=100.000, loss_scale=1.183e+11, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-29 00:22:15,035 (trainer:352) INFO: 14epoch results: [train] iter_time=3.309e-04, forward_time=0.155, loss_ctc=49.469, loss_att=22.777, acc=0.868, loss=30.784, backward_time=0.186, grad_norm=20.298, clip=100.000, loss_scale=6.104e+10, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.900, time=1 hour, 35 minutes and 18.89 seconds, total_count=168462, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=21.592, cer_ctc=0.146, loss_att=9.719, acc=0.935, cer=0.088, wer=0.246, loss=13.281, time=10 minutes and 12.33 seconds, total_count=21476, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 44.99 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 00:22:22,919 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 00:22:22,930 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/4epoch.pth
[seoultech:0/4] 2024-01-29 00:22:22,930 (trainer:286) INFO: 15/50epoch started. Estimated time to finish: 2 days, 16 hours and 28 minutes
[seoultech:0/4] 2024-01-29 00:27:45,308 (trainer:753) INFO: 15epoch:train:1-601batch: iter_time=0.001, forward_time=0.155, loss_ctc=50.275, loss_att=23.075, acc=0.870, loss=31.235, backward_time=0.199, grad_norm=22.257, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=2.145
[seoultech:0/4] 2024-01-29 00:32:26,368 (trainer:753) INFO: 15epoch:train:602-1202batch: iter_time=2.727e-04, forward_time=0.160, loss_ctc=48.614, loss_att=22.284, acc=0.870, loss=30.183, backward_time=0.171, grad_norm=19.891, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.870
[seoultech:0/4] 2024-01-29 00:37:01,823 (trainer:753) INFO: 15epoch:train:1203-1803batch: iter_time=2.365e-04, forward_time=0.128, loss_ctc=47.666, loss_att=21.763, acc=0.872, loss=29.534, backward_time=0.171, grad_norm=19.231, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.028, optim0_lr0=0.002, train_time=1.833
[seoultech:0/4] 2024-01-29 00:41:48,392 (trainer:753) INFO: 15epoch:train:1804-2404batch: iter_time=2.698e-04, forward_time=0.166, loss_ctc=51.251, loss_att=23.590, acc=0.869, loss=31.888, backward_time=0.187, grad_norm=20.138, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.906
[seoultech:0/4] 2024-01-29 00:46:33,423 (trainer:753) INFO: 15epoch:train:2405-3005batch: iter_time=2.696e-04, forward_time=0.157, loss_ctc=49.952, loss_att=22.954, acc=0.870, loss=31.053, backward_time=0.201, grad_norm=19.861, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.039, optim0_lr0=0.002, train_time=1.897
[seoultech:0/4] 2024-01-29 00:51:20,060 (trainer:753) INFO: 15epoch:train:3006-3606batch: iter_time=2.731e-04, forward_time=0.165, loss_ctc=48.320, loss_att=22.117, acc=0.872, loss=29.978, backward_time=0.211, grad_norm=19.109, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.907
[seoultech:0/4] 2024-01-29 00:55:55,974 (trainer:753) INFO: 15epoch:train:3607-4207batch: iter_time=2.627e-04, forward_time=0.159, loss_ctc=49.576, loss_att=22.648, acc=0.872, loss=30.727, backward_time=0.172, grad_norm=20.588, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.836
[seoultech:0/4] 2024-01-29 01:00:39,764 (trainer:753) INFO: 15epoch:train:4208-4808batch: iter_time=2.667e-04, forward_time=0.159, loss_ctc=46.913, loss_att=21.514, acc=0.870, loss=29.134, backward_time=0.211, grad_norm=18.931, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.887
[seoultech:0/4] 2024-01-29 01:05:09,309 (trainer:753) INFO: 15epoch:train:4809-5409batch: iter_time=2.776e-04, forward_time=0.161, loss_ctc=51.922, loss_att=23.815, acc=0.872, loss=32.247, backward_time=0.184, grad_norm=20.287, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.793
[seoultech:0/4] 2024-01-29 01:09:42,863 (trainer:753) INFO: 15epoch:train:5410-6010batch: iter_time=2.830e-04, forward_time=0.166, loss_ctc=47.830, loss_att=21.927, acc=0.869, loss=29.698, backward_time=0.197, grad_norm=20.558, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.820
[seoultech:0/4] 2024-01-29 01:14:34,855 (trainer:753) INFO: 15epoch:train:6011-6611batch: iter_time=2.677e-04, forward_time=0.154, loss_ctc=47.052, loss_att=21.519, acc=0.871, loss=29.179, backward_time=0.215, grad_norm=19.880, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.943
[seoultech:0/4] 2024-01-29 01:19:21,862 (trainer:753) INFO: 15epoch:train:6612-7212batch: iter_time=2.823e-04, forward_time=0.158, loss_ctc=46.987, loss_att=21.540, acc=0.869, loss=29.174, backward_time=0.160, grad_norm=19.842, clip=100.000, loss_scale=1.374e+11, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.909
[seoultech:0/4] 2024-01-29 01:23:55,141 (trainer:753) INFO: 15epoch:train:7213-7813batch: iter_time=2.554e-04, forward_time=0.147, loss_ctc=48.799, loss_att=22.372, acc=0.872, loss=30.300, backward_time=0.149, grad_norm=19.163, clip=100.000, loss_scale=1.970e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.818
[seoultech:0/4] 2024-01-29 01:28:36,767 (trainer:753) INFO: 15epoch:train:7814-8414batch: iter_time=2.820e-04, forward_time=0.158, loss_ctc=46.312, loss_att=21.338, acc=0.871, loss=28.830, backward_time=0.149, grad_norm=18.468, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.875
[seoultech:0/4] 2024-01-29 01:33:18,354 (trainer:753) INFO: 15epoch:train:8415-9015batch: iter_time=2.595e-04, forward_time=0.154, loss_ctc=48.277, loss_att=22.066, acc=0.871, loss=29.929, backward_time=0.149, grad_norm=20.493, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.873
[seoultech:0/4] 2024-01-29 01:38:09,719 (trainer:753) INFO: 15epoch:train:9016-9616batch: iter_time=2.729e-04, forward_time=0.154, loss_ctc=46.852, loss_att=21.454, acc=0.872, loss=29.073, backward_time=0.190, grad_norm=18.728, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.938
[seoultech:0/4] 2024-01-29 01:42:54,317 (trainer:753) INFO: 15epoch:train:9617-10217batch: iter_time=2.645e-04, forward_time=0.157, loss_ctc=45.172, loss_att=20.645, acc=0.872, loss=28.003, backward_time=0.196, grad_norm=20.731, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.893
[seoultech:0/4] 2024-01-29 01:47:35,706 (trainer:753) INFO: 15epoch:train:10218-10818batch: iter_time=2.718e-04, forward_time=0.169, loss_ctc=47.358, loss_att=21.785, acc=0.872, loss=29.457, backward_time=0.166, grad_norm=18.697, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.047, optim0_lr0=0.002, train_time=1.872
[seoultech:0/4] 2024-01-29 01:52:16,824 (trainer:753) INFO: 15epoch:train:10819-11419batch: iter_time=2.790e-04, forward_time=0.167, loss_ctc=50.329, loss_att=22.985, acc=0.873, loss=31.188, backward_time=0.156, grad_norm=20.970, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.869
[seoultech:0/4] 2024-01-29 01:56:57,011 (trainer:753) INFO: 15epoch:train:11420-12020batch: iter_time=2.802e-04, forward_time=0.162, loss_ctc=48.490, loss_att=22.191, acc=0.874, loss=30.081, backward_time=0.184, grad_norm=18.745, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.864
[seoultech:0/4] 2024-01-29 02:08:56,722 (trainer:352) INFO: 15epoch results: [train] iter_time=3.274e-04, forward_time=0.158, loss_ctc=48.357, loss_att=22.161, acc=0.871, loss=30.020, backward_time=0.181, grad_norm=19.829, clip=100.000, loss_scale=1.886e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.887, time=1 hour, 34 minutes and 42.25 seconds, total_count=180495, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=20.819, cer_ctc=0.141, loss_att=9.324, acc=0.936, cer=0.085, wer=0.241, loss=12.772, time=10 minutes and 26.28 seconds, total_count=23010, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 25.26 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 02:09:04,223 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 02:09:04,233 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/5epoch.pth
[seoultech:0/4] 2024-01-29 02:09:04,234 (trainer:286) INFO: 16/50epoch started. Estimated time to finish: 2 days, 14 hours and 38 minutes
[seoultech:0/4] 2024-01-29 02:14:32,067 (trainer:753) INFO: 16epoch:train:1-601batch: iter_time=0.001, forward_time=0.154, loss_ctc=47.583, loss_att=21.771, acc=0.874, loss=29.515, backward_time=0.215, grad_norm=19.319, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=2.181
[seoultech:0/4] 2024-01-29 02:19:17,545 (trainer:753) INFO: 16epoch:train:602-1202batch: iter_time=2.631e-04, forward_time=0.151, loss_ctc=49.904, loss_att=22.873, acc=0.875, loss=30.983, backward_time=0.197, grad_norm=19.448, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.900
[seoultech:0/4] 2024-01-29 02:23:56,340 (trainer:753) INFO: 16epoch:train:1203-1803batch: iter_time=2.626e-04, forward_time=0.140, loss_ctc=48.536, loss_att=22.182, acc=0.874, loss=30.089, backward_time=0.190, grad_norm=19.208, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.854
[seoultech:0/4] 2024-01-29 02:28:37,383 (trainer:753) INFO: 16epoch:train:1804-2404batch: iter_time=2.692e-04, forward_time=0.167, loss_ctc=47.745, loss_att=21.823, acc=0.874, loss=29.600, backward_time=0.192, grad_norm=19.814, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.870
[seoultech:0/4] 2024-01-29 02:33:13,584 (trainer:753) INFO: 16epoch:train:2405-3005batch: iter_time=2.673e-04, forward_time=0.158, loss_ctc=45.512, loss_att=20.729, acc=0.873, loss=28.164, backward_time=0.160, grad_norm=19.251, clip=100.000, loss_scale=2.749e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.838
[seoultech:0/4] 2024-01-29 02:38:02,118 (trainer:753) INFO: 16epoch:train:3006-3606batch: iter_time=2.600e-04, forward_time=0.161, loss_ctc=47.275, loss_att=21.575, acc=0.874, loss=29.285, backward_time=0.191, grad_norm=19.563, clip=100.000, loss_scale=3.134e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.920
[seoultech:0/4] 2024-01-29 02:42:47,647 (trainer:753) INFO: 16epoch:train:3607-4207batch: iter_time=2.524e-04, forward_time=0.139, loss_ctc=48.245, loss_att=21.949, acc=0.875, loss=29.838, backward_time=0.212, grad_norm=17.887, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.899
[seoultech:0/4] 2024-01-29 02:47:30,291 (trainer:753) INFO: 16epoch:train:4208-4808batch: iter_time=2.609e-04, forward_time=0.142, loss_ctc=45.069, loss_att=20.616, acc=0.873, loss=27.952, backward_time=0.179, grad_norm=18.318, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.038, optim0_lr0=0.002, train_time=1.880
[seoultech:0/4] 2024-01-29 02:52:19,207 (trainer:753) INFO: 16epoch:train:4809-5409batch: iter_time=2.980e-04, forward_time=0.167, loss_ctc=48.058, loss_att=22.005, acc=0.877, loss=29.821, backward_time=0.214, grad_norm=19.479, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.922
[seoultech:0/4] 2024-01-29 02:57:01,392 (trainer:753) INFO: 16epoch:train:5410-6010batch: iter_time=2.559e-04, forward_time=0.153, loss_ctc=45.968, loss_att=20.916, acc=0.872, loss=28.432, backward_time=0.168, grad_norm=22.276, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.877
[seoultech:0/4] 2024-01-29 03:01:52,708 (trainer:753) INFO: 16epoch:train:6011-6611batch: iter_time=2.689e-04, forward_time=0.152, loss_ctc=47.729, loss_att=21.750, acc=0.874, loss=29.543, backward_time=0.217, grad_norm=19.388, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.938
[seoultech:0/4] 2024-01-29 03:06:46,479 (trainer:753) INFO: 16epoch:train:6612-7212batch: iter_time=2.700e-04, forward_time=0.167, loss_ctc=46.645, loss_att=21.232, acc=0.877, loss=28.856, backward_time=0.215, grad_norm=19.132, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.954
[seoultech:0/4] 2024-01-29 03:11:33,920 (trainer:753) INFO: 16epoch:train:7213-7813batch: iter_time=2.894e-04, forward_time=0.170, loss_ctc=46.998, loss_att=21.459, acc=0.877, loss=29.121, backward_time=0.175, grad_norm=18.299, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.913
[seoultech:0/4] 2024-01-29 03:16:16,440 (trainer:753) INFO: 16epoch:train:7814-8414batch: iter_time=2.547e-04, forward_time=0.156, loss_ctc=47.821, loss_att=21.873, acc=0.876, loss=29.658, backward_time=0.156, grad_norm=18.563, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.879
[seoultech:0/4] 2024-01-29 03:20:52,395 (trainer:753) INFO: 16epoch:train:8415-9015batch: iter_time=2.722e-04, forward_time=0.162, loss_ctc=48.549, loss_att=22.285, acc=0.874, loss=30.164, backward_time=0.162, grad_norm=18.986, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.836
[seoultech:0/4] 2024-01-29 03:25:42,937 (trainer:753) INFO: 16epoch:train:9016-9616batch: iter_time=2.697e-04, forward_time=0.162, loss_ctc=47.423, loss_att=21.741, acc=0.875, loss=29.446, backward_time=0.195, grad_norm=20.543, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.932
[seoultech:0/4] 2024-01-29 03:30:37,330 (trainer:753) INFO: 16epoch:train:9617-10217batch: iter_time=2.757e-04, forward_time=0.168, loss_ctc=45.247, loss_att=20.668, acc=0.873, loss=28.042, backward_time=0.216, grad_norm=18.872, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.959
[seoultech:0/4] 2024-01-29 03:35:26,906 (trainer:753) INFO: 16epoch:train:10218-10818batch: iter_time=2.722e-04, forward_time=0.169, loss_ctc=47.005, loss_att=21.446, acc=0.875, loss=29.113, backward_time=0.174, grad_norm=18.879, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.928
[seoultech:0/4] 2024-01-29 03:40:19,652 (trainer:753) INFO: 16epoch:train:10819-11419batch: iter_time=2.708e-04, forward_time=0.153, loss_ctc=47.395, loss_att=21.535, acc=0.874, loss=29.293, backward_time=0.201, grad_norm=19.723, clip=100.000, loss_scale=5.498e+11, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.948
[seoultech:0/4] 2024-01-29 03:45:07,631 (trainer:753) INFO: 16epoch:train:11420-12020batch: iter_time=2.740e-04, forward_time=0.147, loss_ctc=45.719, loss_att=20.846, acc=0.875, loss=28.308, backward_time=0.207, grad_norm=19.648, clip=100.000, loss_scale=1.005e+12, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.915
[seoultech:0/4] 2024-01-29 03:56:53,361 (trainer:352) INFO: 16epoch results: [train] iter_time=3.207e-04, forward_time=0.157, loss_ctc=47.210, loss_att=21.559, acc=0.874, loss=29.254, backward_time=0.192, grad_norm=19.336, clip=100.000, loss_scale=4.927e+11, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.917, time=1 hour, 36 minutes and 11.83 seconds, total_count=192528, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=20.518, cer_ctc=0.139, loss_att=9.227, acc=0.937, cer=0.084, wer=0.237, loss=12.614, time=10 minutes and 15.05 seconds, total_count=24544, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 22.24 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 03:57:01,345 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 03:57:01,355 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/6epoch.pth
[seoultech:0/4] 2024-01-29 03:57:01,355 (trainer:286) INFO: 17/50epoch started. Estimated time to finish: 2 days, 12 hours and 52 minutes
[seoultech:0/4] 2024-01-29 04:02:18,670 (trainer:753) INFO: 17epoch:train:1-601batch: iter_time=0.001, forward_time=0.150, loss_ctc=49.616, loss_att=22.535, acc=0.878, loss=30.659, backward_time=0.211, grad_norm=20.863, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.045, optim0_lr0=0.002, train_time=2.111
[seoultech:0/4] 2024-01-29 04:06:59,167 (trainer:753) INFO: 17epoch:train:602-1202batch: iter_time=2.729e-04, forward_time=0.149, loss_ctc=46.218, loss_att=21.054, acc=0.876, loss=28.603, backward_time=0.189, grad_norm=19.446, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.867
[seoultech:0/4] 2024-01-29 04:11:20,861 (trainer:753) INFO: 17epoch:train:1203-1803batch: iter_time=2.587e-04, forward_time=0.146, loss_ctc=46.641, loss_att=21.171, acc=0.877, loss=28.812, backward_time=0.171, grad_norm=19.875, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.742
[seoultech:0/4] 2024-01-29 04:15:49,988 (trainer:753) INFO: 17epoch:train:1804-2404batch: iter_time=2.497e-04, forward_time=0.145, loss_ctc=45.809, loss_att=20.857, acc=0.877, loss=28.343, backward_time=0.195, grad_norm=19.399, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.789
[seoultech:0/4] 2024-01-29 04:20:27,374 (trainer:753) INFO: 17epoch:train:2405-3005batch: iter_time=2.710e-04, forward_time=0.153, loss_ctc=46.391, loss_att=21.181, acc=0.876, loss=28.744, backward_time=0.190, grad_norm=18.974, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.846
[seoultech:0/4] 2024-01-29 04:25:01,771 (trainer:753) INFO: 17epoch:train:3006-3606batch: iter_time=2.660e-04, forward_time=0.157, loss_ctc=46.273, loss_att=21.117, acc=0.878, loss=28.664, backward_time=0.177, grad_norm=18.574, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.825
[seoultech:0/4] 2024-01-29 04:29:42,593 (trainer:753) INFO: 17epoch:train:3607-4207batch: iter_time=2.773e-04, forward_time=0.154, loss_ctc=46.588, loss_att=21.288, acc=0.875, loss=28.878, backward_time=0.188, grad_norm=18.633, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.866
[seoultech:0/4] 2024-01-29 04:34:20,614 (trainer:753) INFO: 17epoch:train:4208-4808batch: iter_time=2.688e-04, forward_time=0.165, loss_ctc=45.967, loss_att=20.986, acc=0.878, loss=28.480, backward_time=0.160, grad_norm=17.777, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.851
[seoultech:0/4] 2024-01-29 04:39:00,250 (trainer:753) INFO: 17epoch:train:4809-5409batch: iter_time=2.660e-04, forward_time=0.147, loss_ctc=45.714, loss_att=20.781, acc=0.877, loss=28.261, backward_time=0.189, grad_norm=18.848, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.861
[seoultech:0/4] 2024-01-29 04:43:31,653 (trainer:753) INFO: 17epoch:train:5410-6010batch: iter_time=2.798e-04, forward_time=0.165, loss_ctc=47.631, loss_att=21.653, acc=0.878, loss=29.446, backward_time=0.154, grad_norm=19.518, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.806
[seoultech:0/4] 2024-01-29 04:48:08,084 (trainer:753) INFO: 17epoch:train:6011-6611batch: iter_time=2.610e-04, forward_time=0.159, loss_ctc=47.535, loss_att=21.685, acc=0.878, loss=29.440, backward_time=0.159, grad_norm=20.158, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.839
[seoultech:0/4] 2024-01-29 04:52:39,859 (trainer:753) INFO: 17epoch:train:6612-7212batch: iter_time=2.378e-04, forward_time=0.136, loss_ctc=46.569, loss_att=21.252, acc=0.878, loss=28.847, backward_time=0.154, grad_norm=18.793, clip=100.000, loss_scale=1.100e+12, optim_step_time=0.034, optim0_lr0=0.002, train_time=1.808
[seoultech:0/4] 2024-01-29 04:57:30,603 (trainer:753) INFO: 17epoch:train:7213-7813batch: iter_time=2.699e-04, forward_time=0.155, loss_ctc=45.982, loss_att=20.965, acc=0.877, loss=28.470, backward_time=0.190, grad_norm=18.566, clip=100.000, loss_scale=1.693e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.934
[seoultech:0/4] 2024-01-29 05:02:17,380 (trainer:753) INFO: 17epoch:train:7814-8414batch: iter_time=2.582e-04, forward_time=0.145, loss_ctc=44.888, loss_att=20.450, acc=0.878, loss=27.782, backward_time=0.159, grad_norm=18.854, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.038, optim0_lr0=0.002, train_time=1.908
[seoultech:0/4] 2024-01-29 05:07:12,578 (trainer:753) INFO: 17epoch:train:8415-9015batch: iter_time=2.587e-04, forward_time=0.143, loss_ctc=43.342, loss_att=19.696, acc=0.877, loss=26.790, backward_time=0.204, grad_norm=18.517, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.964
[seoultech:0/4] 2024-01-29 05:12:05,465 (trainer:753) INFO: 17epoch:train:9016-9616batch: iter_time=2.791e-04, forward_time=0.164, loss_ctc=45.230, loss_att=20.542, acc=0.877, loss=27.948, backward_time=0.178, grad_norm=19.286, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.948
[seoultech:0/4] 2024-01-29 05:16:55,207 (trainer:753) INFO: 17epoch:train:9617-10217batch: iter_time=2.786e-04, forward_time=0.163, loss_ctc=46.799, loss_att=21.335, acc=0.878, loss=28.974, backward_time=0.156, grad_norm=20.081, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.928
[seoultech:0/4] 2024-01-29 05:21:45,600 (trainer:753) INFO: 17epoch:train:10218-10818batch: iter_time=2.843e-04, forward_time=0.169, loss_ctc=47.625, loss_att=21.693, acc=0.877, loss=29.473, backward_time=0.155, grad_norm=19.902, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.932
[seoultech:0/4] 2024-01-29 05:26:45,030 (trainer:753) INFO: 17epoch:train:10819-11419batch: iter_time=2.828e-04, forward_time=0.171, loss_ctc=43.874, loss_att=19.936, acc=0.876, loss=27.118, backward_time=0.155, grad_norm=20.165, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.993
[seoultech:0/4] 2024-01-29 05:31:30,411 (trainer:753) INFO: 17epoch:train:11420-12020batch: iter_time=2.754e-04, forward_time=0.168, loss_ctc=47.040, loss_att=21.267, acc=0.878, loss=28.999, backward_time=0.155, grad_norm=20.034, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.897
[seoultech:0/4] 2024-01-29 05:43:16,301 (trainer:352) INFO: 17epoch results: [train] iter_time=3.204e-04, forward_time=0.155, loss_ctc=46.251, loss_att=21.056, acc=0.877, loss=28.614, backward_time=0.174, grad_norm=19.310, clip=100.000, loss_scale=1.515e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.886, time=1 hour, 34 minutes and 36.84 seconds, total_count=204561, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=19.873, cer_ctc=0.136, loss_att=8.990, acc=0.938, cer=0.082, wer=0.234, loss=12.255, time=10 minutes and 17.87 seconds, total_count=26078, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 20.23 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 05:43:22,178 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 05:43:22,185 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/7epoch.pth
[seoultech:0/4] 2024-01-29 05:43:22,185 (trainer:286) INFO: 18/50epoch started. Estimated time to finish: 2 days, 11 hours and 3 minutes
[seoultech:0/4] 2024-01-29 05:48:51,267 (trainer:753) INFO: 18epoch:train:1-601batch: iter_time=0.001, forward_time=0.152, loss_ctc=46.975, loss_att=21.286, acc=0.878, loss=28.993, backward_time=0.170, grad_norm=19.237, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.041, optim0_lr0=0.002, train_time=2.190
[seoultech:0/4] 2024-01-29 05:53:45,948 (trainer:753) INFO: 18epoch:train:602-1202batch: iter_time=2.675e-04, forward_time=0.153, loss_ctc=46.757, loss_att=21.237, acc=0.877, loss=28.893, backward_time=0.217, grad_norm=19.510, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.961
[seoultech:0/4] 2024-01-29 05:58:28,794 (trainer:753) INFO: 18epoch:train:1203-1803batch: iter_time=2.601e-04, forward_time=0.159, loss_ctc=46.317, loss_att=21.099, acc=0.879, loss=28.665, backward_time=0.201, grad_norm=18.902, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.884
[seoultech:0/4] 2024-01-29 06:02:53,363 (trainer:753) INFO: 18epoch:train:1804-2404batch: iter_time=2.593e-04, forward_time=0.151, loss_ctc=46.086, loss_att=20.998, acc=0.881, loss=28.524, backward_time=0.148, grad_norm=18.499, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.759
[seoultech:0/4] 2024-01-29 06:07:35,280 (trainer:753) INFO: 18epoch:train:2405-3005batch: iter_time=2.673e-04, forward_time=0.156, loss_ctc=44.060, loss_att=19.952, acc=0.878, loss=27.185, backward_time=0.192, grad_norm=19.625, clip=100.000, loss_scale=2.199e+12, optim_step_time=0.047, optim0_lr0=0.002, train_time=1.876
[seoultech:0/4] 2024-01-29 06:12:21,454 (trainer:753) INFO: 18epoch:train:3006-3606batch: iter_time=2.775e-04, forward_time=0.167, loss_ctc=46.672, loss_att=21.215, acc=0.878, loss=28.852, backward_time=0.215, grad_norm=19.722, clip=100.000, loss_scale=2.741e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.903
[seoultech:0/4] 2024-01-29 06:17:03,975 (trainer:753) INFO: 18epoch:train:3607-4207batch: iter_time=2.720e-04, forward_time=0.154, loss_ctc=42.937, loss_att=19.511, acc=0.877, loss=26.538, backward_time=0.186, grad_norm=19.377, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.880
[seoultech:0/4] 2024-01-29 06:21:51,133 (trainer:753) INFO: 18epoch:train:4208-4808batch: iter_time=2.776e-04, forward_time=0.166, loss_ctc=46.796, loss_att=21.192, acc=0.879, loss=28.873, backward_time=0.198, grad_norm=20.639, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.910
[seoultech:0/4] 2024-01-29 06:26:29,539 (trainer:753) INFO: 18epoch:train:4809-5409batch: iter_time=2.680e-04, forward_time=0.156, loss_ctc=46.682, loss_att=21.153, acc=0.880, loss=28.812, backward_time=0.169, grad_norm=18.619, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-29 06:31:17,289 (trainer:753) INFO: 18epoch:train:5410-6010batch: iter_time=2.733e-04, forward_time=0.165, loss_ctc=46.181, loss_att=21.001, acc=0.880, loss=28.555, backward_time=0.199, grad_norm=19.484, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.915
[seoultech:0/4] 2024-01-29 06:35:57,021 (trainer:753) INFO: 18epoch:train:6011-6611batch: iter_time=2.660e-04, forward_time=0.162, loss_ctc=47.151, loss_att=21.363, acc=0.879, loss=29.099, backward_time=0.169, grad_norm=19.993, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.861
[seoultech:0/4] 2024-01-29 06:40:42,925 (trainer:753) INFO: 18epoch:train:6612-7212batch: iter_time=2.697e-04, forward_time=0.165, loss_ctc=45.310, loss_att=20.595, acc=0.879, loss=28.010, backward_time=0.179, grad_norm=19.168, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.901
[seoultech:0/4] 2024-01-29 06:45:22,163 (trainer:753) INFO: 18epoch:train:7213-7813batch: iter_time=2.737e-04, forward_time=0.165, loss_ctc=46.510, loss_att=21.053, acc=0.880, loss=28.690, backward_time=0.157, grad_norm=18.742, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.857
[seoultech:0/4] 2024-01-29 06:50:06,115 (trainer:753) INFO: 18epoch:train:7814-8414batch: iter_time=2.662e-04, forward_time=0.140, loss_ctc=47.186, loss_att=21.290, acc=0.879, loss=29.059, backward_time=0.177, grad_norm=19.911, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.891
[seoultech:0/4] 2024-01-29 06:54:42,736 (trainer:753) INFO: 18epoch:train:8415-9015batch: iter_time=2.723e-04, forward_time=0.157, loss_ctc=47.653, loss_att=21.582, acc=0.880, loss=29.403, backward_time=0.155, grad_norm=19.399, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.840
[seoultech:0/4] 2024-01-29 06:59:35,180 (trainer:753) INFO: 18epoch:train:9016-9616batch: iter_time=2.770e-04, forward_time=0.151, loss_ctc=43.847, loss_att=19.806, acc=0.879, loss=27.018, backward_time=0.165, grad_norm=19.361, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.944
[seoultech:0/4] 2024-01-29 07:04:17,067 (trainer:753) INFO: 18epoch:train:9617-10217batch: iter_time=2.744e-04, forward_time=0.151, loss_ctc=45.131, loss_att=20.436, acc=0.878, loss=27.844, backward_time=0.186, grad_norm=20.234, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.875
[seoultech:0/4] 2024-01-29 07:08:50,768 (trainer:753) INFO: 18epoch:train:10218-10818batch: iter_time=2.579e-04, forward_time=0.146, loss_ctc=45.683, loss_att=20.660, acc=0.879, loss=28.167, backward_time=0.169, grad_norm=20.440, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.821
[seoultech:0/4] 2024-01-29 07:13:35,458 (trainer:753) INFO: 18epoch:train:10819-11419batch: iter_time=2.792e-04, forward_time=0.157, loss_ctc=45.924, loss_att=20.775, acc=0.878, loss=28.319, backward_time=0.175, grad_norm=19.351, clip=100.000, loss_scale=4.398e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.894
[seoultech:0/4] 2024-01-29 07:18:32,290 (trainer:753) INFO: 18epoch:train:11420-12020batch: iter_time=2.653e-04, forward_time=0.161, loss_ctc=43.358, loss_att=19.673, acc=0.878, loss=26.779, backward_time=0.185, grad_norm=20.579, clip=100.000, loss_scale=8.505e+12, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.974
[seoultech:0/4] 2024-01-29 07:30:33,399 (trainer:352) INFO: 18epoch results: [train] iter_time=3.186e-04, forward_time=0.157, loss_ctc=45.802, loss_att=20.768, acc=0.879, loss=28.278, backward_time=0.181, grad_norm=19.537, clip=100.000, loss_scale=3.977e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.899, time=1 hour, 35 minutes and 18.53 seconds, total_count=216594, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=19.947, cer_ctc=0.136, loss_att=8.868, acc=0.939, cer=0.082, wer=0.233, loss=12.192, time=10 minutes and 10.29 seconds, total_count=27612, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 42.39 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 07:30:41,031 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 07:30:41,042 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/8epoch.pth
[seoultech:0/4] 2024-01-29 07:30:41,042 (trainer:286) INFO: 19/50epoch started. Estimated time to finish: 2 days, 9 hours and 15 minutes
[seoultech:0/4] 2024-01-29 07:36:16,565 (trainer:753) INFO: 19epoch:train:1-601batch: iter_time=0.001, forward_time=0.166, loss_ctc=45.881, loss_att=20.711, acc=0.880, loss=28.262, backward_time=0.202, grad_norm=19.733, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=2.233
[seoultech:0/4] 2024-01-29 07:41:02,012 (trainer:753) INFO: 19epoch:train:602-1202batch: iter_time=2.728e-04, forward_time=0.164, loss_ctc=45.083, loss_att=20.367, acc=0.880, loss=27.782, backward_time=0.162, grad_norm=19.522, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.898
[seoultech:0/4] 2024-01-29 07:45:46,331 (trainer:753) INFO: 19epoch:train:1203-1803batch: iter_time=2.784e-04, forward_time=0.156, loss_ctc=47.949, loss_att=21.670, acc=0.880, loss=29.554, backward_time=0.159, grad_norm=19.693, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.892
[seoultech:0/4] 2024-01-29 07:50:26,879 (trainer:753) INFO: 19epoch:train:1804-2404batch: iter_time=2.793e-04, forward_time=0.167, loss_ctc=48.095, loss_att=21.708, acc=0.881, loss=29.624, backward_time=0.157, grad_norm=19.722, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.867
[seoultech:0/4] 2024-01-29 07:55:05,057 (trainer:753) INFO: 19epoch:train:2405-3005batch: iter_time=2.686e-04, forward_time=0.167, loss_ctc=43.541, loss_att=19.784, acc=0.879, loss=26.911, backward_time=0.152, grad_norm=18.780, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.851
[seoultech:0/4] 2024-01-29 07:59:35,877 (trainer:753) INFO: 19epoch:train:3006-3606batch: iter_time=2.677e-04, forward_time=0.163, loss_ctc=45.184, loss_att=20.396, acc=0.881, loss=27.832, backward_time=0.154, grad_norm=19.449, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.802
[seoultech:0/4] 2024-01-29 08:04:08,972 (trainer:753) INFO: 19epoch:train:3607-4207batch: iter_time=2.863e-04, forward_time=0.169, loss_ctc=44.776, loss_att=20.252, acc=0.880, loss=27.609, backward_time=0.162, grad_norm=20.151, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.817
[seoultech:0/4] 2024-01-29 08:08:47,445 (trainer:753) INFO: 19epoch:train:4208-4808batch: iter_time=2.884e-04, forward_time=0.155, loss_ctc=46.300, loss_att=21.001, acc=0.880, loss=28.591, backward_time=0.169, grad_norm=19.683, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-29 08:13:37,724 (trainer:753) INFO: 19epoch:train:4809-5409batch: iter_time=2.690e-04, forward_time=0.161, loss_ctc=45.750, loss_att=20.724, acc=0.881, loss=28.232, backward_time=0.218, grad_norm=19.374, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.931
[seoultech:0/4] 2024-01-29 08:18:23,525 (trainer:753) INFO: 19epoch:train:5410-6010batch: iter_time=2.692e-04, forward_time=0.155, loss_ctc=46.194, loss_att=20.917, acc=0.881, loss=28.500, backward_time=0.190, grad_norm=20.573, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.901
[seoultech:0/4] 2024-01-29 08:23:02,340 (trainer:753) INFO: 19epoch:train:6011-6611batch: iter_time=2.713e-04, forward_time=0.159, loss_ctc=43.986, loss_att=19.910, acc=0.880, loss=27.133, backward_time=0.190, grad_norm=17.860, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.856
[seoultech:0/4] 2024-01-29 08:27:43,861 (trainer:753) INFO: 19epoch:train:6612-7212batch: iter_time=2.789e-04, forward_time=0.167, loss_ctc=45.940, loss_att=20.808, acc=0.881, loss=28.347, backward_time=0.190, grad_norm=19.809, clip=100.000, loss_scale=8.796e+12, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.872
[seoultech:0/4] 2024-01-29 08:32:24,094 (trainer:753) INFO: 19epoch:train:7213-7813batch: iter_time=2.841e-04, forward_time=0.166, loss_ctc=45.655, loss_att=20.636, acc=0.881, loss=28.142, backward_time=0.159, grad_norm=20.440, clip=100.000, loss_scale=1.448e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.865
[seoultech:0/4] 2024-01-29 08:37:03,507 (trainer:753) INFO: 19epoch:train:7814-8414batch: iter_time=2.503e-04, forward_time=0.148, loss_ctc=44.215, loss_att=19.964, acc=0.880, loss=27.240, backward_time=0.154, grad_norm=19.602, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.038, optim0_lr0=0.002, train_time=1.858
[seoultech:0/4] 2024-01-29 08:41:49,276 (trainer:753) INFO: 19epoch:train:8415-9015batch: iter_time=2.720e-04, forward_time=0.158, loss_ctc=44.875, loss_att=20.263, acc=0.878, loss=27.646, backward_time=0.164, grad_norm=20.579, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.039, optim0_lr0=0.002, train_time=1.901
[seoultech:0/4] 2024-01-29 08:46:36,794 (trainer:753) INFO: 19epoch:train:9016-9616batch: iter_time=2.611e-04, forward_time=0.156, loss_ctc=46.018, loss_att=20.790, acc=0.881, loss=28.358, backward_time=0.198, grad_norm=18.691, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.912
[seoultech:0/4] 2024-01-29 08:51:14,824 (trainer:753) INFO: 19epoch:train:9617-10217batch: iter_time=2.717e-04, forward_time=0.165, loss_ctc=45.073, loss_att=20.349, acc=0.880, loss=27.766, backward_time=0.178, grad_norm=19.968, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.850
[seoultech:0/4] 2024-01-29 08:55:59,848 (trainer:753) INFO: 19epoch:train:10218-10818batch: iter_time=2.732e-04, forward_time=0.164, loss_ctc=44.373, loss_att=19.975, acc=0.883, loss=27.294, backward_time=0.183, grad_norm=19.456, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.896
[seoultech:0/4] 2024-01-29 09:00:53,315 (trainer:753) INFO: 19epoch:train:10819-11419batch: iter_time=2.736e-04, forward_time=0.161, loss_ctc=42.359, loss_att=19.250, acc=0.881, loss=26.182, backward_time=0.217, grad_norm=18.292, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.952
[seoultech:0/4] 2024-01-29 09:05:33,170 (trainer:753) INFO: 19epoch:train:11420-12020batch: iter_time=2.790e-04, forward_time=0.167, loss_ctc=44.103, loss_att=19.937, acc=0.883, loss=27.187, backward_time=0.171, grad_norm=17.032, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.863
[seoultech:0/4] 2024-01-29 09:17:23,600 (trainer:352) INFO: 19epoch results: [train] iter_time=3.328e-04, forward_time=0.162, loss_ctc=45.221, loss_att=20.450, acc=0.880, loss=27.882, backward_time=0.176, grad_norm=19.425, clip=100.000, loss_scale=1.216e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.893, time=1 hour, 35 minutes and 0.23 seconds, total_count=228627, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=19.472, cer_ctc=0.132, loss_att=8.688, acc=0.940, cer=0.079, wer=0.229, loss=11.924, time=10 minutes and 11.61 seconds, total_count=29146, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 30.72 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 09:17:31,394 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 09:17:31,405 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/9epoch.pth
[seoultech:0/4] 2024-01-29 09:17:31,405 (trainer:286) INFO: 20/50epoch started. Estimated time to finish: 2 days, 7 hours and 27 minutes
[seoultech:0/4] 2024-01-29 09:22:38,998 (trainer:753) INFO: 20epoch:train:1-601batch: iter_time=0.001, forward_time=0.143, loss_ctc=45.865, loss_att=20.778, acc=0.882, loss=28.304, backward_time=0.158, grad_norm=19.443, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.039, optim0_lr0=0.002, train_time=2.046
[seoultech:0/4] 2024-01-29 09:27:20,725 (trainer:753) INFO: 20epoch:train:602-1202batch: iter_time=2.690e-04, forward_time=0.152, loss_ctc=46.824, loss_att=21.204, acc=0.883, loss=28.890, backward_time=0.152, grad_norm=18.486, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.876
[seoultech:0/4] 2024-01-29 09:31:55,278 (trainer:753) INFO: 20epoch:train:1203-1803batch: iter_time=2.477e-04, forward_time=0.143, loss_ctc=44.160, loss_att=19.930, acc=0.882, loss=27.199, backward_time=0.172, grad_norm=18.799, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.035, optim0_lr0=0.002, train_time=1.826
[seoultech:0/4] 2024-01-29 09:36:38,713 (trainer:753) INFO: 20epoch:train:1804-2404batch: iter_time=2.718e-04, forward_time=0.155, loss_ctc=43.148, loss_att=19.442, acc=0.881, loss=26.554, backward_time=0.179, grad_norm=20.731, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.885
[seoultech:0/4] 2024-01-29 09:41:13,157 (trainer:753) INFO: 20epoch:train:2405-3005batch: iter_time=2.782e-04, forward_time=0.172, loss_ctc=44.587, loss_att=20.104, acc=0.880, loss=27.449, backward_time=0.159, grad_norm=19.859, clip=100.000, loss_scale=1.759e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.826
[seoultech:0/4] 2024-01-29 09:45:37,384 (trainer:753) INFO: 20epoch:train:3006-3606batch: iter_time=2.864e-04, forward_time=0.155, loss_ctc=44.300, loss_att=19.951, acc=0.883, loss=27.255, backward_time=0.172, grad_norm=18.824, clip=100.000, loss_scale=2.381e+13, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.759
[seoultech:0/4] 2024-01-29 09:50:18,152 (trainer:753) INFO: 20epoch:train:3607-4207batch: iter_time=2.828e-04, forward_time=0.163, loss_ctc=45.243, loss_att=20.442, acc=0.882, loss=27.882, backward_time=0.171, grad_norm=18.716, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.867
[seoultech:0/4] 2024-01-29 09:55:07,031 (trainer:753) INFO: 20epoch:train:4208-4808batch: iter_time=2.844e-04, forward_time=0.152, loss_ctc=46.266, loss_att=20.827, acc=0.883, loss=28.459, backward_time=0.197, grad_norm=19.424, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.921
[seoultech:0/4] 2024-01-29 09:59:39,699 (trainer:753) INFO: 20epoch:train:4809-5409batch: iter_time=2.892e-04, forward_time=0.159, loss_ctc=45.634, loss_att=20.559, acc=0.881, loss=28.081, backward_time=0.158, grad_norm=20.509, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.815
[seoultech:0/4] 2024-01-29 10:04:14,808 (trainer:753) INFO: 20epoch:train:5410-6010batch: iter_time=2.757e-04, forward_time=0.156, loss_ctc=49.148, loss_att=22.086, acc=0.882, loss=30.205, backward_time=0.166, grad_norm=21.429, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.830
[seoultech:0/4] 2024-01-29 10:08:49,772 (trainer:753) INFO: 20epoch:train:6011-6611batch: iter_time=2.691e-04, forward_time=0.148, loss_ctc=42.759, loss_att=19.220, acc=0.880, loss=26.282, backward_time=0.175, grad_norm=20.412, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.829
[seoultech:0/4] 2024-01-29 10:13:35,012 (trainer:753) INFO: 20epoch:train:6612-7212batch: iter_time=2.801e-04, forward_time=0.140, loss_ctc=44.844, loss_att=20.113, acc=0.881, loss=27.532, backward_time=0.207, grad_norm=22.102, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.897
[seoultech:0/4] 2024-01-29 10:18:22,650 (trainer:753) INFO: 20epoch:train:7213-7813batch: iter_time=2.719e-04, forward_time=0.141, loss_ctc=44.198, loss_att=19.995, acc=0.880, loss=27.256, backward_time=0.204, grad_norm=20.113, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.914
[seoultech:0/4] 2024-01-29 10:23:11,971 (trainer:753) INFO: 20epoch:train:7814-8414batch: iter_time=2.658e-04, forward_time=0.139, loss_ctc=45.134, loss_att=20.303, acc=0.882, loss=27.752, backward_time=0.180, grad_norm=21.281, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.039, optim0_lr0=0.002, train_time=1.926
[seoultech:0/4] 2024-01-29 10:28:03,170 (trainer:753) INFO: 20epoch:train:8415-9015batch: iter_time=2.945e-04, forward_time=0.160, loss_ctc=43.933, loss_att=19.949, acc=0.883, loss=27.144, backward_time=0.162, grad_norm=17.699, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.936
[seoultech:0/4] 2024-01-29 10:32:58,595 (trainer:753) INFO: 20epoch:train:9016-9616batch: iter_time=2.738e-04, forward_time=0.158, loss_ctc=42.999, loss_att=19.420, acc=0.882, loss=26.494, backward_time=0.204, grad_norm=18.368, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.965
[seoultech:0/4] 2024-01-29 10:37:51,290 (trainer:753) INFO: 20epoch:train:9617-10217batch: iter_time=2.978e-04, forward_time=0.168, loss_ctc=44.961, loss_att=20.271, acc=0.883, loss=27.678, backward_time=0.193, grad_norm=19.122, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.948
[seoultech:0/4] 2024-01-29 10:42:32,002 (trainer:753) INFO: 20epoch:train:10218-10818batch: iter_time=3.061e-04, forward_time=0.165, loss_ctc=46.258, loss_att=20.897, acc=0.883, loss=28.505, backward_time=0.176, grad_norm=20.535, clip=100.000, loss_scale=3.518e+13, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.866
[seoultech:0/4] 2024-01-29 10:47:17,029 (trainer:753) INFO: 20epoch:train:10819-11419batch: iter_time=2.986e-04, forward_time=0.154, loss_ctc=42.970, loss_att=19.380, acc=0.881, loss=26.457, backward_time=0.193, grad_norm=20.169, clip=100.000, loss_scale=3.659e+13, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.897
[seoultech:0/4] 2024-01-29 10:51:58,529 (trainer:753) INFO: 20epoch:train:11420-12020batch: iter_time=2.807e-04, forward_time=0.167, loss_ctc=42.411, loss_att=19.134, acc=0.882, loss=26.117, backward_time=0.178, grad_norm=19.542, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.872
[seoultech:0/4] 2024-01-29 11:03:35,888 (trainer:352) INFO: 20epoch results: [train] iter_time=3.234e-04, forward_time=0.155, loss_ctc=44.732, loss_att=20.177, acc=0.882, loss=27.543, backward_time=0.178, grad_norm=19.778, clip=100.000, loss_scale=3.210e+13, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.885, time=1 hour, 34 minutes and 35.67 seconds, total_count=240660, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=19.476, cer_ctc=0.133, loss_att=8.621, acc=0.940, cer=0.080, wer=0.229, loss=11.877, time=10 minutes and 1.42 seconds, total_count=30680, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 27.4 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 11:03:44,154 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 11:03:44,165 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/10epoch.pth
[seoultech:0/4] 2024-01-29 11:03:44,165 (trainer:286) INFO: 21/50epoch started. Estimated time to finish: 2 days, 5 hours and 38 minutes
[seoultech:0/4] 2024-01-29 11:08:56,801 (trainer:753) INFO: 21epoch:train:1-601batch: iter_time=0.001, forward_time=0.161, loss_ctc=46.496, loss_att=20.845, acc=0.883, loss=28.540, backward_time=0.169, grad_norm=21.843, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.045, optim0_lr0=0.002, train_time=2.081
[seoultech:0/4] 2024-01-29 11:13:27,672 (trainer:753) INFO: 21epoch:train:602-1202batch: iter_time=2.756e-04, forward_time=0.157, loss_ctc=44.333, loss_att=20.053, acc=0.884, loss=27.337, backward_time=0.151, grad_norm=18.745, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.802
[seoultech:0/4] 2024-01-29 11:18:03,014 (trainer:753) INFO: 21epoch:train:1203-1803batch: iter_time=2.648e-04, forward_time=0.147, loss_ctc=45.666, loss_att=20.607, acc=0.884, loss=28.125, backward_time=0.176, grad_norm=18.314, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.832
[seoultech:0/4] 2024-01-29 11:22:45,560 (trainer:753) INFO: 21epoch:train:1804-2404batch: iter_time=2.644e-04, forward_time=0.143, loss_ctc=43.913, loss_att=19.744, acc=0.884, loss=26.995, backward_time=0.193, grad_norm=19.615, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.880
[seoultech:0/4] 2024-01-29 11:27:27,085 (trainer:753) INFO: 21epoch:train:2405-3005batch: iter_time=2.367e-04, forward_time=0.136, loss_ctc=43.922, loss_att=19.766, acc=0.883, loss=27.013, backward_time=0.205, grad_norm=19.556, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.037, optim0_lr0=0.002, train_time=1.873
[seoultech:0/4] 2024-01-29 11:32:05,422 (trainer:753) INFO: 21epoch:train:3006-3606batch: iter_time=2.665e-04, forward_time=0.153, loss_ctc=45.666, loss_att=20.588, acc=0.885, loss=28.111, backward_time=0.162, grad_norm=19.501, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-29 11:36:53,748 (trainer:753) INFO: 21epoch:train:3607-4207batch: iter_time=2.715e-04, forward_time=0.149, loss_ctc=42.058, loss_att=19.004, acc=0.882, loss=25.920, backward_time=0.186, grad_norm=18.600, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.919
[seoultech:0/4] 2024-01-29 11:41:28,015 (trainer:753) INFO: 21epoch:train:4208-4808batch: iter_time=2.726e-04, forward_time=0.162, loss_ctc=43.872, loss_att=19.817, acc=0.883, loss=27.034, backward_time=0.174, grad_norm=19.045, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.823
[seoultech:0/4] 2024-01-29 11:46:06,568 (trainer:753) INFO: 21epoch:train:4809-5409batch: iter_time=2.918e-04, forward_time=0.170, loss_ctc=43.373, loss_att=19.598, acc=0.883, loss=26.730, backward_time=0.177, grad_norm=21.588, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.852
[seoultech:0/4] 2024-01-29 11:50:52,987 (trainer:753) INFO: 21epoch:train:5410-6010batch: iter_time=2.826e-04, forward_time=0.166, loss_ctc=48.254, loss_att=21.681, acc=0.886, loss=29.652, backward_time=0.196, grad_norm=19.873, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.908
[seoultech:0/4] 2024-01-29 11:55:45,386 (trainer:753) INFO: 21epoch:train:6011-6611batch: iter_time=2.829e-04, forward_time=0.166, loss_ctc=44.834, loss_att=20.256, acc=0.883, loss=27.630, backward_time=0.183, grad_norm=20.036, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.945
[seoultech:0/4] 2024-01-29 12:00:32,884 (trainer:753) INFO: 21epoch:train:6612-7212batch: iter_time=2.696e-04, forward_time=0.157, loss_ctc=42.303, loss_att=19.053, acc=0.883, loss=26.028, backward_time=0.195, grad_norm=19.480, clip=100.000, loss_scale=7.037e+13, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.912
[seoultech:0/4] 2024-01-29 12:06:14,980 (trainer:753) INFO: 21epoch:train:7213-7813batch: iter_time=7.185e-04, forward_time=0.196, loss_ctc=43.808, loss_att=19.874, acc=0.884, loss=27.054, backward_time=0.250, grad_norm=19.641, clip=100.000, loss_scale=1.234e+14, optim_step_time=0.052, optim0_lr0=0.002, train_time=2.276
[seoultech:0/4] 2024-01-29 12:12:07,518 (trainer:753) INFO: 21epoch:train:7814-8414batch: iter_time=7.461e-04, forward_time=0.201, loss_ctc=44.201, loss_att=19.973, acc=0.883, loss=27.241, backward_time=0.262, grad_norm=19.124, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.054, optim0_lr0=0.002, train_time=2.345
[seoultech:0/4] 2024-01-29 12:17:55,330 (trainer:753) INFO: 21epoch:train:8415-9015batch: iter_time=7.458e-04, forward_time=0.196, loss_ctc=45.760, loss_att=20.486, acc=0.884, loss=28.068, backward_time=0.258, grad_norm=21.084, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.053, optim0_lr0=0.002, train_time=2.314
[seoultech:0/4] 2024-01-29 12:22:44,235 (trainer:753) INFO: 21epoch:train:9016-9616batch: iter_time=3.663e-04, forward_time=0.161, loss_ctc=42.683, loss_att=19.247, acc=0.881, loss=26.278, backward_time=0.179, grad_norm=20.957, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.925
[seoultech:0/4] 2024-01-29 12:27:15,964 (trainer:753) INFO: 21epoch:train:9617-10217batch: iter_time=2.692e-04, forward_time=0.163, loss_ctc=40.049, loss_att=18.061, acc=0.883, loss=24.658, backward_time=0.163, grad_norm=18.388, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.806
[seoultech:0/4] 2024-01-29 12:31:57,380 (trainer:753) INFO: 21epoch:train:10218-10818batch: iter_time=2.667e-04, forward_time=0.165, loss_ctc=44.459, loss_att=20.099, acc=0.884, loss=27.407, backward_time=0.189, grad_norm=18.901, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.874
[seoultech:0/4] 2024-01-29 12:36:33,721 (trainer:753) INFO: 21epoch:train:10819-11419batch: iter_time=2.652e-04, forward_time=0.161, loss_ctc=42.125, loss_att=19.032, acc=0.884, loss=25.960, backward_time=0.183, grad_norm=18.741, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.838
[seoultech:0/4] 2024-01-29 12:41:13,552 (trainer:753) INFO: 21epoch:train:11420-12020batch: iter_time=2.583e-04, forward_time=0.143, loss_ctc=46.210, loss_att=20.797, acc=0.885, loss=28.421, backward_time=0.189, grad_norm=20.827, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.040, optim0_lr0=0.002, train_time=1.862
[seoultech:0/4] 2024-01-29 12:53:21,344 (trainer:352) INFO: 21epoch results: [train] iter_time=3.950e-04, forward_time=0.163, loss_ctc=44.145, loss_att=19.906, acc=0.883, loss=27.177, backward_time=0.192, grad_norm=19.692, clip=100.000, loss_scale=9.769e+13, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.946, time=1 hour, 37 minutes and 37.54 seconds, total_count=252693, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=19.181, cer_ctc=0.131, loss_att=8.532, acc=0.941, cer=0.079, wer=0.226, loss=11.727, time=10 minutes and 14.74 seconds, total_count=32214, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 44.9 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 12:53:29,556 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 12:53:29,567 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/11epoch.pth
[seoultech:0/4] 2024-01-29 12:53:29,568 (trainer:286) INFO: 22/50epoch started. Estimated time to finish: 2 days, 3 hours and 54 minutes
[seoultech:0/4] 2024-01-29 12:58:54,398 (trainer:753) INFO: 22epoch:train:1-601batch: iter_time=0.001, forward_time=0.149, loss_ctc=43.509, loss_att=19.522, acc=0.886, loss=26.718, backward_time=0.155, grad_norm=18.940, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.043, optim0_lr0=0.002, train_time=2.161
[seoultech:0/4] 2024-01-29 13:03:35,319 (trainer:753) INFO: 22epoch:train:602-1202batch: iter_time=2.619e-04, forward_time=0.161, loss_ctc=43.775, loss_att=19.706, acc=0.884, loss=26.927, backward_time=0.154, grad_norm=18.955, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.868
[seoultech:0/4] 2024-01-29 13:08:23,322 (trainer:753) INFO: 22epoch:train:1203-1803batch: iter_time=2.692e-04, forward_time=0.157, loss_ctc=44.393, loss_att=19.885, acc=0.883, loss=27.237, backward_time=0.202, grad_norm=22.031, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.917
[seoultech:0/4] 2024-01-29 13:13:14,240 (trainer:753) INFO: 22epoch:train:1804-2404batch: iter_time=2.632e-04, forward_time=0.147, loss_ctc=43.126, loss_att=19.383, acc=0.883, loss=26.506, backward_time=0.217, grad_norm=24.090, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.935
[seoultech:0/4] 2024-01-29 13:17:54,650 (trainer:753) INFO: 22epoch:train:2405-3005batch: iter_time=2.691e-04, forward_time=0.148, loss_ctc=46.383, loss_att=20.747, acc=0.884, loss=28.438, backward_time=0.200, grad_norm=22.315, clip=100.000, loss_scale=1.407e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.866
[seoultech:0/4] 2024-01-29 13:22:31,361 (trainer:753) INFO: 22epoch:train:3006-3606batch: iter_time=2.661e-04, forward_time=0.160, loss_ctc=44.103, loss_att=19.797, acc=0.883, loss=27.089, backward_time=0.152, grad_norm=20.877, clip=100.000, loss_scale=2.055e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.841
[seoultech:0/4] 2024-01-29 13:26:58,771 (trainer:753) INFO: 22epoch:train:3607-4207batch: iter_time=2.723e-04, forward_time=0.153, loss_ctc=44.501, loss_att=20.041, acc=0.884, loss=27.379, backward_time=0.182, grad_norm=20.188, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.779
[seoultech:0/4] 2024-01-29 13:31:28,948 (trainer:753) INFO: 22epoch:train:4208-4808batch: iter_time=2.848e-04, forward_time=0.166, loss_ctc=44.346, loss_att=19.898, acc=0.885, loss=27.232, backward_time=0.169, grad_norm=22.204, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.796
[seoultech:0/4] 2024-01-29 13:36:03,495 (trainer:753) INFO: 22epoch:train:4809-5409batch: iter_time=2.701e-04, forward_time=0.162, loss_ctc=43.338, loss_att=19.498, acc=0.884, loss=26.650, backward_time=0.163, grad_norm=19.313, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.827
[seoultech:0/4] 2024-01-29 13:40:44,022 (trainer:753) INFO: 22epoch:train:5410-6010batch: iter_time=2.768e-04, forward_time=0.165, loss_ctc=45.783, loss_att=20.639, acc=0.886, loss=28.182, backward_time=0.157, grad_norm=20.341, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.867
[seoultech:0/4] 2024-01-29 13:45:25,391 (trainer:753) INFO: 22epoch:train:6011-6611batch: iter_time=2.632e-04, forward_time=0.157, loss_ctc=42.820, loss_att=19.275, acc=0.884, loss=26.339, backward_time=0.181, grad_norm=21.483, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.871
[seoultech:0/4] 2024-01-29 13:50:07,033 (trainer:753) INFO: 22epoch:train:6612-7212batch: iter_time=2.640e-04, forward_time=0.157, loss_ctc=43.682, loss_att=19.620, acc=0.882, loss=26.839, backward_time=0.184, grad_norm=20.698, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.874
[seoultech:0/4] 2024-01-29 13:54:51,477 (trainer:753) INFO: 22epoch:train:7213-7813batch: iter_time=2.618e-04, forward_time=0.135, loss_ctc=44.690, loss_att=20.063, acc=0.884, loss=27.451, backward_time=0.193, grad_norm=21.163, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.893
[seoultech:0/4] 2024-01-29 13:59:37,330 (trainer:753) INFO: 22epoch:train:7814-8414batch: iter_time=2.624e-04, forward_time=0.138, loss_ctc=44.613, loss_att=20.056, acc=0.886, loss=27.423, backward_time=0.215, grad_norm=22.262, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.041, optim0_lr0=0.002, train_time=1.902
[seoultech:0/4] 2024-01-29 14:04:23,764 (trainer:753) INFO: 22epoch:train:8415-9015batch: iter_time=2.818e-04, forward_time=0.158, loss_ctc=42.264, loss_att=18.917, acc=0.884, loss=25.921, backward_time=0.210, grad_norm=20.951, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.906
[seoultech:0/4] 2024-01-29 14:08:59,434 (trainer:753) INFO: 22epoch:train:9016-9616batch: iter_time=2.793e-04, forward_time=0.166, loss_ctc=46.139, loss_att=20.741, acc=0.886, loss=28.360, backward_time=0.163, grad_norm=20.260, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.046, optim0_lr0=0.002, train_time=1.834
[seoultech:0/4] 2024-01-29 14:13:41,265 (trainer:753) INFO: 22epoch:train:9617-10217batch: iter_time=2.763e-04, forward_time=0.164, loss_ctc=44.526, loss_att=20.035, acc=0.883, loss=27.383, backward_time=0.157, grad_norm=23.473, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.876
[seoultech:0/4] 2024-01-29 14:18:28,435 (trainer:753) INFO: 22epoch:train:10218-10818batch: iter_time=2.644e-04, forward_time=0.152, loss_ctc=45.882, loss_att=20.563, acc=0.883, loss=28.159, backward_time=0.179, grad_norm=23.772, clip=100.000, loss_scale=2.815e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.910
[seoultech:0/4] 2024-01-29 14:23:17,709 (trainer:753) INFO: 22epoch:train:10819-11419batch: iter_time=2.811e-04, forward_time=0.147, loss_ctc=40.081, loss_att=18.047, acc=0.883, loss=24.658, backward_time=0.196, grad_norm=19.061, clip=100.000, loss_scale=3.228e+14, optim_step_time=0.045, optim0_lr0=0.002, train_time=1.926
[seoultech:0/4] 2024-01-29 14:28:10,061 (trainer:753) INFO: 22epoch:train:11420-12020batch: iter_time=2.656e-04, forward_time=0.142, loss_ctc=43.403, loss_att=19.537, acc=0.884, loss=26.697, backward_time=0.202, grad_norm=20.366, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.943
[seoultech:0/4] 2024-01-29 14:40:15,222 (trainer:352) INFO: 22epoch results: [train] iter_time=3.224e-04, forward_time=0.154, loss_ctc=44.014, loss_att=19.775, acc=0.884, loss=27.046, backward_time=0.182, grad_norm=21.132, clip=100.000, loss_scale=2.590e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=1.890, time=1 hour, 34 minutes and 48.78 seconds, total_count=264726, gpu_max_cached_mem_GB=38.736, [valid] loss_ctc=19.007, cer_ctc=0.131, loss_att=8.556, acc=0.941, cer=0.079, wer=0.227, loss=11.691, time=10 minutes and 15.44 seconds, total_count=33748, gpu_max_cached_mem_GB=38.736, [att_plot] time=1 minute and 41.43 seconds, total_count=0, gpu_max_cached_mem_GB=38.736
[seoultech:0/4] 2024-01-29 14:40:23,695 (trainer:407) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-29 14:40:23,705 (trainer:461) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_en_char_sp/12epoch.pth
[seoultech:0/4] 2024-01-29 14:40:23,706 (trainer:286) INFO: 23/50epoch started. Estimated time to finish: 2 days, 2 hours and 6 minutes
[seoultech:0/4] 2024-01-29 14:45:39,743 (trainer:753) INFO: 23epoch:train:1-601batch: iter_time=0.001, forward_time=0.155, loss_ctc=45.866, loss_att=20.509, acc=0.886, loss=28.116, backward_time=0.154, grad_norm=20.383, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.044, optim0_lr0=0.002, train_time=2.103
[seoultech:0/4] 2024-01-29 14:50:13,761 (trainer:753) INFO: 23epoch:train:602-1202batch: iter_time=2.703e-04, forward_time=0.152, loss_ctc=44.649, loss_att=20.015, acc=0.886, loss=27.405, backward_time=0.166, grad_norm=20.960, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.823
[seoultech:0/4] 2024-01-29 14:54:54,207 (trainer:753) INFO: 23epoch:train:1203-1803batch: iter_time=2.859e-04, forward_time=0.158, loss_ctc=43.295, loss_att=19.421, acc=0.887, loss=26.583, backward_time=0.169, grad_norm=19.696, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.042, optim0_lr0=0.002, train_time=1.865
[seoultech:0/4] 2024-01-29 14:59:30,348 (trainer:753) INFO: 23epoch:train:1804-2404batch: iter_time=2.687e-04, forward_time=0.149, loss_ctc=42.966, loss_att=19.264, acc=0.885, loss=26.375, backward_time=0.169, grad_norm=20.511, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.039, optim0_lr0=0.002, train_time=1.838
[seoultech:0/4] 2024-01-29 15:04:12,024 (trainer:753) INFO: 23epoch:train:2405-3005batch: iter_time=2.613e-04, forward_time=0.146, loss_ctc=42.734, loss_att=19.263, acc=0.886, loss=26.305, backward_time=0.182, grad_norm=17.962, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.037, optim0_lr0=0.002, train_time=1.875
[seoultech:0/4] 2024-01-29 15:08:55,956 (trainer:753) INFO: 23epoch:train:3006-3606batch: iter_time=2.733e-04, forward_time=0.163, loss_ctc=43.736, loss_att=19.720, acc=0.886, loss=26.925, backward_time=0.174, grad_norm=20.126, clip=100.000, loss_scale=5.629e+14, optim_step_time=0.043, optim0_lr0=0.002, train_time=1.888
