# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/kr_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_kr_char/valid/speech_shape --valid_shape_file exp/asr_stats_raw_kr_char/valid/text_shape.char --resume true --init_param --ignore_init_mismatch false --fold_length 80000 --fold_length 150 --output_dir exp/asr_train_asr_conformer_raw_kr_char --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_kr_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train/wav.scp,speech,sound --train_data_path_and_name_and_type dump/raw/train/text,text,text --train_shape_file exp/asr_stats_raw_kr_char/train/speech_shape --train_shape_file exp/asr_stats_raw_kr_char/train/text_shape.char --ngpu 4 --multiprocessing_distributed True 
# Started at Mon Jan 22 13:24:44 KST 2024
#
/home/bootcamp/espnet/tools/anaconda/envs/espnet/bin/python3 /home/bootcamp/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/kr_token_list/char/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --valid_data_path_and_name_and_type dump/raw/dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/raw/dev/text,text,text --valid_shape_file exp/asr_stats_raw_kr_char/valid/speech_shape --valid_shape_file exp/asr_stats_raw_kr_char/valid/text_shape.char --resume true --init_param --ignore_init_mismatch false --fold_length 80000 --fold_length 150 --output_dir exp/asr_train_asr_conformer_raw_kr_char --config conf/train_asr_conformer.yaml --frontend_conf fs=16k --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_raw_kr_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/raw/train/wav.scp,speech,sound --train_data_path_and_name_and_type dump/raw/train/text,text,text --train_shape_file exp/asr_stats_raw_kr_char/train/speech_shape --train_shape_file exp/asr_stats_raw_kr_char/train/text_shape.char --ngpu 4 --multiprocessing_distributed True
[seoultech:0/4] 2024-01-22 13:24:48,402 (distributed_c10d:228) INFO: Added key: store_based_barrier_key:1 to store for rank: 0
[seoultech:0/4] 2024-01-22 13:24:48,403 (distributed_c10d:262) INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[seoultech:0/4] 2024-01-22 13:24:48,434 (asr:411) INFO: Vocabulary size: 2504
[seoultech:0/4] 2024-01-22 13:24:48,543 (conformer_encoder:136) WARNING: Using legacy_rel_pos and it will be deprecated in the future.
[seoultech:0/4] 2024-01-22 13:24:48,605 (conformer_encoder:236) WARNING: Using legacy_rel_selfattn and it will be deprecated in the future.
[seoultech:0/4] 2024-01-22 13:24:50,816 (abs_task:1157) INFO: pytorch.version=1.12.1, cuda.available=True, cudnn.version=8302, cudnn.benchmark=False, cudnn.deterministic=True
[seoultech:0/4] 2024-01-22 13:24:50,822 (abs_task:1158) INFO: Model structure:
ESPnetASRModel(
  (frontend): DefaultFrontend(
    (stft): Stft(n_fft=512, win_length=512, hop_length=256, center=True, normalized=False, onesided=True)
    (frontend): Frontend()
    (logmel): LogMel(sr=16000, n_fft=512, n_mels=80, fmin=0, fmax=8000.0, htk=False)
  )
  (specaug): SpecAug(
    (time_warp): TimeWarp(window=5, mode=bicubic)
    (freq_mask): MaskAlongAxis(mask_width_range=[0, 30], num_mask=2, axis=freq)
    (time_mask): MaskAlongAxis(mask_width_range=[0, 40], num_mask=2, axis=time)
  )
  (normalize): GlobalMVN(stats_file=exp/asr_stats_raw_kr_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): ConformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 512, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=9728, out_features=512, bias=True)
        (1): LegacyRelPositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): LegacyRelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=512, out_features=512, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): Swish()
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
          (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
          (activation): Swish()
        )
        (norm_ff): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_mha): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_conv): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm_final): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(2504, 512)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=512, out_features=2504, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=512, out_features=512, bias=True)
          (linear_k): Linear(in_features=512, out_features=512, bias=True)
          (linear_v): Linear(in_features=512, out_features=512, bias=True)
          (linear_out): Linear(in_features=512, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=512, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=512, out_features=2504, bias=True)
    (ctc_loss): CTCLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Total Number of model parameters: 112.31 M
    Number of trainable parameters: 112.31 M (100.0%)
    Size: 449.23 MB
    Type: torch.float32
[seoultech:0/4] 2024-01-22 13:24:50,822 (abs_task:1161) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0002
    lr: 5e-09
    maximize: False
    weight_decay: 0
)
[seoultech:0/4] 2024-01-22 13:24:50,822 (abs_task:1162) INFO: Scheduler: WarmupLR(warmup_steps=40000)
[seoultech:0/4] 2024-01-22 13:24:50,822 (abs_task:1171) INFO: Saving the configuration in exp/asr_train_asr_conformer_raw_kr_char/config.yaml
[seoultech:0/4] 2024-01-22 13:25:06,278 (abs_task:1526) INFO: [train] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/train/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/train/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fab198a2f40>)
[seoultech:0/4] 2024-01-22 13:25:06,279 (abs_task:1527) INFO: [train] Batch sampler: NumElementsBatchSampler(N-batch=22364, batch_bins=18000000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/4] 2024-01-22 13:25:06,281 (abs_task:1528) INFO: [train] mini-batch sizes summary: N-batch=22364, mean=67.0, min=15, max=611
[seoultech:0/4] 2024-01-22 13:25:08,094 (abs_task:1526) INFO: [valid] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fab198a2fd0>)
[seoultech:0/4] 2024-01-22 13:25:08,094 (abs_task:1527) INFO: [valid] Batch sampler: NumElementsBatchSampler(N-batch=2848, batch_bins=18000000, sort_in_batch=descending, sort_batch=descending)
[seoultech:0/4] 2024-01-22 13:25:08,094 (abs_task:1528) INFO: [valid] mini-batch sizes summary: N-batch=2848, mean=66.9, min=16, max=512
[seoultech:0/4] 2024-01-22 13:25:08,793 (abs_task:1526) INFO: [plot_att] dataset:
ESPnetDataset(
  speech: {"path": "dump/raw/dev/wav.scp", "type": "sound"}
  text: {"path": "dump/raw/dev/text", "type": "text"}
  preprocess: <espnet2.train.preprocessor.CommonPreprocessor object at 0x7fabb5a388b0>)
[seoultech:0/4] 2024-01-22 13:25:08,793 (abs_task:1527) INFO: [plot_att] Batch sampler: UnsortedBatchSampler(N-batch=190536, batch_size=1, key_file=exp/asr_stats_raw_kr_char/valid/speech_shape, 
[seoultech:0/4] 2024-01-22 13:25:08,793 (abs_task:1528) INFO: [plot_att] mini-batch sizes summary: N-batch=3, mean=1.0, min=1, max=1
seoultech:23052:23052 [0] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:23052:23052 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:23052:23052 [0] NCCL INFO NET/IB : No device found.
seoultech:23052:23052 [0] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:23052:23052 [0] NCCL INFO Using network Socket
NCCL version 2.10.3+cuda11.6
seoultech:23054:23054 [2] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:23054:23054 [2] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:23053:23053 [1] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:23055:23055 [3] NCCL INFO Bootstrap : Using eno1:117.17.185.208<0>
seoultech:23053:23053 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:23055:23055 [3] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation
seoultech:23054:23054 [2] NCCL INFO NET/IB : No device found.
seoultech:23054:23054 [2] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:23054:23054 [2] NCCL INFO Using network Socket
seoultech:23053:23053 [1] NCCL INFO NET/IB : No device found.
seoultech:23055:23055 [3] NCCL INFO NET/IB : No device found.
seoultech:23053:23053 [1] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:23055:23055 [3] NCCL INFO NET/Socket : Using [0]eno1:117.17.185.208<0>
seoultech:23053:23053 [1] NCCL INFO Using network Socket
seoultech:23055:23055 [3] NCCL INFO Using network Socket
seoultech:23052:23105 [0] NCCL INFO Channel 00/02 :    0   1   2   3
seoultech:23055:23108 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
seoultech:23054:23106 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
seoultech:23052:23105 [0] NCCL INFO Channel 01/02 :    0   1   2   3
seoultech:23053:23107 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
seoultech:23055:23108 [3] NCCL INFO Setting affinity for GPU 3 to fff0,00fff000
seoultech:23052:23105 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1
seoultech:23054:23106 [2] NCCL INFO Setting affinity for GPU 2 to fff0,00fff000
seoultech:23053:23107 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff
seoultech:23052:23105 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff
seoultech:23054:23106 [2] NCCL INFO Channel 00 : 2[b1000] -> 3[ca000] via direct shared memory
seoultech:23054:23106 [2] NCCL INFO Channel 01 : 2[b1000] -> 3[ca000] via direct shared memory
seoultech:23055:23108 [3] NCCL INFO Channel 00 : 3[ca000] -> 0[31000] via direct shared memory
seoultech:23055:23108 [3] NCCL INFO Channel 01 : 3[ca000] -> 0[31000] via direct shared memory
seoultech:23052:23105 [0] NCCL INFO Channel 00 : 0[31000] -> 1[4b000] via direct shared memory
seoultech:23053:23107 [1] NCCL INFO Channel 00 : 1[4b000] -> 2[b1000] via direct shared memory
seoultech:23052:23105 [0] NCCL INFO Channel 01 : 0[31000] -> 1[4b000] via direct shared memory
seoultech:23053:23107 [1] NCCL INFO Channel 01 : 1[4b000] -> 2[b1000] via direct shared memory
seoultech:23054:23106 [2] NCCL INFO Connected all rings
seoultech:23055:23108 [3] NCCL INFO Connected all rings
seoultech:23055:23108 [3] NCCL INFO Channel 00 : 3[ca000] -> 2[b1000] via direct shared memory
seoultech:23055:23108 [3] NCCL INFO Channel 01 : 3[ca000] -> 2[b1000] via direct shared memory
seoultech:23053:23107 [1] NCCL INFO Connected all rings
seoultech:23052:23105 [0] NCCL INFO Connected all rings
seoultech:23054:23106 [2] NCCL INFO Channel 00 : 2[b1000] -> 1[4b000] via direct shared memory
seoultech:23054:23106 [2] NCCL INFO Channel 01 : 2[b1000] -> 1[4b000] via direct shared memory
seoultech:23055:23108 [3] NCCL INFO Connected all trees
seoultech:23055:23108 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
seoultech:23055:23108 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:23053:23107 [1] NCCL INFO Channel 00 : 1[4b000] -> 0[31000] via direct shared memory
seoultech:23053:23107 [1] NCCL INFO Channel 01 : 1[4b000] -> 0[31000] via direct shared memory
seoultech:23052:23105 [0] NCCL INFO Connected all trees
seoultech:23052:23105 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
seoultech:23052:23105 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:23053:23107 [1] NCCL INFO Connected all trees
seoultech:23053:23107 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
seoultech:23053:23107 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:23054:23106 [2] NCCL INFO Connected all trees
seoultech:23054:23106 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 8/8/512
seoultech:23054:23106 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer
seoultech:23054:23106 [2] NCCL INFO comm 0x7f508c003020 rank 2 nranks 4 cudaDev 2 busId b1000 - Init COMPLETE
seoultech:23055:23108 [3] NCCL INFO comm 0x7f4564003020 rank 3 nranks 4 cudaDev 3 busId ca000 - Init COMPLETE
seoultech:23053:23107 [1] NCCL INFO comm 0x7efb78003020 rank 1 nranks 4 cudaDev 1 busId 4b000 - Init COMPLETE
seoultech:23052:23105 [0] NCCL INFO comm 0x7faa40003020 rank 0 nranks 4 cudaDev 0 busId 31000 - Init COMPLETE
seoultech:23052:23052 [0] NCCL INFO Launch mode Parallel
[seoultech:0/4] 2024-01-22 13:25:09,172 (trainer:276) INFO: 1/35epoch started
/home/bootcamp/espnet/espnet2/layers/stft.py:164: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  olens = (ilens - self.n_fft) // self.hop_length + 1
[seoultech:0/4] 2024-01-22 13:25:19,970 (distributed:995) INFO: Reducer buckets have been rebuilt in this iteration.
[seoultech:0/4] 2024-01-22 13:31:03,795 (trainer:710) INFO: 1epoch:train:1-1118batch: iter_time=3.188e-04, forward_time=0.071, loss_ctc=332.114, loss_att=271.137, acc=0.142, loss=289.430, backward_time=0.094, optim_step_time=0.041, optim0_lr0=2.802e-06, train_time=0.317
[seoultech:0/4] 2024-01-22 13:36:50,371 (trainer:710) INFO: 1epoch:train:1119-2236batch: iter_time=1.050e-04, forward_time=0.068, loss_ctc=211.679, loss_att=170.611, acc=0.308, loss=182.931, backward_time=0.094, optim_step_time=0.044, optim0_lr0=8.392e-06, train_time=0.310
[seoultech:0/4] 2024-01-22 13:42:37,167 (trainer:710) INFO: 1epoch:train:2237-3354batch: iter_time=1.033e-04, forward_time=0.068, loss_ctc=197.210, loss_att=147.376, acc=0.350, loss=162.327, backward_time=0.094, optim_step_time=0.043, optim0_lr0=1.398e-05, train_time=0.310
[seoultech:0/4] 2024-01-22 13:48:22,870 (trainer:710) INFO: 1epoch:train:3355-4472batch: iter_time=1.038e-04, forward_time=0.068, loss_ctc=193.189, loss_att=138.846, acc=0.367, loss=155.149, backward_time=0.094, optim_step_time=0.046, optim0_lr0=1.957e-05, train_time=0.309
[seoultech:0/4] 2024-01-22 13:54:05,749 (trainer:710) INFO: 1epoch:train:4473-5590batch: iter_time=1.031e-04, forward_time=0.068, loss_ctc=193.706, loss_att=136.624, acc=0.376, loss=153.748, backward_time=0.094, optim_step_time=0.045, optim0_lr0=2.516e-05, train_time=0.306
[seoultech:0/4] 2024-01-22 13:59:45,993 (trainer:710) INFO: 1epoch:train:5591-6708batch: iter_time=9.606e-05, forward_time=0.068, loss_ctc=189.524, loss_att=132.621, acc=0.387, loss=149.692, backward_time=0.094, optim_step_time=0.042, optim0_lr0=3.075e-05, train_time=0.304
[seoultech:0/4] 2024-01-22 14:05:18,307 (trainer:710) INFO: 1epoch:train:6709-7826batch: iter_time=9.048e-05, forward_time=0.066, loss_ctc=195.720, loss_att=137.734, acc=0.395, loss=155.130, backward_time=0.094, optim_step_time=0.037, optim0_lr0=3.634e-05, train_time=0.297
[seoultech:0/4] 2024-01-22 14:11:04,324 (trainer:710) INFO: 1epoch:train:7827-8944batch: iter_time=8.942e-05, forward_time=0.067, loss_ctc=172.500, loss_att=122.227, acc=0.411, loss=137.309, backward_time=0.094, optim_step_time=0.038, optim0_lr0=4.193e-05, train_time=0.309
[seoultech:0/4] 2024-01-22 14:16:52,794 (trainer:710) INFO: 1epoch:train:8945-10062batch: iter_time=1.070e-04, forward_time=0.069, loss_ctc=175.383, loss_att=126.625, acc=0.418, loss=141.252, backward_time=0.095, optim_step_time=0.046, optim0_lr0=4.752e-05, train_time=0.311
[seoultech:0/4] 2024-01-22 14:22:29,939 (trainer:710) INFO: 1epoch:train:10063-11180batch: iter_time=9.335e-05, forward_time=0.067, loss_ctc=158.764, loss_att=119.206, acc=0.434, loss=131.073, backward_time=0.095, optim_step_time=0.039, optim0_lr0=5.311e-05, train_time=0.301
[seoultech:0/4] 2024-01-22 14:28:13,160 (trainer:710) INFO: 1epoch:train:11181-12298batch: iter_time=1.023e-04, forward_time=0.067, loss_ctc=142.432, loss_att=115.594, acc=0.442, loss=123.645, backward_time=0.094, optim_step_time=0.042, optim0_lr0=5.870e-05, train_time=0.307
[seoultech:0/4] 2024-01-22 14:34:05,668 (trainer:710) INFO: 1epoch:train:12299-13416batch: iter_time=1.057e-04, forward_time=0.068, loss_ctc=124.965, loss_att=107.043, acc=0.466, loss=112.420, backward_time=0.094, optim_step_time=0.044, optim0_lr0=6.429e-05, train_time=0.315
[seoultech:0/4] 2024-01-22 14:39:52,364 (trainer:710) INFO: 1epoch:train:13417-14534batch: iter_time=1.089e-04, forward_time=0.068, loss_ctc=119.782, loss_att=103.271, acc=0.500, loss=108.224, backward_time=0.095, optim_step_time=0.043, optim0_lr0=6.988e-05, train_time=0.310
[seoultech:0/4] 2024-01-22 14:45:36,851 (trainer:710) INFO: 1epoch:train:14535-15652batch: iter_time=8.900e-05, forward_time=0.067, loss_ctc=117.558, loss_att=97.368, acc=0.541, loss=103.425, backward_time=0.095, optim_step_time=0.038, optim0_lr0=7.547e-05, train_time=0.308
[seoultech:0/4] 2024-01-22 14:51:19,515 (trainer:710) INFO: 1epoch:train:15653-16770batch: iter_time=1.052e-04, forward_time=0.068, loss_ctc=103.357, loss_att=80.432, acc=0.580, loss=87.310, backward_time=0.094, optim_step_time=0.044, optim0_lr0=8.106e-05, train_time=0.306
[seoultech:0/4] 2024-01-22 14:57:05,005 (trainer:710) INFO: 1epoch:train:16771-17888batch: iter_time=9.580e-05, forward_time=0.067, loss_ctc=97.502, loss_att=72.542, acc=0.608, loss=80.030, backward_time=0.094, optim_step_time=0.041, optim0_lr0=8.665e-05, train_time=0.309
[seoultech:0/4] 2024-01-22 15:02:56,478 (trainer:710) INFO: 1epoch:train:17889-19006batch: iter_time=1.095e-04, forward_time=0.069, loss_ctc=99.792, loss_att=71.447, acc=0.636, loss=79.950, backward_time=0.094, optim_step_time=0.047, optim0_lr0=9.224e-05, train_time=0.314
[seoultech:0/4] 2024-01-22 15:08:46,828 (trainer:710) INFO: 1epoch:train:19007-20124batch: iter_time=9.732e-05, forward_time=0.068, loss_ctc=91.770, loss_att=62.876, acc=0.655, loss=71.544, backward_time=0.094, optim_step_time=0.044, optim0_lr0=9.783e-05, train_time=0.313
[seoultech:0/4] 2024-01-22 15:14:37,894 (trainer:710) INFO: 1epoch:train:20125-21242batch: iter_time=8.816e-05, forward_time=0.067, loss_ctc=92.557, loss_att=62.005, acc=0.676, loss=71.171, backward_time=0.095, optim_step_time=0.040, optim0_lr0=1.034e-04, train_time=0.314
[seoultech:0/4] 2024-01-22 15:20:22,502 (trainer:710) INFO: 1epoch:train:21243-22360batch: iter_time=1.020e-04, forward_time=0.068, loss_ctc=83.938, loss_att=54.180, acc=0.688, loss=63.107, backward_time=0.094, optim_step_time=0.045, optim0_lr0=1.090e-04, train_time=0.308
/home/bootcamp/espnet/espnet2/layers/stft.py:164: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  olens = (ilens - self.n_fft) // self.hop_length + 1
/home/bootcamp/espnet/espnet2/layers/stft.py:164: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  olens = (ilens - self.n_fft) // self.hop_length + 1
/home/bootcamp/espnet/espnet2/layers/stft.py:164: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  olens = (ilens - self.n_fft) // self.hop_length + 1
/home/bootcamp/espnet/espnet2/layers/stft.py:164: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  olens = (ilens - self.n_fft) // self.hop_length + 1
[seoultech:0/4] 2024-01-22 15:29:25,906 (trainer:330) INFO: 1epoch results: [train] iter_time=1.107e-04, forward_time=0.068, loss_ctc=154.164, loss_att=116.140, acc=0.470, loss=127.547, backward_time=0.094, optim_step_time=0.043, optim0_lr0=5.592e-05, train_time=0.309, time=1 hour, 55 minutes and 16.23 seconds, total_count=22364, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=59.457, cer_ctc=0.327, loss_att=39.621, acc=0.796, cer=0.266, wer=0.564, loss=45.572, time=8 minutes and 1.27 seconds, total_count=2848, gpu_max_cached_mem_GB=15.113, [att_plot] time=59.23 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-22 15:29:29,176 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-22 15:29:29,177 (trainer:264) INFO: 2/35epoch started. Estimated time to finish: 2 days, 22 hours and 27 minutes
[seoultech:0/4] 2024-01-22 15:35:28,441 (trainer:710) INFO: 2epoch:train:1-1118batch: iter_time=2.504e-04, forward_time=0.067, loss_ctc=84.796, loss_att=53.423, acc=0.709, loss=62.835, backward_time=0.094, optim_step_time=0.040, optim0_lr0=1.146e-04, train_time=0.321
[seoultech:0/4] 2024-01-22 15:41:16,275 (trainer:710) INFO: 2epoch:train:1119-2236batch: iter_time=9.787e-05, forward_time=0.068, loss_ctc=79.050, loss_att=48.591, acc=0.716, loss=57.729, backward_time=0.096, optim_step_time=0.044, optim0_lr0=1.202e-04, train_time=0.311
[seoultech:0/4] 2024-01-22 15:47:01,979 (trainer:710) INFO: 2epoch:train:2237-3354batch: iter_time=8.851e-05, forward_time=0.067, loss_ctc=80.311, loss_att=48.703, acc=0.729, loss=58.186, backward_time=0.095, optim_step_time=0.040, optim0_lr0=1.258e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 15:52:45,300 (trainer:710) INFO: 2epoch:train:3355-4472batch: iter_time=9.257e-05, forward_time=0.067, loss_ctc=74.633, loss_att=44.231, acc=0.731, loss=53.351, backward_time=0.094, optim_step_time=0.042, optim0_lr0=1.314e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 15:58:29,642 (trainer:710) INFO: 2epoch:train:4473-5590batch: iter_time=9.043e-05, forward_time=0.067, loss_ctc=75.809, loss_att=44.564, acc=0.744, loss=53.937, backward_time=0.095, optim_step_time=0.039, optim0_lr0=1.370e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 16:04:18,494 (trainer:710) INFO: 2epoch:train:5591-6708batch: iter_time=9.618e-05, forward_time=0.068, loss_ctc=72.302, loss_att=41.844, acc=0.748, loss=50.981, backward_time=0.095, optim_step_time=0.045, optim0_lr0=1.426e-04, train_time=0.312
[seoultech:0/4] 2024-01-22 16:10:04,634 (trainer:710) INFO: 2epoch:train:6709-7826batch: iter_time=9.075e-05, forward_time=0.067, loss_ctc=72.412, loss_att=41.050, acc=0.758, loss=50.459, backward_time=0.094, optim_step_time=0.041, optim0_lr0=1.482e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 16:15:44,723 (trainer:710) INFO: 2epoch:train:7827-8944batch: iter_time=8.102e-05, forward_time=0.066, loss_ctc=70.675, loss_att=39.770, acc=0.762, loss=49.041, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.538e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 16:21:23,035 (trainer:710) INFO: 2epoch:train:8945-10062batch: iter_time=8.078e-05, forward_time=0.066, loss_ctc=69.279, loss_att=38.626, acc=0.767, loss=47.822, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.593e-04, train_time=0.302
[seoultech:0/4] 2024-01-22 16:27:06,047 (trainer:710) INFO: 2epoch:train:10063-11180batch: iter_time=8.130e-05, forward_time=0.066, loss_ctc=70.034, loss_att=38.643, acc=0.771, loss=48.060, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.649e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 16:32:48,489 (trainer:710) INFO: 2epoch:train:11181-12298batch: iter_time=8.145e-05, forward_time=0.066, loss_ctc=68.086, loss_att=37.168, acc=0.775, loss=46.443, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.705e-04, train_time=0.306
[seoultech:0/4] 2024-01-22 16:38:29,619 (trainer:710) INFO: 2epoch:train:12299-13416batch: iter_time=8.120e-05, forward_time=0.066, loss_ctc=66.581, loss_att=35.852, acc=0.775, loss=45.071, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.761e-04, train_time=0.305
[seoultech:0/4] 2024-01-22 16:44:10,668 (trainer:710) INFO: 2epoch:train:13417-14534batch: iter_time=8.093e-05, forward_time=0.066, loss_ctc=66.797, loss_att=35.625, acc=0.783, loss=44.976, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.817e-04, train_time=0.305
[seoultech:0/4] 2024-01-22 16:49:55,984 (trainer:710) INFO: 2epoch:train:14535-15652batch: iter_time=8.062e-05, forward_time=0.066, loss_ctc=64.398, loss_att=34.283, acc=0.781, loss=43.318, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.873e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 16:55:34,541 (trainer:710) INFO: 2epoch:train:15653-16770batch: iter_time=8.128e-05, forward_time=0.066, loss_ctc=66.246, loss_att=34.857, acc=0.789, loss=44.274, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.929e-04, train_time=0.303
[seoultech:0/4] 2024-01-22 17:01:21,931 (trainer:710) INFO: 2epoch:train:16771-17888batch: iter_time=8.162e-05, forward_time=0.066, loss_ctc=63.558, loss_att=33.309, acc=0.787, loss=42.384, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.983e-04, train_time=0.311
[seoultech:0/4] 2024-01-22 17:07:05,292 (trainer:710) INFO: 2epoch:train:17889-19006batch: iter_time=8.069e-05, forward_time=0.066, loss_ctc=62.229, loss_att=32.319, acc=0.793, loss=41.292, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.980e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 17:12:38,023 (trainer:710) INFO: 2epoch:train:19007-20124batch: iter_time=8.030e-05, forward_time=0.065, loss_ctc=59.918, loss_att=30.877, acc=0.797, loss=39.590, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.953e-04, train_time=0.297
[seoultech:0/4] 2024-01-22 17:18:18,076 (trainer:710) INFO: 2epoch:train:20125-21242batch: iter_time=8.050e-05, forward_time=0.066, loss_ctc=60.680, loss_att=31.136, acc=0.803, loss=39.999, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.928e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 17:24:02,468 (trainer:710) INFO: 2epoch:train:21243-22360batch: iter_time=8.336e-05, forward_time=0.066, loss_ctc=58.130, loss_att=29.555, acc=0.801, loss=38.127, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.903e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 17:33:03,239 (trainer:330) INFO: 2epoch results: [train] iter_time=9.309e-05, forward_time=0.066, loss_ctc=69.247, loss_att=38.684, acc=0.766, loss=47.853, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.641e-04, train_time=0.307, time=1 hour, 54 minutes and 35.71 seconds, total_count=44728, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=37.274, cer_ctc=0.207, loss_att=17.855, acc=0.894, cer=0.141, wer=0.347, loss=23.680, time=7 minutes and 57.81 seconds, total_count=5696, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 0.53 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-22 17:33:09,328 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-22 17:33:09,329 (trainer:264) INFO: 3/35epoch started. Estimated time to finish: 2 days, 20 hours and 12 minutes
[seoultech:0/4] 2024-01-22 17:39:01,650 (trainer:710) INFO: 3epoch:train:1-1118batch: iter_time=2.866e-04, forward_time=0.068, loss_ctc=60.008, loss_att=30.235, acc=0.811, loss=39.167, backward_time=0.096, optim_step_time=0.045, optim0_lr0=1.880e-04, train_time=0.315
[seoultech:0/4] 2024-01-22 17:44:53,672 (trainer:710) INFO: 3epoch:train:1119-2236batch: iter_time=9.949e-05, forward_time=0.069, loss_ctc=58.183, loss_att=29.300, acc=0.813, loss=37.965, backward_time=0.096, optim_step_time=0.047, optim0_lr0=1.857e-04, train_time=0.315
[seoultech:0/4] 2024-01-22 17:50:33,830 (trainer:710) INFO: 3epoch:train:2237-3354batch: iter_time=8.025e-05, forward_time=0.066, loss_ctc=57.969, loss_att=28.970, acc=0.815, loss=37.670, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.835e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 17:56:13,309 (trainer:710) INFO: 3epoch:train:3355-4472batch: iter_time=8.200e-05, forward_time=0.066, loss_ctc=56.973, loss_att=28.369, acc=0.815, loss=36.950, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.814e-04, train_time=0.303
[seoultech:0/4] 2024-01-22 18:01:53,570 (trainer:710) INFO: 3epoch:train:4473-5590batch: iter_time=8.362e-05, forward_time=0.066, loss_ctc=56.080, loss_att=27.725, acc=0.816, loss=36.232, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.793e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 18:07:31,234 (trainer:710) INFO: 3epoch:train:5591-6708batch: iter_time=8.065e-05, forward_time=0.066, loss_ctc=56.545, loss_att=27.906, acc=0.821, loss=36.498, backward_time=0.096, optim_step_time=0.036, optim0_lr0=1.773e-04, train_time=0.302
[seoultech:0/4] 2024-01-22 18:13:10,117 (trainer:710) INFO: 3epoch:train:6709-7826batch: iter_time=8.026e-05, forward_time=0.066, loss_ctc=55.635, loss_att=27.331, acc=0.825, loss=35.822, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.754e-04, train_time=0.303
[seoultech:0/4] 2024-01-22 18:18:41,871 (trainer:710) INFO: 3epoch:train:7827-8944batch: iter_time=7.998e-05, forward_time=0.066, loss_ctc=54.890, loss_att=26.857, acc=0.822, loss=35.267, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.736e-04, train_time=0.297
[seoultech:0/4] 2024-01-22 18:24:13,832 (trainer:710) INFO: 3epoch:train:8945-10062batch: iter_time=7.882e-05, forward_time=0.066, loss_ctc=55.090, loss_att=26.914, acc=0.827, loss=35.367, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.718e-04, train_time=0.297
[seoultech:0/4] 2024-01-22 18:30:00,990 (trainer:710) INFO: 3epoch:train:10063-11180batch: iter_time=9.648e-05, forward_time=0.068, loss_ctc=53.310, loss_att=25.947, acc=0.827, loss=34.156, backward_time=0.095, optim_step_time=0.045, optim0_lr0=1.700e-04, train_time=0.310
[seoultech:0/4] 2024-01-22 18:35:46,569 (trainer:710) INFO: 3epoch:train:11181-12298batch: iter_time=9.862e-05, forward_time=0.068, loss_ctc=51.220, loss_att=24.999, acc=0.823, loss=32.865, backward_time=0.094, optim_step_time=0.047, optim0_lr0=1.683e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 18:41:31,043 (trainer:710) INFO: 3epoch:train:12299-13416batch: iter_time=9.901e-05, forward_time=0.068, loss_ctc=51.854, loss_att=25.136, acc=0.829, loss=33.152, backward_time=0.095, optim_step_time=0.046, optim0_lr0=1.667e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 18:47:11,530 (trainer:710) INFO: 3epoch:train:13417-14534batch: iter_time=8.973e-05, forward_time=0.067, loss_ctc=52.633, loss_att=25.439, acc=0.832, loss=33.597, backward_time=0.095, optim_step_time=0.041, optim0_lr0=1.651e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 18:52:50,889 (trainer:710) INFO: 3epoch:train:14535-15652batch: iter_time=8.231e-05, forward_time=0.066, loss_ctc=52.361, loss_att=25.131, acc=0.833, loss=33.300, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.635e-04, train_time=0.303
[seoultech:0/4] 2024-01-22 18:58:23,591 (trainer:710) INFO: 3epoch:train:15653-16770batch: iter_time=8.158e-05, forward_time=0.066, loss_ctc=50.481, loss_att=24.291, acc=0.828, loss=32.148, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.620e-04, train_time=0.297
[seoultech:0/4] 2024-01-22 19:04:09,898 (trainer:710) INFO: 3epoch:train:16771-17888batch: iter_time=9.754e-05, forward_time=0.068, loss_ctc=49.906, loss_att=24.014, acc=0.833, loss=31.782, backward_time=0.095, optim_step_time=0.045, optim0_lr0=1.606e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 19:09:54,521 (trainer:710) INFO: 3epoch:train:17889-19006batch: iter_time=1.004e-04, forward_time=0.068, loss_ctc=48.898, loss_att=23.362, acc=0.832, loss=31.023, backward_time=0.094, optim_step_time=0.047, optim0_lr0=1.591e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 19:15:40,609 (trainer:710) INFO: 3epoch:train:19007-20124batch: iter_time=1.054e-04, forward_time=0.068, loss_ctc=49.108, loss_att=23.441, acc=0.834, loss=31.141, backward_time=0.095, optim_step_time=0.047, optim0_lr0=1.578e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 19:21:24,163 (trainer:710) INFO: 3epoch:train:20125-21242batch: iter_time=8.795e-05, forward_time=0.067, loss_ctc=49.854, loss_att=23.689, acc=0.836, loss=31.538, backward_time=0.094, optim_step_time=0.040, optim0_lr0=1.564e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 19:27:08,284 (trainer:710) INFO: 3epoch:train:21243-22360batch: iter_time=8.138e-05, forward_time=0.066, loss_ctc=49.051, loss_att=23.251, acc=0.836, loss=30.991, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.551e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 19:36:09,434 (trainer:330) INFO: 3epoch results: [train] iter_time=9.861e-05, forward_time=0.067, loss_ctc=53.448, loss_att=26.083, acc=0.826, loss=34.292, backward_time=0.095, optim_step_time=0.041, optim0_lr0=1.700e-04, train_time=0.306, time=1 hour, 54 minutes and 1.39 seconds, total_count=67092, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=31.299, cer_ctc=0.179, loss_att=13.806, acc=0.915, cer=0.113, wer=0.297, loss=19.054, time=7 minutes and 58.34 seconds, total_count=8544, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 0.37 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-22 19:36:15,877 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-22 19:36:15,878 (trainer:264) INFO: 4/35epoch started. Estimated time to finish: 2 days, 17 hours and 58 minutes
[seoultech:0/4] 2024-01-22 19:42:06,101 (trainer:710) INFO: 4epoch:train:1-1118batch: iter_time=2.567e-04, forward_time=0.066, loss_ctc=48.992, loss_att=23.164, acc=0.843, loss=30.913, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.538e-04, train_time=0.313
[seoultech:0/4] 2024-01-22 19:47:41,704 (trainer:710) INFO: 4epoch:train:1119-2236batch: iter_time=7.947e-05, forward_time=0.066, loss_ctc=49.464, loss_att=23.362, acc=0.844, loss=31.193, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.525e-04, train_time=0.300
[seoultech:0/4] 2024-01-22 19:53:22,036 (trainer:710) INFO: 4epoch:train:2237-3354batch: iter_time=7.925e-05, forward_time=0.065, loss_ctc=48.610, loss_att=22.886, acc=0.844, loss=30.603, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.513e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 19:58:59,017 (trainer:710) INFO: 4epoch:train:3355-4472batch: iter_time=7.945e-05, forward_time=0.066, loss_ctc=48.988, loss_att=22.916, acc=0.842, loss=30.738, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.501e-04, train_time=0.301
[seoultech:0/4] 2024-01-22 20:04:43,171 (trainer:710) INFO: 4epoch:train:4473-5590batch: iter_time=9.434e-05, forward_time=0.068, loss_ctc=46.802, loss_att=22.124, acc=0.840, loss=29.527, backward_time=0.096, optim_step_time=0.044, optim0_lr0=1.489e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 20:10:30,926 (trainer:710) INFO: 4epoch:train:5591-6708batch: iter_time=9.999e-05, forward_time=0.069, loss_ctc=46.872, loss_att=21.974, acc=0.842, loss=29.443, backward_time=0.095, optim_step_time=0.047, optim0_lr0=1.478e-04, train_time=0.311
[seoultech:0/4] 2024-01-22 20:16:08,247 (trainer:710) INFO: 4epoch:train:6709-7826batch: iter_time=8.276e-05, forward_time=0.066, loss_ctc=48.408, loss_att=22.717, acc=0.848, loss=30.424, backward_time=0.095, optim_step_time=0.037, optim0_lr0=1.467e-04, train_time=0.302
[seoultech:0/4] 2024-01-22 20:21:53,528 (trainer:710) INFO: 4epoch:train:7827-8944batch: iter_time=8.031e-05, forward_time=0.066, loss_ctc=47.719, loss_att=22.310, acc=0.846, loss=29.933, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.456e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 20:27:38,941 (trainer:710) INFO: 4epoch:train:8945-10062batch: iter_time=8.185e-05, forward_time=0.066, loss_ctc=46.153, loss_att=21.388, acc=0.843, loss=28.817, backward_time=0.095, optim_step_time=0.037, optim0_lr0=1.445e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 20:33:12,041 (trainer:710) INFO: 4epoch:train:10063-11180batch: iter_time=7.973e-05, forward_time=0.066, loss_ctc=45.743, loss_att=21.272, acc=0.842, loss=28.613, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.435e-04, train_time=0.298
[seoultech:0/4] 2024-01-22 20:38:45,735 (trainer:710) INFO: 4epoch:train:11181-12298batch: iter_time=7.924e-05, forward_time=0.065, loss_ctc=46.003, loss_att=21.454, acc=0.845, loss=28.819, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.425e-04, train_time=0.298
[seoultech:0/4] 2024-01-22 20:44:28,252 (trainer:710) INFO: 4epoch:train:12299-13416batch: iter_time=9.039e-05, forward_time=0.067, loss_ctc=47.345, loss_att=21.949, acc=0.854, loss=29.568, backward_time=0.095, optim_step_time=0.041, optim0_lr0=1.415e-04, train_time=0.306
[seoultech:0/4] 2024-01-22 20:50:14,787 (trainer:710) INFO: 4epoch:train:13417-14534batch: iter_time=9.610e-05, forward_time=0.068, loss_ctc=45.654, loss_att=21.084, acc=0.848, loss=28.455, backward_time=0.094, optim_step_time=0.044, optim0_lr0=1.405e-04, train_time=0.310
[seoultech:0/4] 2024-01-22 20:55:53,632 (trainer:710) INFO: 4epoch:train:14535-15652batch: iter_time=8.749e-05, forward_time=0.067, loss_ctc=46.818, loss_att=21.686, acc=0.851, loss=29.226, backward_time=0.096, optim_step_time=0.039, optim0_lr0=1.395e-04, train_time=0.303
[seoultech:0/4] 2024-01-22 21:01:42,519 (trainer:710) INFO: 4epoch:train:15653-16770batch: iter_time=1.035e-04, forward_time=0.069, loss_ctc=46.734, loss_att=21.523, acc=0.854, loss=29.086, backward_time=0.096, optim_step_time=0.047, optim0_lr0=1.386e-04, train_time=0.312
[seoultech:0/4] 2024-01-22 21:07:28,238 (trainer:710) INFO: 4epoch:train:16771-17888batch: iter_time=9.359e-05, forward_time=0.067, loss_ctc=45.716, loss_att=21.036, acc=0.850, loss=28.440, backward_time=0.094, optim_step_time=0.043, optim0_lr0=1.377e-04, train_time=0.309
[seoultech:0/4] 2024-01-22 21:13:14,755 (trainer:710) INFO: 4epoch:train:17889-19006batch: iter_time=9.073e-05, forward_time=0.067, loss_ctc=45.247, loss_att=20.891, acc=0.853, loss=28.198, backward_time=0.093, optim_step_time=0.041, optim0_lr0=1.368e-04, train_time=0.310
[seoultech:0/4] 2024-01-22 21:19:02,990 (trainer:710) INFO: 4epoch:train:19007-20124batch: iter_time=1.014e-04, forward_time=0.068, loss_ctc=45.958, loss_att=21.092, acc=0.856, loss=28.552, backward_time=0.094, optim_step_time=0.047, optim0_lr0=1.359e-04, train_time=0.311
[seoultech:0/4] 2024-01-22 21:24:51,937 (trainer:710) INFO: 4epoch:train:20125-21242batch: iter_time=1.005e-04, forward_time=0.068, loss_ctc=44.978, loss_att=20.777, acc=0.853, loss=28.038, backward_time=0.094, optim_step_time=0.046, optim0_lr0=1.350e-04, train_time=0.312
[seoultech:0/4] 2024-01-22 21:30:38,393 (trainer:710) INFO: 4epoch:train:21243-22360batch: iter_time=8.608e-05, forward_time=0.066, loss_ctc=45.305, loss_att=20.769, acc=0.853, loss=28.130, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.342e-04, train_time=0.310
[seoultech:0/4] 2024-01-22 21:39:37,267 (trainer:330) INFO: 4epoch results: [train] iter_time=9.715e-05, forward_time=0.067, loss_ctc=46.860, loss_att=21.811, acc=0.848, loss=29.326, backward_time=0.095, optim_step_time=0.040, optim0_lr0=1.433e-04, train_time=0.307, time=1 hour, 54 minutes and 25.28 seconds, total_count=89456, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=27.397, cer_ctc=0.160, loss_att=11.529, acc=0.926, cer=0.099, wer=0.268, loss=16.290, time=7 minutes and 57.26 seconds, total_count=11392, gpu_max_cached_mem_GB=15.113, [att_plot] time=58.85 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-22 21:39:43,821 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-22 21:39:43,822 (trainer:264) INFO: 5/35epoch started. Estimated time to finish: 2 days, 15 hours and 52 minutes
[seoultech:0/4] 2024-01-22 21:45:38,145 (trainer:710) INFO: 5epoch:train:1-1118batch: iter_time=2.380e-04, forward_time=0.066, loss_ctc=43.718, loss_att=20.034, acc=0.856, loss=27.139, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.333e-04, train_time=0.317
[seoultech:0/4] 2024-01-22 21:51:16,456 (trainer:710) INFO: 5epoch:train:1119-2236batch: iter_time=8.206e-05, forward_time=0.066, loss_ctc=44.961, loss_att=20.507, acc=0.860, loss=27.843, backward_time=0.095, optim_step_time=0.038, optim0_lr0=1.325e-04, train_time=0.302
[seoultech:0/4] 2024-01-22 21:57:01,163 (trainer:710) INFO: 5epoch:train:2237-3354batch: iter_time=9.677e-05, forward_time=0.068, loss_ctc=44.410, loss_att=20.408, acc=0.857, loss=27.609, backward_time=0.096, optim_step_time=0.045, optim0_lr0=1.317e-04, train_time=0.308
[seoultech:0/4] 2024-01-22 22:02:35,596 (trainer:710) INFO: 5epoch:train:3355-4472batch: iter_time=7.883e-05, forward_time=0.066, loss_ctc=44.369, loss_att=20.313, acc=0.859, loss=27.530, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.309e-04, train_time=0.299
[seoultech:0/4] 2024-01-22 22:08:10,617 (trainer:710) INFO: 5epoch:train:4473-5590batch: iter_time=8.270e-05, forward_time=0.066, loss_ctc=43.961, loss_att=20.097, acc=0.858, loss=27.256, backward_time=0.095, optim_step_time=0.038, optim0_lr0=1.301e-04, train_time=0.299
[seoultech:0/4] 2024-01-22 22:13:46,451 (trainer:710) INFO: 5epoch:train:5591-6708batch: iter_time=8.064e-05, forward_time=0.066, loss_ctc=43.942, loss_att=20.081, acc=0.858, loss=27.239, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.294e-04, train_time=0.300
[seoultech:0/4] 2024-01-22 22:19:22,518 (trainer:710) INFO: 5epoch:train:6709-7826batch: iter_time=8.050e-05, forward_time=0.066, loss_ctc=42.173, loss_att=19.336, acc=0.851, loss=26.187, backward_time=0.096, optim_step_time=0.036, optim0_lr0=1.286e-04, train_time=0.300
[seoultech:0/4] 2024-01-22 22:25:05,384 (trainer:710) INFO: 5epoch:train:7827-8944batch: iter_time=8.127e-05, forward_time=0.066, loss_ctc=44.128, loss_att=20.127, acc=0.857, loss=27.328, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.279e-04, train_time=0.306
[seoultech:0/4] 2024-01-22 22:30:48,930 (trainer:710) INFO: 5epoch:train:8945-10062batch: iter_time=9.200e-05, forward_time=0.068, loss_ctc=43.890, loss_att=19.869, acc=0.859, loss=27.076, backward_time=0.095, optim_step_time=0.043, optim0_lr0=1.272e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 22:36:38,146 (trainer:710) INFO: 5epoch:train:10063-11180batch: iter_time=9.998e-05, forward_time=0.069, loss_ctc=43.340, loss_att=19.637, acc=0.857, loss=26.748, backward_time=0.096, optim_step_time=0.047, optim0_lr0=1.264e-04, train_time=0.312
[seoultech:0/4] 2024-01-22 22:42:14,304 (trainer:710) INFO: 5epoch:train:11181-12298batch: iter_time=8.591e-05, forward_time=0.066, loss_ctc=43.440, loss_att=19.691, acc=0.861, loss=26.816, backward_time=0.095, optim_step_time=0.039, optim0_lr0=1.257e-04, train_time=0.300
[seoultech:0/4] 2024-01-22 22:47:54,725 (trainer:710) INFO: 5epoch:train:12299-13416batch: iter_time=8.099e-05, forward_time=0.066, loss_ctc=43.363, loss_att=19.702, acc=0.864, loss=26.800, backward_time=0.096, optim_step_time=0.036, optim0_lr0=1.251e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 22:53:38,024 (trainer:710) INFO: 5epoch:train:13417-14534batch: iter_time=9.514e-05, forward_time=0.068, loss_ctc=42.370, loss_att=19.152, acc=0.860, loss=26.118, backward_time=0.095, optim_step_time=0.044, optim0_lr0=1.244e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 22:59:21,041 (trainer:710) INFO: 5epoch:train:14535-15652batch: iter_time=8.310e-05, forward_time=0.066, loss_ctc=43.491, loss_att=19.625, acc=0.861, loss=26.785, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.237e-04, train_time=0.307
[seoultech:0/4] 2024-01-22 23:05:07,571 (trainer:710) INFO: 5epoch:train:15653-16770batch: iter_time=7.979e-05, forward_time=0.066, loss_ctc=41.847, loss_att=18.850, acc=0.861, loss=25.749, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.231e-04, train_time=0.310
[seoultech:0/4] 2024-01-22 23:10:45,850 (trainer:710) INFO: 5epoch:train:16771-17888batch: iter_time=8.031e-05, forward_time=0.066, loss_ctc=42.423, loss_att=19.272, acc=0.858, loss=26.217, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.224e-04, train_time=0.302
[seoultech:0/4] 2024-01-22 23:16:26,474 (trainer:710) INFO: 5epoch:train:17889-19006batch: iter_time=8.084e-05, forward_time=0.065, loss_ctc=43.002, loss_att=19.418, acc=0.865, loss=26.493, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.218e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 23:22:13,901 (trainer:710) INFO: 5epoch:train:19007-20124batch: iter_time=9.799e-05, forward_time=0.068, loss_ctc=41.419, loss_att=18.779, acc=0.858, loss=25.571, backward_time=0.095, optim_step_time=0.045, optim0_lr0=1.211e-04, train_time=0.310
[seoultech:0/4] 2024-01-22 23:27:45,369 (trainer:710) INFO: 5epoch:train:20125-21242batch: iter_time=7.939e-05, forward_time=0.065, loss_ctc=41.603, loss_att=18.754, acc=0.860, loss=25.609, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.205e-04, train_time=0.296
[seoultech:0/4] 2024-01-22 23:33:22,662 (trainer:710) INFO: 5epoch:train:21243-22360batch: iter_time=7.988e-05, forward_time=0.066, loss_ctc=43.095, loss_att=19.483, acc=0.865, loss=26.566, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.199e-04, train_time=0.301
[seoultech:0/4] 2024-01-22 23:42:26,526 (trainer:330) INFO: 5epoch results: [train] iter_time=9.280e-05, forward_time=0.066, loss_ctc=43.233, loss_att=19.650, acc=0.859, loss=26.725, backward_time=0.095, optim_step_time=0.039, optim0_lr0=1.263e-04, train_time=0.305, time=1 hour, 53 minutes and 41.3 seconds, total_count=111820, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=25.696, cer_ctc=0.153, loss_att=10.611, acc=0.931, cer=0.093, wer=0.255, loss=15.137, time=7 minutes and 57.99 seconds, total_count=14240, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 3.41 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-22 23:42:32,574 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-22 23:42:32,574 (trainer:264) INFO: 6/35epoch started. Estimated time to finish: 2 days, 13 hours and 44 minutes
[seoultech:0/4] 2024-01-22 23:48:26,807 (trainer:710) INFO: 6epoch:train:1-1118batch: iter_time=2.549e-04, forward_time=0.067, loss_ctc=41.133, loss_att=18.486, acc=0.864, loss=25.280, backward_time=0.094, optim_step_time=0.040, optim0_lr0=1.193e-04, train_time=0.317
[seoultech:0/4] 2024-01-22 23:54:07,162 (trainer:710) INFO: 6epoch:train:1119-2236batch: iter_time=7.851e-05, forward_time=0.067, loss_ctc=41.371, loss_att=18.635, acc=0.866, loss=25.455, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.187e-04, train_time=0.304
[seoultech:0/4] 2024-01-22 23:59:51,108 (trainer:710) INFO: 6epoch:train:2237-3354batch: iter_time=8.956e-05, forward_time=0.067, loss_ctc=41.410, loss_att=18.601, acc=0.867, loss=25.444, backward_time=0.094, optim_step_time=0.042, optim0_lr0=1.182e-04, train_time=0.307
[seoultech:0/4] 2024-01-23 00:05:41,935 (trainer:710) INFO: 6epoch:train:3355-4472batch: iter_time=7.954e-05, forward_time=0.066, loss_ctc=41.479, loss_att=18.695, acc=0.867, loss=25.530, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.176e-04, train_time=0.314
[seoultech:0/4] 2024-01-23 00:11:25,509 (trainer:710) INFO: 6epoch:train:4473-5590batch: iter_time=7.971e-05, forward_time=0.066, loss_ctc=42.182, loss_att=18.920, acc=0.869, loss=25.898, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.170e-04, train_time=0.307
[seoultech:0/4] 2024-01-23 00:17:10,719 (trainer:710) INFO: 6epoch:train:5591-6708batch: iter_time=7.933e-05, forward_time=0.066, loss_ctc=39.980, loss_att=18.012, acc=0.861, loss=24.602, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.165e-04, train_time=0.309
[seoultech:0/4] 2024-01-23 00:22:52,450 (trainer:710) INFO: 6epoch:train:6709-7826batch: iter_time=7.997e-05, forward_time=0.065, loss_ctc=40.878, loss_att=18.289, acc=0.867, loss=25.066, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.159e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 00:28:35,129 (trainer:710) INFO: 6epoch:train:7827-8944batch: iter_time=8.353e-05, forward_time=0.066, loss_ctc=41.895, loss_att=18.751, acc=0.870, loss=25.694, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.154e-04, train_time=0.306
[seoultech:0/4] 2024-01-23 00:34:22,280 (trainer:710) INFO: 6epoch:train:8945-10062batch: iter_time=9.370e-05, forward_time=0.068, loss_ctc=41.164, loss_att=18.473, acc=0.867, loss=25.280, backward_time=0.094, optim_step_time=0.043, optim0_lr0=1.148e-04, train_time=0.310
[seoultech:0/4] 2024-01-23 00:39:59,779 (trainer:710) INFO: 6epoch:train:10063-11180batch: iter_time=7.870e-05, forward_time=0.065, loss_ctc=39.781, loss_att=17.879, acc=0.862, loss=24.450, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.143e-04, train_time=0.302
[seoultech:0/4] 2024-01-23 00:45:37,835 (trainer:710) INFO: 6epoch:train:11181-12298batch: iter_time=7.996e-05, forward_time=0.066, loss_ctc=41.051, loss_att=18.312, acc=0.867, loss=25.133, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.138e-04, train_time=0.302
[seoultech:0/4] 2024-01-23 00:51:19,348 (trainer:710) INFO: 6epoch:train:12299-13416batch: iter_time=8.098e-05, forward_time=0.066, loss_ctc=40.121, loss_att=17.857, acc=0.863, loss=24.536, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.133e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 00:57:01,817 (trainer:710) INFO: 6epoch:train:13417-14534batch: iter_time=8.149e-05, forward_time=0.066, loss_ctc=39.444, loss_att=17.706, acc=0.864, loss=24.227, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.128e-04, train_time=0.306
[seoultech:0/4] 2024-01-23 01:02:44,479 (trainer:710) INFO: 6epoch:train:14535-15652batch: iter_time=8.624e-05, forward_time=0.067, loss_ctc=41.492, loss_att=18.545, acc=0.873, loss=25.429, backward_time=0.096, optim_step_time=0.040, optim0_lr0=1.123e-04, train_time=0.306
[seoultech:0/4] 2024-01-23 01:08:21,454 (trainer:710) INFO: 6epoch:train:15653-16770batch: iter_time=8.449e-05, forward_time=0.066, loss_ctc=40.608, loss_att=18.081, acc=0.868, loss=24.839, backward_time=0.094, optim_step_time=0.039, optim0_lr0=1.118e-04, train_time=0.301
[seoultech:0/4] 2024-01-23 01:14:03,152 (trainer:710) INFO: 6epoch:train:16771-17888batch: iter_time=9.100e-05, forward_time=0.068, loss_ctc=40.288, loss_att=18.116, acc=0.865, loss=24.767, backward_time=0.096, optim_step_time=0.042, optim0_lr0=1.113e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 01:19:42,075 (trainer:710) INFO: 6epoch:train:17889-19006batch: iter_time=8.709e-05, forward_time=0.067, loss_ctc=41.323, loss_att=18.511, acc=0.873, loss=25.355, backward_time=0.096, optim_step_time=0.040, optim0_lr0=1.108e-04, train_time=0.303
[seoultech:0/4] 2024-01-23 01:25:16,675 (trainer:710) INFO: 6epoch:train:19007-20124batch: iter_time=7.944e-05, forward_time=0.065, loss_ctc=39.885, loss_att=17.803, acc=0.866, loss=24.428, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.104e-04, train_time=0.299
[seoultech:0/4] 2024-01-23 01:30:57,187 (trainer:710) INFO: 6epoch:train:20125-21242batch: iter_time=7.909e-05, forward_time=0.066, loss_ctc=40.294, loss_att=17.922, acc=0.869, loss=24.634, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.099e-04, train_time=0.304
[seoultech:0/4] 2024-01-23 01:36:45,341 (trainer:710) INFO: 6epoch:train:21243-22360batch: iter_time=9.117e-05, forward_time=0.068, loss_ctc=40.097, loss_att=17.945, acc=0.867, loss=24.591, backward_time=0.095, optim_step_time=0.043, optim0_lr0=1.094e-04, train_time=0.311
[seoultech:0/4] 2024-01-23 01:45:48,805 (trainer:330) INFO: 6epoch results: [train] iter_time=9.192e-05, forward_time=0.066, loss_ctc=40.780, loss_att=18.271, acc=0.867, loss=25.023, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.142e-04, train_time=0.306, time=1 hour, 54 minutes and 15.52 seconds, total_count=134184, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=24.557, cer_ctc=0.147, loss_att=10.047, acc=0.934, cer=0.089, wer=0.247, loss=14.400, time=7 minutes and 59.66 seconds, total_count=17088, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 1.05 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 01:45:55,805 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 01:45:55,807 (trainer:264) INFO: 7/35epoch started. Estimated time to finish: 2 days, 11 hours and 40 minutes
[seoultech:0/4] 2024-01-23 01:51:58,401 (trainer:710) INFO: 7epoch:train:1-1118batch: iter_time=3.894e-04, forward_time=0.069, loss_ctc=38.751, loss_att=17.273, acc=0.871, loss=23.717, backward_time=0.094, optim_step_time=0.047, optim0_lr0=1.090e-04, train_time=0.324
[seoultech:0/4] 2024-01-23 01:57:42,749 (trainer:710) INFO: 7epoch:train:1119-2236batch: iter_time=9.727e-05, forward_time=0.066, loss_ctc=38.569, loss_att=17.183, acc=0.867, loss=23.599, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.085e-04, train_time=0.308
[seoultech:0/4] 2024-01-23 02:03:21,201 (trainer:710) INFO: 7epoch:train:2237-3354batch: iter_time=8.002e-05, forward_time=0.065, loss_ctc=39.322, loss_att=17.466, acc=0.873, loss=24.023, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.081e-04, train_time=0.303
[seoultech:0/4] 2024-01-23 02:08:55,097 (trainer:710) INFO: 7epoch:train:3355-4472batch: iter_time=8.199e-05, forward_time=0.066, loss_ctc=39.211, loss_att=17.433, acc=0.871, loss=23.966, backward_time=0.095, optim_step_time=0.037, optim0_lr0=1.076e-04, train_time=0.298
[seoultech:0/4] 2024-01-23 02:14:36,387 (trainer:710) INFO: 7epoch:train:4473-5590batch: iter_time=8.290e-05, forward_time=0.066, loss_ctc=39.256, loss_att=17.433, acc=0.872, loss=23.980, backward_time=0.094, optim_step_time=0.037, optim0_lr0=1.072e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 02:20:17,851 (trainer:710) INFO: 7epoch:train:5591-6708batch: iter_time=8.004e-05, forward_time=0.066, loss_ctc=38.990, loss_att=17.284, acc=0.869, loss=23.796, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.068e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 02:26:01,614 (trainer:710) INFO: 7epoch:train:6709-7826batch: iter_time=8.358e-05, forward_time=0.066, loss_ctc=39.264, loss_att=17.513, acc=0.874, loss=24.038, backward_time=0.094, optim_step_time=0.038, optim0_lr0=1.064e-04, train_time=0.307
[seoultech:0/4] 2024-01-23 02:31:50,519 (trainer:710) INFO: 7epoch:train:7827-8944batch: iter_time=1.264e-04, forward_time=0.069, loss_ctc=39.658, loss_att=17.598, acc=0.874, loss=24.216, backward_time=0.096, optim_step_time=0.047, optim0_lr0=1.059e-04, train_time=0.312
[seoultech:0/4] 2024-01-23 02:37:34,543 (trainer:710) INFO: 7epoch:train:8945-10062batch: iter_time=1.078e-04, forward_time=0.068, loss_ctc=37.464, loss_att=16.761, acc=0.868, loss=22.972, backward_time=0.094, optim_step_time=0.047, optim0_lr0=1.055e-04, train_time=0.307
[seoultech:0/4] 2024-01-23 02:43:15,654 (trainer:710) INFO: 7epoch:train:10063-11180batch: iter_time=9.329e-05, forward_time=0.066, loss_ctc=39.319, loss_att=17.487, acc=0.872, loss=24.037, backward_time=0.094, optim_step_time=0.039, optim0_lr0=1.051e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 02:48:50,168 (trainer:710) INFO: 7epoch:train:11181-12298batch: iter_time=7.932e-05, forward_time=0.066, loss_ctc=39.374, loss_att=17.458, acc=0.873, loss=24.033, backward_time=0.095, optim_step_time=0.036, optim0_lr0=1.047e-04, train_time=0.299
[seoultech:0/4] 2024-01-23 02:54:32,208 (trainer:710) INFO: 7epoch:train:12299-13416batch: iter_time=7.891e-05, forward_time=0.066, loss_ctc=39.181, loss_att=17.422, acc=0.873, loss=23.950, backward_time=0.096, optim_step_time=0.036, optim0_lr0=1.043e-04, train_time=0.306
[seoultech:0/4] 2024-01-23 03:00:16,944 (trainer:710) INFO: 7epoch:train:13417-14534batch: iter_time=1.006e-04, forward_time=0.068, loss_ctc=38.805, loss_att=17.272, acc=0.870, loss=23.732, backward_time=0.095, optim_step_time=0.044, optim0_lr0=1.039e-04, train_time=0.308
[seoultech:0/4] 2024-01-23 03:06:03,462 (trainer:710) INFO: 7epoch:train:14535-15652batch: iter_time=8.939e-05, forward_time=0.067, loss_ctc=37.942, loss_att=16.834, acc=0.869, loss=23.166, backward_time=0.094, optim_step_time=0.042, optim0_lr0=1.035e-04, train_time=0.310
[seoultech:0/4] 2024-01-23 03:11:46,182 (trainer:710) INFO: 7epoch:train:15653-16770batch: iter_time=8.979e-05, forward_time=0.068, loss_ctc=40.029, loss_att=17.692, acc=0.878, loss=24.393, backward_time=0.095, optim_step_time=0.041, optim0_lr0=1.031e-04, train_time=0.306
[seoultech:0/4] 2024-01-23 03:17:30,305 (trainer:710) INFO: 7epoch:train:16771-17888batch: iter_time=8.071e-05, forward_time=0.066, loss_ctc=39.495, loss_att=17.598, acc=0.876, loss=24.167, backward_time=0.094, optim_step_time=0.036, optim0_lr0=1.028e-04, train_time=0.308
[seoultech:0/4] 2024-01-23 03:23:11,948 (trainer:710) INFO: 7epoch:train:17889-19006batch: iter_time=7.983e-05, forward_time=0.066, loss_ctc=38.111, loss_att=16.896, acc=0.870, loss=23.261, backward_time=0.093, optim_step_time=0.036, optim0_lr0=1.024e-04, train_time=0.305
[seoultech:0/4] 2024-01-23 03:28:56,356 (trainer:710) INFO: 7epoch:train:19007-20124batch: iter_time=8.692e-05, forward_time=0.067, loss_ctc=38.205, loss_att=16.922, acc=0.870, loss=23.307, backward_time=0.095, optim_step_time=0.040, optim0_lr0=1.020e-04, train_time=0.308
[seoultech:0/4] 2024-01-23 03:34:45,999 (trainer:710) INFO: 7epoch:train:20125-21242batch: iter_time=9.922e-05, forward_time=0.069, loss_ctc=39.022, loss_att=17.342, acc=0.874, loss=23.846, backward_time=0.095, optim_step_time=0.047, optim0_lr0=1.016e-04, train_time=0.312
[seoultech:0/4] 2024-01-23 03:40:34,052 (trainer:710) INFO: 7epoch:train:21243-22360batch: iter_time=9.331e-05, forward_time=0.068, loss_ctc=39.144, loss_att=17.367, acc=0.877, loss=23.900, backward_time=0.094, optim_step_time=0.043, optim0_lr0=1.013e-04, train_time=0.311
[seoultech:0/4] 2024-01-23 03:49:34,168 (trainer:330) INFO: 7epoch results: [train] iter_time=1.050e-04, forward_time=0.067, loss_ctc=38.942, loss_att=17.306, acc=0.872, loss=23.797, backward_time=0.094, optim_step_time=0.040, optim0_lr0=1.050e-04, train_time=0.307, time=1 hour, 54 minutes and 40.71 seconds, total_count=156548, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=23.403, cer_ctc=0.142, loss_att=9.521, acc=0.937, cer=0.084, wer=0.238, loss=13.685, time=7 minutes and 57.69 seconds, total_count=19936, gpu_max_cached_mem_GB=15.113, [att_plot] time=59.96 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 03:49:41,700 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 03:49:41,701 (trainer:264) INFO: 8/35epoch started. Estimated time to finish: 2 days, 9 hours and 38 minutes
[seoultech:0/4] 2024-01-23 03:55:39,654 (trainer:710) INFO: 8epoch:train:1-1118batch: iter_time=2.625e-04, forward_time=0.069, loss_ctc=36.979, loss_att=16.383, acc=0.873, loss=22.562, backward_time=0.095, optim_step_time=0.047, optim0_lr0=1.009e-04, train_time=0.320
[seoultech:0/4] 2024-01-23 04:01:29,995 (trainer:710) INFO: 8epoch:train:1119-2236batch: iter_time=1.049e-04, forward_time=0.069, loss_ctc=38.248, loss_att=16.868, acc=0.879, loss=23.282, backward_time=0.095, optim_step_time=0.047, optim0_lr0=1.006e-04, train_time=0.313
[seoultech:0/4] 2024-01-23 04:07:14,065 (trainer:710) INFO: 8epoch:train:2237-3354batch: iter_time=9.284e-05, forward_time=0.068, loss_ctc=37.796, loss_att=16.764, acc=0.873, loss=23.074, backward_time=0.096, optim_step_time=0.042, optim0_lr0=1.002e-04, train_time=0.308
[seoultech:0/4] 2024-01-23 04:12:47,397 (trainer:710) INFO: 8epoch:train:3355-4472batch: iter_time=8.068e-05, forward_time=0.066, loss_ctc=38.126, loss_att=16.891, acc=0.875, loss=23.261, backward_time=0.096, optim_step_time=0.036, optim0_lr0=9.986e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 04:18:26,646 (trainer:710) INFO: 8epoch:train:4473-5590batch: iter_time=8.079e-05, forward_time=0.066, loss_ctc=37.968, loss_att=16.872, acc=0.877, loss=23.201, backward_time=0.095, optim_step_time=0.036, optim0_lr0=9.951e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 04:24:12,708 (trainer:710) INFO: 8epoch:train:5591-6708batch: iter_time=8.204e-05, forward_time=0.066, loss_ctc=37.489, loss_att=16.603, acc=0.874, loss=22.869, backward_time=0.093, optim_step_time=0.036, optim0_lr0=9.917e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 04:29:54,874 (trainer:710) INFO: 8epoch:train:6709-7826batch: iter_time=8.122e-05, forward_time=0.066, loss_ctc=37.044, loss_att=16.421, acc=0.875, loss=22.608, backward_time=0.093, optim_step_time=0.036, optim0_lr0=9.883e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 04:35:39,877 (trainer:710) INFO: 8epoch:train:7827-8944batch: iter_time=8.100e-05, forward_time=0.066, loss_ctc=37.734, loss_att=16.671, acc=0.876, loss=22.990, backward_time=0.093, optim_step_time=0.036, optim0_lr0=9.849e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 04:41:13,160 (trainer:710) INFO: 8epoch:train:8945-10062batch: iter_time=7.929e-05, forward_time=0.065, loss_ctc=37.420, loss_att=16.481, acc=0.874, loss=22.762, backward_time=0.095, optim_step_time=0.036, optim0_lr0=9.816e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 04:46:53,402 (trainer:710) INFO: 8epoch:train:10063-11180batch: iter_time=8.249e-05, forward_time=0.066, loss_ctc=37.066, loss_att=16.501, acc=0.875, loss=22.671, backward_time=0.094, optim_step_time=0.036, optim0_lr0=9.783e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 04:52:29,479 (trainer:710) INFO: 8epoch:train:11181-12298batch: iter_time=8.155e-05, forward_time=0.065, loss_ctc=36.936, loss_att=16.406, acc=0.873, loss=22.565, backward_time=0.094, optim_step_time=0.036, optim0_lr0=9.751e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 04:58:06,244 (trainer:710) INFO: 8epoch:train:12299-13416batch: iter_time=8.036e-05, forward_time=0.066, loss_ctc=37.785, loss_att=16.698, acc=0.879, loss=23.024, backward_time=0.095, optim_step_time=0.036, optim0_lr0=9.718e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 05:03:56,515 (trainer:710) INFO: 8epoch:train:13417-14534batch: iter_time=8.072e-05, forward_time=0.066, loss_ctc=36.342, loss_att=16.111, acc=0.871, loss=22.180, backward_time=0.093, optim_step_time=0.037, optim0_lr0=9.687e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 05:09:45,557 (trainer:710) INFO: 8epoch:train:14535-15652batch: iter_time=8.437e-05, forward_time=0.067, loss_ctc=37.410, loss_att=16.490, acc=0.876, loss=22.766, backward_time=0.093, optim_step_time=0.038, optim0_lr0=9.655e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 05:15:37,017 (trainer:710) INFO: 8epoch:train:15653-16770batch: iter_time=1.170e-04, forward_time=0.069, loss_ctc=37.781, loss_att=16.638, acc=0.878, loss=22.981, backward_time=0.095, optim_step_time=0.047, optim0_lr0=9.624e-05, train_time=0.314
[seoultech:0/4] 2024-01-23 05:21:28,889 (trainer:710) INFO: 8epoch:train:16771-17888batch: iter_time=1.055e-04, forward_time=0.069, loss_ctc=37.567, loss_att=16.571, acc=0.876, loss=22.870, backward_time=0.094, optim_step_time=0.047, optim0_lr0=9.593e-05, train_time=0.314
[seoultech:0/4] 2024-01-23 05:27:16,038 (trainer:710) INFO: 8epoch:train:17889-19006batch: iter_time=1.069e-04, forward_time=0.069, loss_ctc=37.608, loss_att=16.626, acc=0.877, loss=22.921, backward_time=0.096, optim_step_time=0.047, optim0_lr0=9.562e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 05:32:56,507 (trainer:710) INFO: 8epoch:train:19007-20124batch: iter_time=9.367e-05, forward_time=0.067, loss_ctc=36.956, loss_att=16.281, acc=0.876, loss=22.483, backward_time=0.095, optim_step_time=0.044, optim0_lr0=9.532e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 05:38:33,320 (trainer:710) INFO: 8epoch:train:20125-21242batch: iter_time=7.933e-05, forward_time=0.066, loss_ctc=37.946, loss_att=16.782, acc=0.881, loss=23.131, backward_time=0.095, optim_step_time=0.036, optim0_lr0=9.501e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 05:44:09,117 (trainer:710) INFO: 8epoch:train:21243-22360batch: iter_time=8.446e-05, forward_time=0.066, loss_ctc=38.380, loss_att=16.828, acc=0.882, loss=23.293, backward_time=0.094, optim_step_time=0.037, optim0_lr0=9.472e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 05:53:11,449 (trainer:330) INFO: 8epoch results: [train] iter_time=9.708e-05, forward_time=0.067, loss_ctc=37.521, loss_att=16.591, acc=0.876, loss=22.870, backward_time=0.094, optim_step_time=0.040, optim0_lr0=9.772e-05, train_time=0.307, time=1 hour, 54 minutes and 29.94 seconds, total_count=178912, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=22.635, cer_ctc=0.139, loss_att=9.224, acc=0.938, cer=0.082, wer=0.234, loss=13.248, time=7 minutes and 56.54 seconds, total_count=22784, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 3.27 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 05:53:18,511 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 05:53:18,511 (trainer:264) INFO: 9/35epoch started. Estimated time to finish: 2 days, 7 hours and 35 minutes
[seoultech:0/4] 2024-01-23 05:59:16,445 (trainer:710) INFO: 9epoch:train:1-1118batch: iter_time=2.532e-04, forward_time=0.067, loss_ctc=35.785, loss_att=15.888, acc=0.874, loss=21.857, backward_time=0.094, optim_step_time=0.040, optim0_lr0=9.442e-05, train_time=0.320
[seoultech:0/4] 2024-01-23 06:04:57,388 (trainer:710) INFO: 9epoch:train:1119-2236batch: iter_time=8.111e-05, forward_time=0.066, loss_ctc=35.616, loss_att=15.752, acc=0.875, loss=21.711, backward_time=0.095, optim_step_time=0.036, optim0_lr0=9.413e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 06:10:44,091 (trainer:710) INFO: 9epoch:train:2237-3354batch: iter_time=8.523e-05, forward_time=0.066, loss_ctc=36.047, loss_att=15.875, acc=0.881, loss=21.927, backward_time=0.093, optim_step_time=0.038, optim0_lr0=9.384e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 06:16:29,522 (trainer:710) INFO: 9epoch:train:3355-4472batch: iter_time=9.721e-05, forward_time=0.068, loss_ctc=36.226, loss_att=15.979, acc=0.878, loss=22.053, backward_time=0.094, optim_step_time=0.045, optim0_lr0=9.355e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 06:22:17,337 (trainer:710) INFO: 9epoch:train:4473-5590batch: iter_time=1.000e-04, forward_time=0.068, loss_ctc=36.537, loss_att=16.122, acc=0.879, loss=22.247, backward_time=0.095, optim_step_time=0.047, optim0_lr0=9.326e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 06:28:04,226 (trainer:710) INFO: 9epoch:train:5591-6708batch: iter_time=9.864e-05, forward_time=0.069, loss_ctc=37.042, loss_att=16.213, acc=0.881, loss=22.461, backward_time=0.096, optim_step_time=0.046, optim0_lr0=9.298e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 06:33:52,401 (trainer:710) INFO: 9epoch:train:6709-7826batch: iter_time=1.022e-04, forward_time=0.068, loss_ctc=36.794, loss_att=16.128, acc=0.881, loss=22.328, backward_time=0.094, optim_step_time=0.047, optim0_lr0=9.270e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 06:39:33,415 (trainer:710) INFO: 9epoch:train:7827-8944batch: iter_time=9.184e-05, forward_time=0.067, loss_ctc=36.109, loss_att=15.947, acc=0.879, loss=21.996, backward_time=0.095, optim_step_time=0.042, optim0_lr0=9.243e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 06:45:10,572 (trainer:710) INFO: 9epoch:train:8945-10062batch: iter_time=8.231e-05, forward_time=0.066, loss_ctc=36.642, loss_att=16.138, acc=0.878, loss=22.289, backward_time=0.095, optim_step_time=0.037, optim0_lr0=9.215e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 06:50:55,386 (trainer:710) INFO: 9epoch:train:10063-11180batch: iter_time=1.002e-04, forward_time=0.069, loss_ctc=36.332, loss_att=16.061, acc=0.879, loss=22.143, backward_time=0.095, optim_step_time=0.047, optim0_lr0=9.188e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 06:56:30,012 (trainer:710) INFO: 9epoch:train:11181-12298batch: iter_time=8.751e-05, forward_time=0.066, loss_ctc=36.478, loss_att=16.104, acc=0.881, loss=22.216, backward_time=0.095, optim_step_time=0.038, optim0_lr0=9.161e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 07:02:18,504 (trainer:710) INFO: 9epoch:train:12299-13416batch: iter_time=1.061e-04, forward_time=0.069, loss_ctc=36.749, loss_att=16.285, acc=0.881, loss=22.424, backward_time=0.095, optim_step_time=0.047, optim0_lr0=9.134e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 07:08:06,058 (trainer:710) INFO: 9epoch:train:13417-14534batch: iter_time=9.248e-05, forward_time=0.068, loss_ctc=36.891, loss_att=16.260, acc=0.881, loss=22.449, backward_time=0.095, optim_step_time=0.041, optim0_lr0=9.108e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 07:13:38,734 (trainer:710) INFO: 9epoch:train:14535-15652batch: iter_time=8.089e-05, forward_time=0.066, loss_ctc=36.329, loss_att=15.986, acc=0.876, loss=22.089, backward_time=0.096, optim_step_time=0.036, optim0_lr0=9.081e-05, train_time=0.297
[seoultech:0/4] 2024-01-23 07:19:13,702 (trainer:710) INFO: 9epoch:train:15653-16770batch: iter_time=8.490e-05, forward_time=0.066, loss_ctc=36.276, loss_att=15.997, acc=0.880, loss=22.081, backward_time=0.096, optim_step_time=0.037, optim0_lr0=9.055e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 07:24:46,719 (trainer:710) INFO: 9epoch:train:16771-17888batch: iter_time=8.152e-05, forward_time=0.066, loss_ctc=36.752, loss_att=16.143, acc=0.882, loss=22.326, backward_time=0.095, optim_step_time=0.036, optim0_lr0=9.030e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 07:30:20,977 (trainer:710) INFO: 9epoch:train:17889-19006batch: iter_time=8.125e-05, forward_time=0.066, loss_ctc=36.101, loss_att=15.992, acc=0.879, loss=22.024, backward_time=0.095, optim_step_time=0.035, optim0_lr0=9.004e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 07:36:08,246 (trainer:710) INFO: 9epoch:train:19007-20124batch: iter_time=9.832e-05, forward_time=0.068, loss_ctc=35.661, loss_att=15.714, acc=0.877, loss=21.698, backward_time=0.095, optim_step_time=0.046, optim0_lr0=8.978e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 07:41:52,788 (trainer:710) INFO: 9epoch:train:20125-21242batch: iter_time=8.610e-05, forward_time=0.066, loss_ctc=36.536, loss_att=16.081, acc=0.884, loss=22.217, backward_time=0.094, optim_step_time=0.039, optim0_lr0=8.953e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 07:47:39,139 (trainer:710) INFO: 9epoch:train:21243-22360batch: iter_time=8.149e-05, forward_time=0.066, loss_ctc=35.841, loss_att=15.809, acc=0.880, loss=21.819, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.928e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 07:56:41,752 (trainer:330) INFO: 9epoch results: [train] iter_time=9.863e-05, forward_time=0.067, loss_ctc=36.332, loss_att=16.021, acc=0.879, loss=22.114, backward_time=0.095, optim_step_time=0.041, optim0_lr0=9.178e-05, train_time=0.307, time=1 hour, 54 minutes and 23.13 seconds, total_count=201276, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=22.332, cer_ctc=0.135, loss_att=9.046, acc=0.940, cer=0.080, wer=0.230, loss=13.032, time=7 minutes and 57.16 seconds, total_count=25632, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 2.95 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 07:56:48,587 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 07:56:48,588 (trainer:264) INFO: 10/35epoch started. Estimated time to finish: 2 days, 5 hours and 31 minutes
[seoultech:0/4] 2024-01-23 08:02:48,454 (trainer:710) INFO: 10epoch:train:1-1118batch: iter_time=2.791e-04, forward_time=0.068, loss_ctc=34.753, loss_att=15.389, acc=0.880, loss=21.198, backward_time=0.095, optim_step_time=0.043, optim0_lr0=8.903e-05, train_time=0.322
[seoultech:0/4] 2024-01-23 08:08:35,336 (trainer:710) INFO: 10epoch:train:1119-2236batch: iter_time=9.517e-05, forward_time=0.068, loss_ctc=35.243, loss_att=15.531, acc=0.882, loss=21.444, backward_time=0.095, optim_step_time=0.044, optim0_lr0=8.879e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 08:14:17,537 (trainer:710) INFO: 10epoch:train:2237-3354batch: iter_time=8.943e-05, forward_time=0.067, loss_ctc=34.878, loss_att=15.446, acc=0.880, loss=21.276, backward_time=0.095, optim_step_time=0.042, optim0_lr0=8.855e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 08:19:58,491 (trainer:710) INFO: 10epoch:train:3355-4472batch: iter_time=8.880e-05, forward_time=0.067, loss_ctc=35.864, loss_att=15.768, acc=0.882, loss=21.797, backward_time=0.096, optim_step_time=0.041, optim0_lr0=8.830e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 08:25:40,539 (trainer:710) INFO: 10epoch:train:4473-5590batch: iter_time=8.329e-05, forward_time=0.066, loss_ctc=34.830, loss_att=15.387, acc=0.880, loss=21.220, backward_time=0.095, optim_step_time=0.038, optim0_lr0=8.806e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 08:31:23,828 (trainer:710) INFO: 10epoch:train:5591-6708batch: iter_time=7.954e-05, forward_time=0.066, loss_ctc=35.498, loss_att=15.611, acc=0.882, loss=21.577, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.783e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 08:37:13,162 (trainer:710) INFO: 10epoch:train:6709-7826batch: iter_time=8.038e-05, forward_time=0.066, loss_ctc=35.193, loss_att=15.543, acc=0.882, loss=21.438, backward_time=0.094, optim_step_time=0.037, optim0_lr0=8.759e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 08:42:57,927 (trainer:710) INFO: 10epoch:train:7827-8944batch: iter_time=8.038e-05, forward_time=0.066, loss_ctc=35.844, loss_att=15.765, acc=0.883, loss=21.788, backward_time=0.096, optim_step_time=0.036, optim0_lr0=8.736e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 08:48:41,622 (trainer:710) INFO: 10epoch:train:8945-10062batch: iter_time=8.061e-05, forward_time=0.066, loss_ctc=34.962, loss_att=15.345, acc=0.879, loss=21.230, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.713e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 08:54:30,581 (trainer:710) INFO: 10epoch:train:10063-11180batch: iter_time=9.148e-05, forward_time=0.067, loss_ctc=35.248, loss_att=15.531, acc=0.880, loss=21.446, backward_time=0.095, optim_step_time=0.042, optim0_lr0=8.690e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 09:00:21,005 (trainer:710) INFO: 10epoch:train:11181-12298batch: iter_time=1.007e-04, forward_time=0.069, loss_ctc=34.081, loss_att=15.053, acc=0.877, loss=20.762, backward_time=0.095, optim_step_time=0.047, optim0_lr0=8.667e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 09:06:11,522 (trainer:710) INFO: 10epoch:train:12299-13416batch: iter_time=1.010e-04, forward_time=0.068, loss_ctc=35.588, loss_att=15.668, acc=0.880, loss=21.644, backward_time=0.094, optim_step_time=0.045, optim0_lr0=8.644e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 09:11:53,127 (trainer:710) INFO: 10epoch:train:13417-14534batch: iter_time=8.066e-05, forward_time=0.066, loss_ctc=36.401, loss_att=16.043, acc=0.886, loss=22.150, backward_time=0.094, optim_step_time=0.036, optim0_lr0=8.622e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 09:17:39,752 (trainer:710) INFO: 10epoch:train:14535-15652batch: iter_time=1.230e-04, forward_time=0.068, loss_ctc=35.726, loss_att=15.709, acc=0.883, loss=21.714, backward_time=0.094, optim_step_time=0.045, optim0_lr0=8.599e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 09:23:24,922 (trainer:710) INFO: 10epoch:train:15653-16770batch: iter_time=1.019e-04, forward_time=0.068, loss_ctc=33.977, loss_att=15.060, acc=0.877, loss=20.735, backward_time=0.095, optim_step_time=0.047, optim0_lr0=8.577e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 09:29:12,926 (trainer:710) INFO: 10epoch:train:16771-17888batch: iter_time=1.005e-04, forward_time=0.068, loss_ctc=35.499, loss_att=15.599, acc=0.884, loss=21.569, backward_time=0.094, optim_step_time=0.047, optim0_lr0=8.555e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 09:34:52,897 (trainer:710) INFO: 10epoch:train:17889-19006batch: iter_time=8.823e-05, forward_time=0.066, loss_ctc=35.478, loss_att=15.592, acc=0.887, loss=21.558, backward_time=0.095, optim_step_time=0.040, optim0_lr0=8.533e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 09:40:32,209 (trainer:710) INFO: 10epoch:train:19007-20124batch: iter_time=8.105e-05, forward_time=0.066, loss_ctc=35.001, loss_att=15.435, acc=0.882, loss=21.305, backward_time=0.094, optim_step_time=0.036, optim0_lr0=8.512e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 09:46:11,363 (trainer:710) INFO: 10epoch:train:20125-21242batch: iter_time=8.093e-05, forward_time=0.066, loss_ctc=35.891, loss_att=15.757, acc=0.885, loss=21.797, backward_time=0.094, optim_step_time=0.036, optim0_lr0=8.490e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 09:51:46,167 (trainer:710) INFO: 10epoch:train:21243-22360batch: iter_time=8.013e-05, forward_time=0.065, loss_ctc=36.261, loss_att=15.869, acc=0.888, loss=21.987, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.469e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 10:00:44,445 (trainer:330) INFO: 10epoch results: [train] iter_time=9.931e-05, forward_time=0.067, loss_ctc=35.297, loss_att=15.550, acc=0.882, loss=21.474, backward_time=0.095, optim_step_time=0.041, optim0_lr0=8.681e-05, train_time=0.308, time=1 hour, 54 minutes and 59.91 seconds, total_count=223640, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=21.661, cer_ctc=0.134, loss_att=8.796, acc=0.941, cer=0.079, wer=0.227, loss=12.656, time=7 minutes and 55.66 seconds, total_count=28480, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 0.28 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 10:00:51,684 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 10:00:51,686 (trainer:264) INFO: 11/35epoch started. Estimated time to finish: 2 days, 3 hours and 29 minutes
[seoultech:0/4] 2024-01-23 10:06:42,514 (trainer:710) INFO: 11epoch:train:1-1118batch: iter_time=2.692e-04, forward_time=0.067, loss_ctc=33.474, loss_att=14.769, acc=0.878, loss=20.381, backward_time=0.094, optim_step_time=0.038, optim0_lr0=8.448e-05, train_time=0.314
[seoultech:0/4] 2024-01-23 10:12:25,891 (trainer:710) INFO: 11epoch:train:1119-2236batch: iter_time=8.298e-05, forward_time=0.066, loss_ctc=34.298, loss_att=15.098, acc=0.882, loss=20.858, backward_time=0.095, optim_step_time=0.037, optim0_lr0=8.427e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 10:18:06,037 (trainer:710) INFO: 11epoch:train:2237-3354batch: iter_time=7.911e-05, forward_time=0.066, loss_ctc=34.383, loss_att=15.217, acc=0.884, loss=20.967, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.406e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 10:23:52,396 (trainer:710) INFO: 11epoch:train:3355-4472batch: iter_time=7.922e-05, forward_time=0.066, loss_ctc=35.151, loss_att=15.465, acc=0.889, loss=21.371, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.385e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 10:29:43,856 (trainer:710) INFO: 11epoch:train:4473-5590batch: iter_time=8.772e-05, forward_time=0.067, loss_ctc=34.305, loss_att=15.029, acc=0.883, loss=20.812, backward_time=0.093, optim_step_time=0.040, optim0_lr0=8.365e-05, train_time=0.314
[seoultech:0/4] 2024-01-23 10:35:30,761 (trainer:710) INFO: 11epoch:train:5591-6708batch: iter_time=8.029e-05, forward_time=0.066, loss_ctc=34.002, loss_att=14.956, acc=0.882, loss=20.670, backward_time=0.093, optim_step_time=0.036, optim0_lr0=8.344e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 10:41:18,849 (trainer:710) INFO: 11epoch:train:6709-7826batch: iter_time=9.665e-05, forward_time=0.068, loss_ctc=34.711, loss_att=15.269, acc=0.883, loss=21.101, backward_time=0.095, optim_step_time=0.045, optim0_lr0=8.324e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 10:47:00,946 (trainer:710) INFO: 11epoch:train:7827-8944batch: iter_time=9.214e-05, forward_time=0.068, loss_ctc=34.983, loss_att=15.467, acc=0.887, loss=21.322, backward_time=0.096, optim_step_time=0.042, optim0_lr0=8.304e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 10:52:41,408 (trainer:710) INFO: 11epoch:train:8945-10062batch: iter_time=8.023e-05, forward_time=0.066, loss_ctc=34.789, loss_att=15.284, acc=0.884, loss=21.136, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.284e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 10:58:15,925 (trainer:710) INFO: 11epoch:train:10063-11180batch: iter_time=7.990e-05, forward_time=0.066, loss_ctc=34.610, loss_att=15.205, acc=0.884, loss=21.027, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.264e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 11:03:48,961 (trainer:710) INFO: 11epoch:train:11181-12298batch: iter_time=7.992e-05, forward_time=0.066, loss_ctc=34.357, loss_att=15.156, acc=0.886, loss=20.916, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.245e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 11:09:21,234 (trainer:710) INFO: 11epoch:train:12299-13416batch: iter_time=7.974e-05, forward_time=0.065, loss_ctc=33.949, loss_att=14.978, acc=0.884, loss=20.669, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.225e-05, train_time=0.297
[seoultech:0/4] 2024-01-23 11:14:57,030 (trainer:710) INFO: 11epoch:train:13417-14534batch: iter_time=7.928e-05, forward_time=0.066, loss_ctc=34.351, loss_att=15.179, acc=0.886, loss=20.930, backward_time=0.096, optim_step_time=0.036, optim0_lr0=8.206e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 11:20:32,254 (trainer:710) INFO: 11epoch:train:14535-15652batch: iter_time=8.268e-05, forward_time=0.066, loss_ctc=34.385, loss_att=15.114, acc=0.884, loss=20.895, backward_time=0.096, optim_step_time=0.037, optim0_lr0=8.187e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 11:26:11,579 (trainer:710) INFO: 11epoch:train:15653-16770batch: iter_time=7.998e-05, forward_time=0.066, loss_ctc=34.277, loss_att=15.126, acc=0.883, loss=20.871, backward_time=0.095, optim_step_time=0.036, optim0_lr0=8.167e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 11:31:51,244 (trainer:710) INFO: 11epoch:train:16771-17888batch: iter_time=8.408e-05, forward_time=0.066, loss_ctc=34.973, loss_att=15.316, acc=0.885, loss=21.213, backward_time=0.096, optim_step_time=0.036, optim0_lr0=8.149e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 11:37:42,626 (trainer:710) INFO: 11epoch:train:17889-19006batch: iter_time=8.275e-05, forward_time=0.066, loss_ctc=34.850, loss_att=15.317, acc=0.884, loss=21.177, backward_time=0.095, optim_step_time=0.037, optim0_lr0=8.130e-05, train_time=0.314
[seoultech:0/4] 2024-01-23 11:43:28,737 (trainer:710) INFO: 11epoch:train:19007-20124batch: iter_time=8.726e-05, forward_time=0.067, loss_ctc=33.798, loss_att=14.882, acc=0.882, loss=20.557, backward_time=0.093, optim_step_time=0.039, optim0_lr0=8.111e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 11:49:02,483 (trainer:710) INFO: 11epoch:train:20125-21242batch: iter_time=8.176e-05, forward_time=0.066, loss_ctc=35.010, loss_att=15.364, acc=0.887, loss=21.257, backward_time=0.096, optim_step_time=0.036, optim0_lr0=8.092e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 11:54:42,178 (trainer:710) INFO: 11epoch:train:21243-22360batch: iter_time=8.241e-05, forward_time=0.066, loss_ctc=34.502, loss_att=15.177, acc=0.888, loss=20.975, backward_time=0.094, optim_step_time=0.036, optim0_lr0=8.074e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 12:03:37,577 (trainer:330) INFO: 11epoch results: [train] iter_time=9.237e-05, forward_time=0.066, loss_ctc=34.451, loss_att=15.166, acc=0.884, loss=20.951, backward_time=0.095, optim_step_time=0.037, optim0_lr0=8.257e-05, train_time=0.305, time=1 hour, 53 minutes and 52.97 seconds, total_count=246004, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=21.574, cer_ctc=0.132, loss_att=8.774, acc=0.941, cer=0.079, wer=0.226, loss=12.614, time=7 minutes and 54.04 seconds, total_count=31328, gpu_max_cached_mem_GB=15.113, [att_plot] time=58.88 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 12:03:44,875 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 12:03:44,885 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/1epoch.pth
[seoultech:0/4] 2024-01-23 12:03:44,885 (trainer:264) INFO: 12/35epoch started. Estimated time to finish: 2 days, 1 hour and 24 minutes
[seoultech:0/4] 2024-01-23 12:09:40,314 (trainer:710) INFO: 12epoch:train:1-1118batch: iter_time=2.528e-04, forward_time=0.068, loss_ctc=33.837, loss_att=14.836, acc=0.886, loss=20.536, backward_time=0.094, optim_step_time=0.043, optim0_lr0=8.056e-05, train_time=0.318
[seoultech:0/4] 2024-01-23 12:15:14,556 (trainer:710) INFO: 12epoch:train:1119-2236batch: iter_time=8.028e-05, forward_time=0.066, loss_ctc=34.303, loss_att=15.031, acc=0.888, loss=20.813, backward_time=0.096, optim_step_time=0.036, optim0_lr0=8.037e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 12:21:00,873 (trainer:710) INFO: 12epoch:train:2237-3354batch: iter_time=8.689e-05, forward_time=0.067, loss_ctc=33.816, loss_att=14.879, acc=0.888, loss=20.560, backward_time=0.094, optim_step_time=0.039, optim0_lr0=8.019e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 12:26:46,854 (trainer:710) INFO: 12epoch:train:3355-4472batch: iter_time=9.731e-05, forward_time=0.068, loss_ctc=34.913, loss_att=15.329, acc=0.890, loss=21.204, backward_time=0.096, optim_step_time=0.045, optim0_lr0=8.001e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 12:32:27,366 (trainer:710) INFO: 12epoch:train:4473-5590batch: iter_time=8.033e-05, forward_time=0.066, loss_ctc=33.895, loss_att=14.909, acc=0.887, loss=20.605, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.983e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 12:38:06,649 (trainer:710) INFO: 12epoch:train:5591-6708batch: iter_time=8.120e-05, forward_time=0.066, loss_ctc=34.575, loss_att=15.131, acc=0.891, loss=20.964, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.966e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 12:43:50,273 (trainer:710) INFO: 12epoch:train:6709-7826batch: iter_time=8.229e-05, forward_time=0.066, loss_ctc=33.445, loss_att=14.804, acc=0.885, loss=20.396, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.948e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 12:49:39,811 (trainer:710) INFO: 12epoch:train:7827-8944batch: iter_time=9.343e-05, forward_time=0.068, loss_ctc=33.280, loss_att=14.654, acc=0.883, loss=20.241, backward_time=0.093, optim_step_time=0.043, optim0_lr0=7.931e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 12:55:18,911 (trainer:710) INFO: 12epoch:train:8945-10062batch: iter_time=9.489e-05, forward_time=0.067, loss_ctc=34.090, loss_att=15.001, acc=0.886, loss=20.728, backward_time=0.095, optim_step_time=0.040, optim0_lr0=7.913e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 13:01:11,322 (trainer:710) INFO: 12epoch:train:10063-11180batch: iter_time=8.374e-05, forward_time=0.067, loss_ctc=33.041, loss_att=14.641, acc=0.883, loss=20.161, backward_time=0.094, optim_step_time=0.038, optim0_lr0=7.896e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 13:07:03,441 (trainer:710) INFO: 12epoch:train:11181-12298batch: iter_time=8.120e-05, forward_time=0.066, loss_ctc=32.780, loss_att=14.409, acc=0.882, loss=19.920, backward_time=0.093, optim_step_time=0.037, optim0_lr0=7.879e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 13:12:38,303 (trainer:710) INFO: 12epoch:train:12299-13416batch: iter_time=8.093e-05, forward_time=0.066, loss_ctc=33.393, loss_att=14.743, acc=0.886, loss=20.338, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.862e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 13:18:16,388 (trainer:710) INFO: 12epoch:train:13417-14534batch: iter_time=8.358e-05, forward_time=0.066, loss_ctc=33.592, loss_att=14.803, acc=0.885, loss=20.440, backward_time=0.095, optim_step_time=0.038, optim0_lr0=7.845e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 13:23:49,576 (trainer:710) INFO: 12epoch:train:14535-15652batch: iter_time=8.234e-05, forward_time=0.066, loss_ctc=33.425, loss_att=14.703, acc=0.887, loss=20.320, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.828e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 13:29:26,038 (trainer:710) INFO: 12epoch:train:15653-16770batch: iter_time=8.246e-05, forward_time=0.066, loss_ctc=34.000, loss_att=14.942, acc=0.889, loss=20.659, backward_time=0.094, optim_step_time=0.037, optim0_lr0=7.811e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 13:35:15,216 (trainer:710) INFO: 12epoch:train:16771-17888batch: iter_time=1.014e-04, forward_time=0.069, loss_ctc=33.916, loss_att=14.857, acc=0.884, loss=20.575, backward_time=0.094, optim_step_time=0.047, optim0_lr0=7.795e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 13:41:01,065 (trainer:710) INFO: 12epoch:train:17889-19006batch: iter_time=9.813e-05, forward_time=0.069, loss_ctc=34.678, loss_att=15.212, acc=0.891, loss=21.052, backward_time=0.096, optim_step_time=0.046, optim0_lr0=7.778e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 13:46:44,699 (trainer:710) INFO: 12epoch:train:19007-20124batch: iter_time=8.893e-05, forward_time=0.067, loss_ctc=33.699, loss_att=14.835, acc=0.886, loss=20.494, backward_time=0.095, optim_step_time=0.041, optim0_lr0=7.762e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 13:52:22,638 (trainer:710) INFO: 12epoch:train:20125-21242batch: iter_time=8.247e-05, forward_time=0.066, loss_ctc=32.723, loss_att=14.451, acc=0.883, loss=19.932, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.746e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 13:58:02,164 (trainer:710) INFO: 12epoch:train:21243-22360batch: iter_time=8.178e-05, forward_time=0.066, loss_ctc=33.133, loss_att=14.588, acc=0.886, loss=20.152, backward_time=0.094, optim_step_time=0.034, optim0_lr0=7.729e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 14:06:58,559 (trainer:330) INFO: 12epoch results: [train] iter_time=9.481e-05, forward_time=0.067, loss_ctc=33.713, loss_att=14.833, acc=0.886, loss=20.497, backward_time=0.095, optim_step_time=0.039, optim0_lr0=7.889e-05, train_time=0.306, time=1 hour, 54 minutes and 19.71 seconds, total_count=268368, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=21.363, cer_ctc=0.131, loss_att=8.716, acc=0.942, cer=0.078, wer=0.224, loss=12.510, time=7 minutes and 54.23 seconds, total_count=34176, gpu_max_cached_mem_GB=15.113, [att_plot] time=59.74 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 14:07:05,756 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 14:07:05,766 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/2epoch.pth
[seoultech:0/4] 2024-01-23 14:07:05,766 (trainer:264) INFO: 13/35epoch started. Estimated time to finish: 1 day, 23 hours and 20 minutes
[seoultech:0/4] 2024-01-23 14:13:05,725 (trainer:710) INFO: 13epoch:train:1-1118batch: iter_time=3.930e-04, forward_time=0.068, loss_ctc=33.215, loss_att=14.582, acc=0.889, loss=20.172, backward_time=0.093, optim_step_time=0.044, optim0_lr0=7.713e-05, train_time=0.322
[seoultech:0/4] 2024-01-23 14:18:42,203 (trainer:710) INFO: 13epoch:train:1119-2236batch: iter_time=8.232e-05, forward_time=0.066, loss_ctc=32.822, loss_att=14.432, acc=0.888, loss=19.949, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.697e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 14:24:17,674 (trainer:710) INFO: 13epoch:train:2237-3354batch: iter_time=8.208e-05, forward_time=0.066, loss_ctc=33.124, loss_att=14.622, acc=0.891, loss=20.172, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.681e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 14:29:59,803 (trainer:710) INFO: 13epoch:train:3355-4472batch: iter_time=8.283e-05, forward_time=0.066, loss_ctc=33.065, loss_att=14.554, acc=0.889, loss=20.107, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.666e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 14:35:34,381 (trainer:710) INFO: 13epoch:train:4473-5590batch: iter_time=8.295e-05, forward_time=0.066, loss_ctc=32.832, loss_att=14.432, acc=0.886, loss=19.952, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.650e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 14:41:16,105 (trainer:710) INFO: 13epoch:train:5591-6708batch: iter_time=8.229e-05, forward_time=0.066, loss_ctc=32.767, loss_att=14.466, acc=0.883, loss=19.956, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.634e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 14:46:56,529 (trainer:710) INFO: 13epoch:train:6709-7826batch: iter_time=8.297e-05, forward_time=0.066, loss_ctc=33.062, loss_att=14.597, acc=0.887, loss=20.136, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.619e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 14:52:43,279 (trainer:710) INFO: 13epoch:train:7827-8944batch: iter_time=9.889e-05, forward_time=0.069, loss_ctc=32.973, loss_att=14.520, acc=0.887, loss=20.056, backward_time=0.094, optim_step_time=0.045, optim0_lr0=7.603e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 14:58:31,442 (trainer:710) INFO: 13epoch:train:8945-10062batch: iter_time=9.730e-05, forward_time=0.068, loss_ctc=33.223, loss_att=14.587, acc=0.886, loss=20.178, backward_time=0.093, optim_step_time=0.045, optim0_lr0=7.588e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 15:04:08,081 (trainer:710) INFO: 13epoch:train:10063-11180batch: iter_time=8.720e-05, forward_time=0.066, loss_ctc=33.480, loss_att=14.701, acc=0.892, loss=20.335, backward_time=0.093, optim_step_time=0.038, optim0_lr0=7.573e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 15:09:45,606 (trainer:710) INFO: 13epoch:train:11181-12298batch: iter_time=8.273e-05, forward_time=0.066, loss_ctc=33.173, loss_att=14.637, acc=0.888, loss=20.198, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.558e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 15:15:21,570 (trainer:710) INFO: 13epoch:train:12299-13416batch: iter_time=8.240e-05, forward_time=0.066, loss_ctc=33.008, loss_att=14.576, acc=0.888, loss=20.106, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.543e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 15:21:03,515 (trainer:710) INFO: 13epoch:train:13417-14534batch: iter_time=9.711e-05, forward_time=0.068, loss_ctc=33.652, loss_att=14.825, acc=0.891, loss=20.473, backward_time=0.094, optim_step_time=0.045, optim0_lr0=7.528e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 15:26:48,404 (trainer:710) INFO: 13epoch:train:14535-15652batch: iter_time=1.024e-04, forward_time=0.069, loss_ctc=33.027, loss_att=14.522, acc=0.887, loss=20.073, backward_time=0.094, optim_step_time=0.047, optim0_lr0=7.513e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 15:32:29,580 (trainer:710) INFO: 13epoch:train:15653-16770batch: iter_time=8.341e-05, forward_time=0.067, loss_ctc=33.661, loss_att=14.802, acc=0.890, loss=20.460, backward_time=0.094, optim_step_time=0.037, optim0_lr0=7.498e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 15:38:05,065 (trainer:710) INFO: 13epoch:train:16771-17888batch: iter_time=8.143e-05, forward_time=0.066, loss_ctc=32.779, loss_att=14.448, acc=0.886, loss=19.947, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.484e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 15:43:47,156 (trainer:710) INFO: 13epoch:train:17889-19006batch: iter_time=8.129e-05, forward_time=0.066, loss_ctc=33.053, loss_att=14.486, acc=0.888, loss=20.056, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.469e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 15:49:32,214 (trainer:710) INFO: 13epoch:train:19007-20124batch: iter_time=8.181e-05, forward_time=0.065, loss_ctc=32.478, loss_att=14.269, acc=0.886, loss=19.732, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.454e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 15:55:09,616 (trainer:710) INFO: 13epoch:train:20125-21242batch: iter_time=8.172e-05, forward_time=0.065, loss_ctc=32.207, loss_att=14.200, acc=0.883, loss=19.602, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.440e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 16:00:50,395 (trainer:710) INFO: 13epoch:train:21243-22360batch: iter_time=8.140e-05, forward_time=0.066, loss_ctc=33.274, loss_att=14.661, acc=0.892, loss=20.245, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.426e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 16:09:55,371 (trainer:330) INFO: 13epoch results: [train] iter_time=1.014e-04, forward_time=0.067, loss_ctc=33.040, loss_att=14.544, acc=0.888, loss=20.093, backward_time=0.094, optim_step_time=0.039, optim0_lr0=7.567e-05, train_time=0.305, time=1 hour, 53 minutes and 47.18 seconds, total_count=290732, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=20.850, cer_ctc=0.130, loss_att=8.506, acc=0.943, cer=0.076, wer=0.221, loss=12.209, time=7 minutes and 58 seconds, total_count=37024, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 4.43 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 16:10:02,105 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 16:10:02,111 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/3epoch.pth
[seoultech:0/4] 2024-01-23 16:10:02,112 (trainer:264) INFO: 14/35epoch started. Estimated time to finish: 1 day, 21 hours and 15 minutes
[seoultech:0/4] 2024-01-23 16:15:58,327 (trainer:710) INFO: 14epoch:train:1-1118batch: iter_time=2.615e-04, forward_time=0.068, loss_ctc=32.456, loss_att=14.194, acc=0.890, loss=19.673, backward_time=0.095, optim_step_time=0.044, optim0_lr0=7.411e-05, train_time=0.318
[seoultech:0/4] 2024-01-23 16:21:46,774 (trainer:710) INFO: 14epoch:train:1119-2236batch: iter_time=1.010e-04, forward_time=0.069, loss_ctc=32.024, loss_att=14.173, acc=0.887, loss=19.528, backward_time=0.094, optim_step_time=0.047, optim0_lr0=7.397e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 16:27:25,574 (trainer:710) INFO: 14epoch:train:2237-3354batch: iter_time=8.526e-05, forward_time=0.066, loss_ctc=31.653, loss_att=14.001, acc=0.885, loss=19.296, backward_time=0.096, optim_step_time=0.038, optim0_lr0=7.383e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 16:33:07,168 (trainer:710) INFO: 14epoch:train:3355-4472batch: iter_time=8.501e-05, forward_time=0.066, loss_ctc=32.771, loss_att=14.420, acc=0.891, loss=19.926, backward_time=0.094, optim_step_time=0.038, optim0_lr0=7.369e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 16:38:57,117 (trainer:710) INFO: 14epoch:train:4473-5590batch: iter_time=9.437e-05, forward_time=0.068, loss_ctc=33.160, loss_att=14.506, acc=0.891, loss=20.102, backward_time=0.096, optim_step_time=0.044, optim0_lr0=7.355e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 16:44:45,996 (trainer:710) INFO: 14epoch:train:5591-6708batch: iter_time=9.988e-05, forward_time=0.069, loss_ctc=32.369, loss_att=14.248, acc=0.890, loss=19.685, backward_time=0.095, optim_step_time=0.047, optim0_lr0=7.341e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 16:50:28,592 (trainer:710) INFO: 14epoch:train:6709-7826batch: iter_time=9.511e-05, forward_time=0.068, loss_ctc=33.025, loss_att=14.509, acc=0.891, loss=20.064, backward_time=0.094, optim_step_time=0.044, optim0_lr0=7.327e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 16:56:12,163 (trainer:710) INFO: 14epoch:train:7827-8944batch: iter_time=7.981e-05, forward_time=0.066, loss_ctc=32.598, loss_att=14.312, acc=0.892, loss=19.798, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.314e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 17:02:01,191 (trainer:710) INFO: 14epoch:train:8945-10062batch: iter_time=9.999e-05, forward_time=0.069, loss_ctc=32.535, loss_att=14.337, acc=0.891, loss=19.797, backward_time=0.095, optim_step_time=0.047, optim0_lr0=7.300e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 17:07:46,222 (trainer:710) INFO: 14epoch:train:10063-11180batch: iter_time=9.136e-05, forward_time=0.067, loss_ctc=32.534, loss_att=14.257, acc=0.889, loss=19.740, backward_time=0.095, optim_step_time=0.042, optim0_lr0=7.287e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 17:13:29,979 (trainer:710) INFO: 14epoch:train:11181-12298batch: iter_time=8.110e-05, forward_time=0.066, loss_ctc=32.131, loss_att=14.159, acc=0.888, loss=19.551, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.273e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 17:19:11,968 (trainer:710) INFO: 14epoch:train:12299-13416batch: iter_time=8.004e-05, forward_time=0.066, loss_ctc=33.054, loss_att=14.529, acc=0.891, loss=20.087, backward_time=0.096, optim_step_time=0.036, optim0_lr0=7.260e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 17:24:45,085 (trainer:710) INFO: 14epoch:train:13417-14534batch: iter_time=7.951e-05, forward_time=0.066, loss_ctc=31.916, loss_att=14.048, acc=0.889, loss=19.409, backward_time=0.096, optim_step_time=0.035, optim0_lr0=7.246e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 17:30:36,620 (trainer:710) INFO: 14epoch:train:14535-15652batch: iter_time=9.607e-05, forward_time=0.068, loss_ctc=32.036, loss_att=14.085, acc=0.885, loss=19.470, backward_time=0.094, optim_step_time=0.042, optim0_lr0=7.233e-05, train_time=0.314
[seoultech:0/4] 2024-01-23 17:36:17,425 (trainer:710) INFO: 14epoch:train:15653-16770batch: iter_time=8.169e-05, forward_time=0.066, loss_ctc=31.589, loss_att=13.943, acc=0.886, loss=19.237, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.220e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 17:41:53,625 (trainer:710) INFO: 14epoch:train:16771-17888batch: iter_time=8.113e-05, forward_time=0.066, loss_ctc=33.508, loss_att=14.761, acc=0.892, loss=20.385, backward_time=0.096, optim_step_time=0.036, optim0_lr0=7.207e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 17:47:27,118 (trainer:710) INFO: 14epoch:train:17889-19006batch: iter_time=8.089e-05, forward_time=0.066, loss_ctc=32.028, loss_att=14.190, acc=0.888, loss=19.541, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.194e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 17:52:59,325 (trainer:710) INFO: 14epoch:train:19007-20124batch: iter_time=8.229e-05, forward_time=0.066, loss_ctc=32.731, loss_att=14.381, acc=0.892, loss=19.886, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.181e-05, train_time=0.297
[seoultech:0/4] 2024-01-23 17:58:33,754 (trainer:710) INFO: 14epoch:train:20125-21242batch: iter_time=8.228e-05, forward_time=0.066, loss_ctc=32.334, loss_att=14.254, acc=0.889, loss=19.678, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.168e-05, train_time=0.299
[seoultech:0/4] 2024-01-23 18:04:12,175 (trainer:710) INFO: 14epoch:train:21243-22360batch: iter_time=8.157e-05, forward_time=0.066, loss_ctc=32.577, loss_att=14.324, acc=0.890, loss=19.800, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.155e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 18:13:10,196 (trainer:330) INFO: 14epoch results: [train] iter_time=9.600e-05, forward_time=0.067, loss_ctc=32.441, loss_att=14.277, acc=0.889, loss=19.727, backward_time=0.095, optim_step_time=0.040, optim0_lr0=7.281e-05, train_time=0.306, time=1 hour, 54 minutes and 12.43 seconds, total_count=313096, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=20.368, cer_ctc=0.126, loss_att=8.315, acc=0.944, cer=0.075, wer=0.219, loss=11.931, time=7 minutes and 54.94 seconds, total_count=39872, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 0.71 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 18:13:17,214 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 18:13:17,224 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/4epoch.pth
[seoultech:0/4] 2024-01-23 18:13:17,224 (trainer:264) INFO: 15/35epoch started. Estimated time to finish: 1 day, 19 hours and 12 minutes
[seoultech:0/4] 2024-01-23 18:19:18,267 (trainer:710) INFO: 15epoch:train:1-1118batch: iter_time=3.057e-04, forward_time=0.069, loss_ctc=31.627, loss_att=13.964, acc=0.893, loss=19.263, backward_time=0.095, optim_step_time=0.047, optim0_lr0=7.142e-05, train_time=0.323
[seoultech:0/4] 2024-01-23 18:25:10,338 (trainer:710) INFO: 15epoch:train:1119-2236batch: iter_time=1.024e-04, forward_time=0.069, loss_ctc=31.271, loss_att=13.797, acc=0.888, loss=19.040, backward_time=0.094, optim_step_time=0.047, optim0_lr0=7.130e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 18:31:02,939 (trainer:710) INFO: 15epoch:train:2237-3354batch: iter_time=1.049e-04, forward_time=0.069, loss_ctc=31.044, loss_att=13.724, acc=0.888, loss=18.920, backward_time=0.095, optim_step_time=0.047, optim0_lr0=7.117e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 18:36:44,312 (trainer:710) INFO: 15epoch:train:3355-4472batch: iter_time=8.378e-05, forward_time=0.066, loss_ctc=31.949, loss_att=14.038, acc=0.891, loss=19.411, backward_time=0.094, optim_step_time=0.037, optim0_lr0=7.104e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 18:42:32,726 (trainer:710) INFO: 15epoch:train:4473-5590batch: iter_time=8.130e-05, forward_time=0.066, loss_ctc=31.022, loss_att=13.733, acc=0.888, loss=18.920, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.092e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 18:48:16,087 (trainer:710) INFO: 15epoch:train:5591-6708batch: iter_time=8.133e-05, forward_time=0.066, loss_ctc=31.995, loss_att=14.107, acc=0.892, loss=19.474, backward_time=0.093, optim_step_time=0.036, optim0_lr0=7.079e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 18:53:59,069 (trainer:710) INFO: 15epoch:train:6709-7826batch: iter_time=8.158e-05, forward_time=0.066, loss_ctc=32.161, loss_att=14.218, acc=0.893, loss=19.601, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.067e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 18:59:43,965 (trainer:710) INFO: 15epoch:train:7827-8944batch: iter_time=8.188e-05, forward_time=0.066, loss_ctc=31.761, loss_att=13.960, acc=0.890, loss=19.300, backward_time=0.094, optim_step_time=0.036, optim0_lr0=7.055e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 19:05:27,445 (trainer:710) INFO: 15epoch:train:8945-10062batch: iter_time=8.024e-05, forward_time=0.066, loss_ctc=32.534, loss_att=14.315, acc=0.891, loss=19.781, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.043e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 19:11:05,666 (trainer:710) INFO: 15epoch:train:10063-11180batch: iter_time=8.180e-05, forward_time=0.066, loss_ctc=32.071, loss_att=14.122, acc=0.892, loss=19.506, backward_time=0.096, optim_step_time=0.036, optim0_lr0=7.030e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 19:16:39,457 (trainer:710) INFO: 15epoch:train:11181-12298batch: iter_time=8.125e-05, forward_time=0.066, loss_ctc=32.268, loss_att=14.152, acc=0.893, loss=19.587, backward_time=0.096, optim_step_time=0.036, optim0_lr0=7.018e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 19:22:16,481 (trainer:710) INFO: 15epoch:train:12299-13416batch: iter_time=8.086e-05, forward_time=0.066, loss_ctc=32.967, loss_att=14.495, acc=0.893, loss=20.036, backward_time=0.095, optim_step_time=0.036, optim0_lr0=7.006e-05, train_time=0.301
[seoultech:0/4] 2024-01-23 19:27:58,700 (trainer:710) INFO: 15epoch:train:13417-14534batch: iter_time=8.463e-05, forward_time=0.067, loss_ctc=31.859, loss_att=14.020, acc=0.891, loss=19.372, backward_time=0.095, optim_step_time=0.038, optim0_lr0=6.994e-05, train_time=0.306
[seoultech:0/4] 2024-01-23 19:33:32,074 (trainer:710) INFO: 15epoch:train:14535-15652batch: iter_time=8.060e-05, forward_time=0.066, loss_ctc=32.050, loss_att=14.117, acc=0.888, loss=19.497, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.982e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 19:39:05,667 (trainer:710) INFO: 15epoch:train:15653-16770batch: iter_time=7.984e-05, forward_time=0.066, loss_ctc=31.834, loss_att=14.042, acc=0.892, loss=19.379, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.970e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 19:44:49,569 (trainer:710) INFO: 15epoch:train:16771-17888batch: iter_time=8.473e-05, forward_time=0.066, loss_ctc=30.804, loss_att=13.586, acc=0.883, loss=18.752, backward_time=0.093, optim_step_time=0.038, optim0_lr0=6.959e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 19:50:27,224 (trainer:710) INFO: 15epoch:train:17889-19006batch: iter_time=8.032e-05, forward_time=0.066, loss_ctc=31.841, loss_att=13.984, acc=0.890, loss=19.341, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.947e-05, train_time=0.302
[seoultech:0/4] 2024-01-23 19:56:12,039 (trainer:710) INFO: 15epoch:train:19007-20124batch: iter_time=8.101e-05, forward_time=0.066, loss_ctc=32.293, loss_att=14.168, acc=0.892, loss=19.606, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.935e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 20:01:51,115 (trainer:710) INFO: 15epoch:train:20125-21242batch: iter_time=8.043e-05, forward_time=0.066, loss_ctc=31.771, loss_att=13.965, acc=0.890, loss=19.307, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.924e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 20:07:34,162 (trainer:710) INFO: 15epoch:train:21243-22360batch: iter_time=8.120e-05, forward_time=0.066, loss_ctc=33.287, loss_att=14.679, acc=0.899, loss=20.261, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.912e-05, train_time=0.307
[seoultech:0/4] 2024-01-23 20:16:35,170 (trainer:330) INFO: 15epoch results: [train] iter_time=9.499e-05, forward_time=0.066, loss_ctc=31.905, loss_att=14.053, acc=0.891, loss=19.408, backward_time=0.095, optim_step_time=0.038, optim0_lr0=7.025e-05, train_time=0.306, time=1 hour, 54 minutes and 19.38 seconds, total_count=335460, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=20.239, cer_ctc=0.126, loss_att=8.294, acc=0.944, cer=0.075, wer=0.218, loss=11.877, time=7 minutes and 58.73 seconds, total_count=42720, gpu_max_cached_mem_GB=15.113, [att_plot] time=59.84 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 20:16:41,791 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 20:16:41,798 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/5epoch.pth
[seoultech:0/4] 2024-01-23 20:16:41,798 (trainer:264) INFO: 16/35epoch started. Estimated time to finish: 1 day, 17 hours and 8 minutes
[seoultech:0/4] 2024-01-23 20:22:37,948 (trainer:710) INFO: 16epoch:train:1-1118batch: iter_time=2.743e-04, forward_time=0.066, loss_ctc=30.451, loss_att=13.441, acc=0.890, loss=18.544, backward_time=0.094, optim_step_time=0.037, optim0_lr0=6.900e-05, train_time=0.318
[seoultech:0/4] 2024-01-23 20:28:21,977 (trainer:710) INFO: 16epoch:train:1119-2236batch: iter_time=8.142e-05, forward_time=0.066, loss_ctc=31.691, loss_att=13.980, acc=0.894, loss=19.293, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.889e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 20:34:02,922 (trainer:710) INFO: 16epoch:train:2237-3354batch: iter_time=8.152e-05, forward_time=0.066, loss_ctc=30.976, loss_att=13.735, acc=0.891, loss=18.907, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.878e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 20:39:50,111 (trainer:710) INFO: 16epoch:train:3355-4472batch: iter_time=8.105e-05, forward_time=0.067, loss_ctc=31.865, loss_att=13.968, acc=0.894, loss=19.337, backward_time=0.093, optim_step_time=0.036, optim0_lr0=6.866e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 20:45:31,156 (trainer:710) INFO: 16epoch:train:4473-5590batch: iter_time=8.763e-05, forward_time=0.067, loss_ctc=32.410, loss_att=14.256, acc=0.896, loss=19.702, backward_time=0.095, optim_step_time=0.040, optim0_lr0=6.855e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 20:51:04,659 (trainer:710) INFO: 16epoch:train:5591-6708batch: iter_time=8.020e-05, forward_time=0.065, loss_ctc=30.633, loss_att=13.547, acc=0.890, loss=18.673, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.844e-05, train_time=0.298
[seoultech:0/4] 2024-01-23 20:56:50,153 (trainer:710) INFO: 16epoch:train:6709-7826batch: iter_time=8.270e-05, forward_time=0.067, loss_ctc=31.623, loss_att=13.878, acc=0.890, loss=19.201, backward_time=0.094, optim_step_time=0.037, optim0_lr0=6.833e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 21:02:38,156 (trainer:710) INFO: 16epoch:train:7827-8944batch: iter_time=9.245e-05, forward_time=0.068, loss_ctc=30.876, loss_att=13.593, acc=0.889, loss=18.778, backward_time=0.094, optim_step_time=0.043, optim0_lr0=6.821e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 21:08:18,731 (trainer:710) INFO: 16epoch:train:8945-10062batch: iter_time=8.476e-05, forward_time=0.066, loss_ctc=32.020, loss_att=14.033, acc=0.897, loss=19.429, backward_time=0.095, optim_step_time=0.039, optim0_lr0=6.810e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 21:14:00,107 (trainer:710) INFO: 16epoch:train:10063-11180batch: iter_time=7.934e-05, forward_time=0.066, loss_ctc=32.050, loss_att=14.131, acc=0.893, loss=19.507, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.799e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 21:19:41,147 (trainer:710) INFO: 16epoch:train:11181-12298batch: iter_time=8.736e-05, forward_time=0.067, loss_ctc=31.188, loss_att=13.710, acc=0.890, loss=18.953, backward_time=0.096, optim_step_time=0.039, optim0_lr0=6.788e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 21:25:33,261 (trainer:710) INFO: 16epoch:train:12299-13416batch: iter_time=7.983e-05, forward_time=0.066, loss_ctc=31.495, loss_att=13.874, acc=0.890, loss=19.160, backward_time=0.094, optim_step_time=0.037, optim0_lr0=6.778e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 21:31:25,898 (trainer:710) INFO: 16epoch:train:13417-14534batch: iter_time=8.090e-05, forward_time=0.066, loss_ctc=31.865, loss_att=14.010, acc=0.895, loss=19.366, backward_time=0.093, optim_step_time=0.037, optim0_lr0=6.767e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 21:37:11,089 (trainer:710) INFO: 16epoch:train:14535-15652batch: iter_time=8.989e-05, forward_time=0.067, loss_ctc=31.646, loss_att=14.010, acc=0.895, loss=19.301, backward_time=0.095, optim_step_time=0.041, optim0_lr0=6.756e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 21:43:01,301 (trainer:710) INFO: 16epoch:train:15653-16770batch: iter_time=1.020e-04, forward_time=0.069, loss_ctc=31.224, loss_att=13.739, acc=0.889, loss=18.984, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.745e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 21:48:50,506 (trainer:710) INFO: 16epoch:train:16771-17888batch: iter_time=1.021e-04, forward_time=0.068, loss_ctc=31.233, loss_att=13.704, acc=0.892, loss=18.963, backward_time=0.094, optim_step_time=0.047, optim0_lr0=6.734e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 21:54:43,820 (trainer:710) INFO: 16epoch:train:17889-19006batch: iter_time=1.011e-04, forward_time=0.069, loss_ctc=31.572, loss_att=13.973, acc=0.890, loss=19.253, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.724e-05, train_time=0.316
[seoultech:0/4] 2024-01-23 22:00:28,849 (trainer:710) INFO: 16epoch:train:19007-20124batch: iter_time=8.871e-05, forward_time=0.067, loss_ctc=31.571, loss_att=13.956, acc=0.893, loss=19.241, backward_time=0.094, optim_step_time=0.040, optim0_lr0=6.713e-05, train_time=0.308
[seoultech:0/4] 2024-01-23 22:06:04,333 (trainer:710) INFO: 16epoch:train:20125-21242batch: iter_time=8.010e-05, forward_time=0.066, loss_ctc=30.918, loss_att=13.638, acc=0.889, loss=18.822, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.703e-05, train_time=0.300
[seoultech:0/4] 2024-01-23 22:11:44,310 (trainer:710) INFO: 16epoch:train:21243-22360batch: iter_time=8.060e-05, forward_time=0.066, loss_ctc=31.196, loss_att=13.796, acc=0.890, loss=19.016, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.692e-05, train_time=0.304
[seoultech:0/4] 2024-01-23 22:20:44,450 (trainer:330) INFO: 16epoch results: [train] iter_time=9.589e-05, forward_time=0.067, loss_ctc=31.417, loss_att=13.845, acc=0.892, loss=19.117, backward_time=0.095, optim_step_time=0.039, optim0_lr0=6.795e-05, train_time=0.308, time=1 hour, 55 minutes and 4.98 seconds, total_count=357824, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=20.253, cer_ctc=0.126, loss_att=8.252, acc=0.944, cer=0.075, wer=0.217, loss=11.852, time=7 minutes and 56.91 seconds, total_count=45568, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 0.76 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-23 22:20:50,881 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-23 22:20:50,887 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/6epoch.pth
[seoultech:0/4] 2024-01-23 22:20:50,887 (trainer:264) INFO: 17/35epoch started. Estimated time to finish: 1 day, 15 hours and 6 minutes
[seoultech:0/4] 2024-01-23 22:26:40,149 (trainer:710) INFO: 17epoch:train:1-1118batch: iter_time=2.560e-04, forward_time=0.068, loss_ctc=30.956, loss_att=13.652, acc=0.893, loss=18.843, backward_time=0.095, optim_step_time=0.042, optim0_lr0=6.682e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 22:32:27,056 (trainer:710) INFO: 17epoch:train:1119-2236batch: iter_time=9.730e-05, forward_time=0.069, loss_ctc=31.488, loss_att=13.880, acc=0.895, loss=19.162, backward_time=0.096, optim_step_time=0.045, optim0_lr0=6.671e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 22:38:14,722 (trainer:710) INFO: 17epoch:train:2237-3354batch: iter_time=1.010e-04, forward_time=0.069, loss_ctc=30.444, loss_att=13.508, acc=0.891, loss=18.589, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.661e-05, train_time=0.311
[seoultech:0/4] 2024-01-23 22:44:05,067 (trainer:710) INFO: 17epoch:train:3355-4472batch: iter_time=9.986e-05, forward_time=0.069, loss_ctc=31.020, loss_att=13.610, acc=0.890, loss=18.833, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.651e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 22:49:54,084 (trainer:710) INFO: 17epoch:train:4473-5590batch: iter_time=1.006e-04, forward_time=0.069, loss_ctc=31.383, loss_att=13.824, acc=0.896, loss=19.092, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.640e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 22:55:39,678 (trainer:710) INFO: 17epoch:train:5591-6708batch: iter_time=9.040e-05, forward_time=0.067, loss_ctc=30.143, loss_att=13.385, acc=0.890, loss=18.412, backward_time=0.096, optim_step_time=0.041, optim0_lr0=6.630e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 23:01:28,961 (trainer:710) INFO: 17epoch:train:6709-7826batch: iter_time=8.207e-05, forward_time=0.066, loss_ctc=30.805, loss_att=13.547, acc=0.893, loss=18.724, backward_time=0.095, optim_step_time=0.037, optim0_lr0=6.620e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 23:07:20,831 (trainer:710) INFO: 17epoch:train:7827-8944batch: iter_time=8.452e-05, forward_time=0.067, loss_ctc=30.856, loss_att=13.629, acc=0.892, loss=18.797, backward_time=0.094, optim_step_time=0.038, optim0_lr0=6.610e-05, train_time=0.315
[seoultech:0/4] 2024-01-23 23:13:11,325 (trainer:710) INFO: 17epoch:train:8945-10062batch: iter_time=8.661e-05, forward_time=0.067, loss_ctc=31.436, loss_att=13.822, acc=0.897, loss=19.106, backward_time=0.096, optim_step_time=0.039, optim0_lr0=6.600e-05, train_time=0.313
[seoultech:0/4] 2024-01-23 23:19:00,533 (trainer:710) INFO: 17epoch:train:10063-11180batch: iter_time=1.013e-04, forward_time=0.069, loss_ctc=30.936, loss_att=13.628, acc=0.893, loss=18.821, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.590e-05, train_time=0.312
[seoultech:0/4] 2024-01-23 23:24:46,064 (trainer:710) INFO: 17epoch:train:11181-12298batch: iter_time=9.365e-05, forward_time=0.068, loss_ctc=30.899, loss_att=13.643, acc=0.893, loss=18.820, backward_time=0.096, optim_step_time=0.043, optim0_lr0=6.580e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 23:30:24,872 (trainer:710) INFO: 17epoch:train:12299-13416batch: iter_time=8.168e-05, forward_time=0.066, loss_ctc=31.474, loss_att=13.841, acc=0.896, loss=19.131, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.570e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 23:36:03,992 (trainer:710) INFO: 17epoch:train:13417-14534batch: iter_time=8.322e-05, forward_time=0.066, loss_ctc=30.927, loss_att=13.637, acc=0.893, loss=18.824, backward_time=0.095, optim_step_time=0.037, optim0_lr0=6.560e-05, train_time=0.303
[seoultech:0/4] 2024-01-23 23:41:50,002 (trainer:710) INFO: 17epoch:train:14535-15652batch: iter_time=7.933e-05, forward_time=0.066, loss_ctc=31.658, loss_att=13.948, acc=0.897, loss=19.261, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.550e-05, train_time=0.309
[seoultech:0/4] 2024-01-23 23:47:36,625 (trainer:710) INFO: 17epoch:train:15653-16770batch: iter_time=7.995e-05, forward_time=0.066, loss_ctc=30.929, loss_att=13.651, acc=0.892, loss=18.834, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.540e-05, train_time=0.310
[seoultech:0/4] 2024-01-23 23:53:18,274 (trainer:710) INFO: 17epoch:train:16771-17888batch: iter_time=8.083e-05, forward_time=0.066, loss_ctc=31.480, loss_att=13.844, acc=0.895, loss=19.135, backward_time=0.097, optim_step_time=0.036, optim0_lr0=6.531e-05, train_time=0.305
[seoultech:0/4] 2024-01-23 23:58:57,323 (trainer:710) INFO: 17epoch:train:17889-19006batch: iter_time=8.117e-05, forward_time=0.066, loss_ctc=30.147, loss_att=13.390, acc=0.889, loss=18.417, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.521e-05, train_time=0.303
[seoultech:0/4] 2024-01-24 00:04:39,602 (trainer:710) INFO: 17epoch:train:19007-20124batch: iter_time=8.177e-05, forward_time=0.066, loss_ctc=30.512, loss_att=13.469, acc=0.891, loss=18.582, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.511e-05, train_time=0.306
[seoultech:0/4] 2024-01-24 00:10:21,459 (trainer:710) INFO: 17epoch:train:20125-21242batch: iter_time=8.179e-05, forward_time=0.066, loss_ctc=31.263, loss_att=13.752, acc=0.895, loss=19.005, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.502e-05, train_time=0.306
[seoultech:0/4] 2024-01-24 00:16:01,610 (trainer:710) INFO: 17epoch:train:21243-22360batch: iter_time=8.085e-05, forward_time=0.066, loss_ctc=30.515, loss_att=13.442, acc=0.892, loss=18.564, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.492e-05, train_time=0.304
[seoultech:0/4] 2024-01-24 00:25:02,575 (trainer:330) INFO: 17epoch results: [train] iter_time=9.619e-05, forward_time=0.067, loss_ctc=30.956, loss_att=13.652, acc=0.893, loss=18.843, backward_time=0.095, optim_step_time=0.040, optim0_lr0=6.586e-05, train_time=0.309, time=1 hour, 55 minutes and 13.24 seconds, total_count=380188, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=20.146, cer_ctc=0.123, loss_att=8.145, acc=0.945, cer=0.074, wer=0.215, loss=11.746, time=7 minutes and 55.53 seconds, total_count=48416, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 2.91 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 00:25:09,495 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 00:25:09,505 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/7epoch.pth
[seoultech:0/4] 2024-01-24 00:25:09,505 (trainer:264) INFO: 18/35epoch started. Estimated time to finish: 1 day, 13 hours and 3 minutes
[seoultech:0/4] 2024-01-24 00:31:05,444 (trainer:710) INFO: 18epoch:train:1-1118batch: iter_time=2.568e-04, forward_time=0.066, loss_ctc=30.877, loss_att=13.676, acc=0.900, loss=18.836, backward_time=0.094, optim_step_time=0.037, optim0_lr0=6.482e-05, train_time=0.318
[seoultech:0/4] 2024-01-24 00:36:50,566 (trainer:710) INFO: 18epoch:train:1119-2236batch: iter_time=8.067e-05, forward_time=0.066, loss_ctc=30.921, loss_att=13.650, acc=0.898, loss=18.831, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.473e-05, train_time=0.308
[seoultech:0/4] 2024-01-24 00:42:39,557 (trainer:710) INFO: 18epoch:train:2237-3354batch: iter_time=9.690e-05, forward_time=0.068, loss_ctc=30.740, loss_att=13.518, acc=0.896, loss=18.685, backward_time=0.095, optim_step_time=0.044, optim0_lr0=6.464e-05, train_time=0.312
[seoultech:0/4] 2024-01-24 00:48:33,184 (trainer:710) INFO: 18epoch:train:3355-4472batch: iter_time=1.006e-04, forward_time=0.069, loss_ctc=30.733, loss_att=13.610, acc=0.895, loss=18.747, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.454e-05, train_time=0.316
[seoultech:0/4] 2024-01-24 00:54:21,911 (trainer:710) INFO: 18epoch:train:4473-5590batch: iter_time=9.990e-05, forward_time=0.069, loss_ctc=30.480, loss_att=13.433, acc=0.893, loss=18.547, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.445e-05, train_time=0.312
[seoultech:0/4] 2024-01-24 00:59:56,622 (trainer:710) INFO: 18epoch:train:5591-6708batch: iter_time=8.046e-05, forward_time=0.065, loss_ctc=30.589, loss_att=13.558, acc=0.895, loss=18.668, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.435e-05, train_time=0.299
[seoultech:0/4] 2024-01-24 01:05:32,437 (trainer:710) INFO: 18epoch:train:6709-7826batch: iter_time=8.278e-05, forward_time=0.066, loss_ctc=30.538, loss_att=13.423, acc=0.894, loss=18.558, backward_time=0.096, optim_step_time=0.037, optim0_lr0=6.426e-05, train_time=0.300
[seoultech:0/4] 2024-01-24 01:11:23,979 (trainer:710) INFO: 18epoch:train:7827-8944batch: iter_time=9.938e-05, forward_time=0.069, loss_ctc=30.765, loss_att=13.560, acc=0.895, loss=18.722, backward_time=0.097, optim_step_time=0.047, optim0_lr0=6.417e-05, train_time=0.314
[seoultech:0/4] 2024-01-24 01:17:16,317 (trainer:710) INFO: 18epoch:train:8945-10062batch: iter_time=8.683e-05, forward_time=0.067, loss_ctc=30.848, loss_att=13.625, acc=0.897, loss=18.792, backward_time=0.095, optim_step_time=0.040, optim0_lr0=6.408e-05, train_time=0.315
[seoultech:0/4] 2024-01-24 01:22:56,157 (trainer:710) INFO: 18epoch:train:10063-11180batch: iter_time=8.432e-05, forward_time=0.067, loss_ctc=30.172, loss_att=13.302, acc=0.891, loss=18.363, backward_time=0.095, optim_step_time=0.039, optim0_lr0=6.398e-05, train_time=0.304
[seoultech:0/4] 2024-01-24 01:28:43,147 (trainer:710) INFO: 18epoch:train:11181-12298batch: iter_time=9.255e-05, forward_time=0.068, loss_ctc=29.942, loss_att=13.107, acc=0.889, loss=18.157, backward_time=0.094, optim_step_time=0.043, optim0_lr0=6.389e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 01:34:28,436 (trainer:710) INFO: 18epoch:train:12299-13416batch: iter_time=9.939e-05, forward_time=0.069, loss_ctc=30.371, loss_att=13.409, acc=0.894, loss=18.498, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.380e-05, train_time=0.309
[seoultech:0/4] 2024-01-24 01:40:16,443 (trainer:710) INFO: 18epoch:train:13417-14534batch: iter_time=9.970e-05, forward_time=0.069, loss_ctc=30.281, loss_att=13.421, acc=0.892, loss=18.479, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.371e-05, train_time=0.311
[seoultech:0/4] 2024-01-24 01:46:06,241 (trainer:710) INFO: 18epoch:train:14535-15652batch: iter_time=9.896e-05, forward_time=0.069, loss_ctc=30.416, loss_att=13.413, acc=0.893, loss=18.514, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.362e-05, train_time=0.313
[seoultech:0/4] 2024-01-24 01:51:53,351 (trainer:710) INFO: 18epoch:train:15653-16770batch: iter_time=1.006e-04, forward_time=0.069, loss_ctc=30.662, loss_att=13.563, acc=0.893, loss=18.693, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.353e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 01:57:40,244 (trainer:710) INFO: 18epoch:train:16771-17888batch: iter_time=1.012e-04, forward_time=0.069, loss_ctc=30.369, loss_att=13.458, acc=0.894, loss=18.531, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.344e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 02:03:19,538 (trainer:710) INFO: 18epoch:train:17889-19006batch: iter_time=8.795e-05, forward_time=0.067, loss_ctc=30.954, loss_att=13.565, acc=0.896, loss=18.782, backward_time=0.095, optim_step_time=0.040, optim0_lr0=6.335e-05, train_time=0.303
[seoultech:0/4] 2024-01-24 02:09:03,487 (trainer:710) INFO: 18epoch:train:19007-20124batch: iter_time=8.088e-05, forward_time=0.066, loss_ctc=30.679, loss_att=13.539, acc=0.893, loss=18.681, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.326e-05, train_time=0.307
[seoultech:0/4] 2024-01-24 02:14:41,820 (trainer:710) INFO: 18epoch:train:20125-21242batch: iter_time=8.004e-05, forward_time=0.066, loss_ctc=29.843, loss_att=13.202, acc=0.890, loss=18.195, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.318e-05, train_time=0.302
[seoultech:0/4] 2024-01-24 02:20:23,646 (trainer:710) INFO: 18epoch:train:21243-22360batch: iter_time=8.004e-05, forward_time=0.066, loss_ctc=31.012, loss_att=13.664, acc=0.896, loss=18.869, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.309e-05, train_time=0.306
[seoultech:0/4] 2024-01-24 02:29:22,245 (trainer:330) INFO: 18epoch results: [train] iter_time=9.949e-05, forward_time=0.068, loss_ctc=30.554, loss_att=13.482, acc=0.894, loss=18.604, backward_time=0.095, optim_step_time=0.042, optim0_lr0=6.395e-05, train_time=0.309, time=1 hour, 55 minutes and 16.66 seconds, total_count=402552, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=20.192, cer_ctc=0.123, loss_att=8.130, acc=0.945, cer=0.073, wer=0.214, loss=11.748, time=7 minutes and 56.25 seconds, total_count=51264, gpu_max_cached_mem_GB=15.113, [att_plot] time=59.83 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 02:29:29,022 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 02:29:29,028 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/8epoch.pth
[seoultech:0/4] 2024-01-24 02:29:29,029 (trainer:264) INFO: 19/35epoch started. Estimated time to finish: 1 day, 11 hours and 45.42 seconds
[seoultech:0/4] 2024-01-24 02:35:21,993 (trainer:710) INFO: 19epoch:train:1-1118batch: iter_time=2.714e-04, forward_time=0.066, loss_ctc=30.641, loss_att=13.509, acc=0.900, loss=18.649, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.300e-05, train_time=0.315
[seoultech:0/4] 2024-01-24 02:41:11,729 (trainer:710) INFO: 19epoch:train:1119-2236batch: iter_time=8.158e-05, forward_time=0.066, loss_ctc=29.802, loss_att=13.153, acc=0.894, loss=18.148, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.291e-05, train_time=0.313
[seoultech:0/4] 2024-01-24 02:46:57,468 (trainer:710) INFO: 19epoch:train:2237-3354batch: iter_time=8.579e-05, forward_time=0.067, loss_ctc=30.084, loss_att=13.276, acc=0.895, loss=18.318, backward_time=0.095, optim_step_time=0.038, optim0_lr0=6.283e-05, train_time=0.309
[seoultech:0/4] 2024-01-24 02:52:44,024 (trainer:710) INFO: 19epoch:train:3355-4472batch: iter_time=9.052e-05, forward_time=0.068, loss_ctc=30.518, loss_att=13.568, acc=0.896, loss=18.653, backward_time=0.095, optim_step_time=0.041, optim0_lr0=6.274e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 02:58:33,161 (trainer:710) INFO: 19epoch:train:4473-5590batch: iter_time=9.976e-05, forward_time=0.068, loss_ctc=29.814, loss_att=13.149, acc=0.893, loss=18.149, backward_time=0.095, optim_step_time=0.046, optim0_lr0=6.265e-05, train_time=0.312
[seoultech:0/4] 2024-01-24 03:04:12,102 (trainer:710) INFO: 19epoch:train:5591-6708batch: iter_time=8.664e-05, forward_time=0.067, loss_ctc=30.146, loss_att=13.329, acc=0.893, loss=18.374, backward_time=0.097, optim_step_time=0.039, optim0_lr0=6.257e-05, train_time=0.303
[seoultech:0/4] 2024-01-24 03:10:01,305 (trainer:710) INFO: 19epoch:train:6709-7826batch: iter_time=8.554e-05, forward_time=0.066, loss_ctc=30.209, loss_att=13.307, acc=0.895, loss=18.378, backward_time=0.095, optim_step_time=0.039, optim0_lr0=6.248e-05, train_time=0.312
[seoultech:0/4] 2024-01-24 03:15:53,907 (trainer:710) INFO: 19epoch:train:7827-8944batch: iter_time=9.947e-05, forward_time=0.069, loss_ctc=29.872, loss_att=13.297, acc=0.894, loss=18.270, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.240e-05, train_time=0.315
[seoultech:0/4] 2024-01-24 03:21:38,714 (trainer:710) INFO: 19epoch:train:8945-10062batch: iter_time=8.990e-05, forward_time=0.068, loss_ctc=30.435, loss_att=13.460, acc=0.894, loss=18.553, backward_time=0.096, optim_step_time=0.041, optim0_lr0=6.231e-05, train_time=0.308
[seoultech:0/4] 2024-01-24 03:27:26,359 (trainer:710) INFO: 19epoch:train:10063-11180batch: iter_time=9.284e-05, forward_time=0.068, loss_ctc=30.366, loss_att=13.429, acc=0.896, loss=18.510, backward_time=0.095, optim_step_time=0.043, optim0_lr0=6.223e-05, train_time=0.311
[seoultech:0/4] 2024-01-24 03:33:06,657 (trainer:710) INFO: 19epoch:train:11181-12298batch: iter_time=8.355e-05, forward_time=0.066, loss_ctc=29.670, loss_att=13.104, acc=0.894, loss=18.074, backward_time=0.094, optim_step_time=0.037, optim0_lr0=6.215e-05, train_time=0.304
[seoultech:0/4] 2024-01-24 03:38:50,641 (trainer:710) INFO: 19epoch:train:12299-13416batch: iter_time=8.070e-05, forward_time=0.066, loss_ctc=30.182, loss_att=13.388, acc=0.895, loss=18.426, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.206e-05, train_time=0.307
[seoultech:0/4] 2024-01-24 03:44:27,623 (trainer:710) INFO: 19epoch:train:13417-14534batch: iter_time=8.096e-05, forward_time=0.065, loss_ctc=29.461, loss_att=13.027, acc=0.891, loss=17.957, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.198e-05, train_time=0.301
[seoultech:0/4] 2024-01-24 03:50:08,420 (trainer:710) INFO: 19epoch:train:14535-15652batch: iter_time=8.797e-05, forward_time=0.067, loss_ctc=30.513, loss_att=13.536, acc=0.898, loss=18.629, backward_time=0.096, optim_step_time=0.040, optim0_lr0=6.190e-05, train_time=0.305
[seoultech:0/4] 2024-01-24 03:55:56,192 (trainer:710) INFO: 19epoch:train:15653-16770batch: iter_time=1.008e-04, forward_time=0.069, loss_ctc=30.544, loss_att=13.498, acc=0.898, loss=18.612, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.181e-05, train_time=0.311
[seoultech:0/4] 2024-01-24 04:01:44,097 (trainer:710) INFO: 19epoch:train:16771-17888batch: iter_time=1.002e-04, forward_time=0.069, loss_ctc=29.975, loss_att=13.232, acc=0.893, loss=18.255, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.173e-05, train_time=0.311
[seoultech:0/4] 2024-01-24 04:07:33,844 (trainer:710) INFO: 19epoch:train:17889-19006batch: iter_time=9.940e-05, forward_time=0.069, loss_ctc=30.275, loss_att=13.294, acc=0.895, loss=18.389, backward_time=0.096, optim_step_time=0.047, optim0_lr0=6.165e-05, train_time=0.313
[seoultech:0/4] 2024-01-24 04:13:21,800 (trainer:710) INFO: 19epoch:train:19007-20124batch: iter_time=1.009e-04, forward_time=0.069, loss_ctc=29.992, loss_att=13.194, acc=0.894, loss=18.233, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.157e-05, train_time=0.311
[seoultech:0/4] 2024-01-24 04:18:56,156 (trainer:710) INFO: 19epoch:train:20125-21242batch: iter_time=8.110e-05, forward_time=0.066, loss_ctc=30.572, loss_att=13.491, acc=0.896, loss=18.615, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.148e-05, train_time=0.299
[seoultech:0/4] 2024-01-24 04:24:30,474 (trainer:710) INFO: 19epoch:train:21243-22360batch: iter_time=8.199e-05, forward_time=0.066, loss_ctc=30.304, loss_att=13.343, acc=0.896, loss=18.431, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.140e-05, train_time=0.299
[seoultech:0/4] 2024-01-24 04:33:32,691 (trainer:330) INFO: 19epoch results: [train] iter_time=9.905e-05, forward_time=0.067, loss_ctc=30.164, loss_att=13.327, acc=0.895, loss=18.378, backward_time=0.095, optim_step_time=0.041, optim0_lr0=6.219e-05, train_time=0.308, time=1 hour, 55 minutes and 3.82 seconds, total_count=424916, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.927, cer_ctc=0.121, loss_att=8.041, acc=0.946, cer=0.073, wer=0.212, loss=11.607, time=7 minutes and 58.26 seconds, total_count=54112, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 1.58 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 04:33:39,743 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 04:33:39,749 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/9epoch.pth
[seoultech:0/4] 2024-01-24 04:33:39,749 (trainer:264) INFO: 20/35epoch started. Estimated time to finish: 1 day, 8 hours and 57 minutes
[seoultech:0/4] 2024-01-24 04:39:27,026 (trainer:710) INFO: 20epoch:train:1-1118batch: iter_time=2.478e-04, forward_time=0.066, loss_ctc=30.245, loss_att=13.308, acc=0.898, loss=18.389, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.132e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 04:45:08,672 (trainer:710) INFO: 20epoch:train:1119-2236batch: iter_time=8.041e-05, forward_time=0.066, loss_ctc=30.139, loss_att=13.299, acc=0.901, loss=18.351, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.124e-05, train_time=0.305
[seoultech:0/4] 2024-01-24 04:50:47,920 (trainer:710) INFO: 20epoch:train:2237-3354batch: iter_time=8.035e-05, forward_time=0.066, loss_ctc=30.358, loss_att=13.442, acc=0.898, loss=18.517, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.116e-05, train_time=0.303
[seoultech:0/4] 2024-01-24 04:56:30,393 (trainer:710) INFO: 20epoch:train:3355-4472batch: iter_time=8.018e-05, forward_time=0.066, loss_ctc=30.103, loss_att=13.330, acc=0.902, loss=18.362, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.108e-05, train_time=0.306
[seoultech:0/4] 2024-01-24 05:02:12,615 (trainer:710) INFO: 20epoch:train:4473-5590batch: iter_time=8.077e-05, forward_time=0.066, loss_ctc=30.416, loss_att=13.485, acc=0.901, loss=18.564, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.100e-05, train_time=0.306
[seoultech:0/4] 2024-01-24 05:07:49,754 (trainer:710) INFO: 20epoch:train:5591-6708batch: iter_time=8.227e-05, forward_time=0.066, loss_ctc=29.943, loss_att=13.268, acc=0.897, loss=18.271, backward_time=0.097, optim_step_time=0.037, optim0_lr0=6.092e-05, train_time=0.301
[seoultech:0/4] 2024-01-24 05:13:39,105 (trainer:710) INFO: 20epoch:train:6709-7826batch: iter_time=1.067e-04, forward_time=0.069, loss_ctc=29.724, loss_att=13.213, acc=0.895, loss=18.166, backward_time=0.095, optim_step_time=0.047, optim0_lr0=6.085e-05, train_time=0.312
[seoultech:0/4] 2024-01-24 05:19:25,487 (trainer:710) INFO: 20epoch:train:7827-8944batch: iter_time=9.828e-05, forward_time=0.068, loss_ctc=29.526, loss_att=13.081, acc=0.893, loss=18.015, backward_time=0.095, optim_step_time=0.043, optim0_lr0=6.077e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 05:25:02,975 (trainer:710) INFO: 20epoch:train:8945-10062batch: iter_time=8.076e-05, forward_time=0.066, loss_ctc=29.382, loss_att=13.006, acc=0.893, loss=17.919, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.069e-05, train_time=0.302
[seoultech:0/4] 2024-01-24 05:30:50,052 (trainer:710) INFO: 20epoch:train:10063-11180batch: iter_time=9.501e-05, forward_time=0.068, loss_ctc=30.376, loss_att=13.443, acc=0.899, loss=18.523, backward_time=0.095, optim_step_time=0.045, optim0_lr0=6.061e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 05:36:37,491 (trainer:710) INFO: 20epoch:train:11181-12298batch: iter_time=9.784e-05, forward_time=0.068, loss_ctc=29.663, loss_att=13.078, acc=0.896, loss=18.053, backward_time=0.095, optim_step_time=0.045, optim0_lr0=6.053e-05, train_time=0.310
[seoultech:0/4] 2024-01-24 05:42:13,798 (trainer:710) INFO: 20epoch:train:12299-13416batch: iter_time=7.947e-05, forward_time=0.066, loss_ctc=29.145, loss_att=12.894, acc=0.891, loss=17.769, backward_time=0.097, optim_step_time=0.036, optim0_lr0=6.046e-05, train_time=0.301
[seoultech:0/4] 2024-01-24 05:47:53,210 (trainer:710) INFO: 20epoch:train:13417-14534batch: iter_time=8.096e-05, forward_time=0.066, loss_ctc=29.467, loss_att=13.033, acc=0.893, loss=17.963, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.038e-05, train_time=0.303
[seoultech:0/4] 2024-01-24 05:53:35,126 (trainer:710) INFO: 20epoch:train:14535-15652batch: iter_time=8.113e-05, forward_time=0.066, loss_ctc=29.690, loss_att=13.127, acc=0.893, loss=18.096, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.030e-05, train_time=0.306
[seoultech:0/4] 2024-01-24 05:59:22,782 (trainer:710) INFO: 20epoch:train:15653-16770batch: iter_time=8.164e-05, forward_time=0.066, loss_ctc=29.706, loss_att=13.166, acc=0.895, loss=18.128, backward_time=0.095, optim_step_time=0.036, optim0_lr0=6.023e-05, train_time=0.311
[seoultech:0/4] 2024-01-24 06:05:03,539 (trainer:710) INFO: 20epoch:train:16771-17888batch: iter_time=8.129e-05, forward_time=0.065, loss_ctc=29.384, loss_att=12.978, acc=0.894, loss=17.900, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.015e-05, train_time=0.305
[seoultech:0/4] 2024-01-24 06:10:40,366 (trainer:710) INFO: 20epoch:train:17889-19006batch: iter_time=8.065e-05, forward_time=0.066, loss_ctc=29.674, loss_att=13.143, acc=0.896, loss=18.102, backward_time=0.096, optim_step_time=0.036, optim0_lr0=6.007e-05, train_time=0.301
[seoultech:0/4] 2024-01-24 06:16:26,422 (trainer:710) INFO: 20epoch:train:19007-20124batch: iter_time=8.218e-05, forward_time=0.066, loss_ctc=29.647, loss_att=13.094, acc=0.892, loss=18.060, backward_time=0.094, optim_step_time=0.036, optim0_lr0=6.000e-05, train_time=0.309
[seoultech:0/4] 2024-01-24 06:22:20,234 (trainer:710) INFO: 20epoch:train:20125-21242batch: iter_time=8.607e-05, forward_time=0.067, loss_ctc=30.126, loss_att=13.346, acc=0.898, loss=18.380, backward_time=0.095, optim_step_time=0.038, optim0_lr0=5.992e-05, train_time=0.316
[seoultech:0/4] 2024-01-24 06:31:56,001 (trainer:710) INFO: 20epoch:train:21243-22360batch: iter_time=1.204e-04, forward_time=0.107, loss_ctc=28.902, loss_att=12.842, acc=0.892, loss=17.660, backward_time=0.096, optim_step_time=0.076, optim0_lr0=5.985e-05, train_time=0.515
[seoultech:0/4] 2024-01-24 06:43:49,406 (trainer:330) INFO: 20epoch results: [train] iter_time=9.521e-05, forward_time=0.069, loss_ctc=29.772, loss_att=13.175, acc=0.896, loss=18.154, backward_time=0.095, optim_step_time=0.040, optim0_lr0=6.058e-05, train_time=0.317, time=1 hour, 58 minutes and 20.72 seconds, total_count=447280, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.708, cer_ctc=0.120, loss_att=8.000, acc=0.946, cer=0.072, wer=0.212, loss=11.512, time=10 minutes and 38.17 seconds, total_count=56960, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 10.77 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 06:43:59,033 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 06:43:59,045 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/10epoch.pth
[seoultech:0/4] 2024-01-24 06:43:59,046 (trainer:264) INFO: 21/35epoch started. Estimated time to finish: 1 day, 6 hours and 59 minutes
[seoultech:0/4] 2024-01-24 06:53:17,296 (trainer:710) INFO: 21epoch:train:1-1118batch: iter_time=3.051e-04, forward_time=0.099, loss_ctc=29.009, loss_att=12.868, acc=0.896, loss=17.710, backward_time=0.095, optim_step_time=0.074, optim0_lr0=5.977e-05, train_time=0.499
[seoultech:0/4] 2024-01-24 07:02:21,695 (trainer:710) INFO: 21epoch:train:1119-2236batch: iter_time=1.129e-04, forward_time=0.090, loss_ctc=29.115, loss_att=12.941, acc=0.897, loss=17.793, backward_time=0.096, optim_step_time=0.067, optim0_lr0=5.970e-05, train_time=0.487
[seoultech:0/4] 2024-01-24 07:11:28,850 (trainer:710) INFO: 21epoch:train:2237-3354batch: iter_time=1.119e-04, forward_time=0.088, loss_ctc=29.446, loss_att=13.005, acc=0.897, loss=17.937, backward_time=0.104, optim_step_time=0.068, optim0_lr0=5.962e-05, train_time=0.489
[seoultech:0/4] 2024-01-24 07:20:51,760 (trainer:710) INFO: 21epoch:train:3355-4472batch: iter_time=1.126e-04, forward_time=0.093, loss_ctc=29.488, loss_att=13.053, acc=0.896, loss=17.983, backward_time=0.104, optim_step_time=0.066, optim0_lr0=5.955e-05, train_time=0.503
[seoultech:0/4] 2024-01-24 07:30:58,388 (trainer:710) INFO: 21epoch:train:4473-5590batch: iter_time=1.111e-04, forward_time=0.117, loss_ctc=29.778, loss_att=13.132, acc=0.901, loss=18.126, backward_time=0.100, optim_step_time=0.055, optim0_lr0=5.948e-05, train_time=0.542
[seoultech:0/4] 2024-01-24 07:41:10,969 (trainer:710) INFO: 21epoch:train:5591-6708batch: iter_time=1.301e-04, forward_time=0.114, loss_ctc=29.482, loss_att=13.092, acc=0.897, loss=18.009, backward_time=0.098, optim_step_time=0.065, optim0_lr0=5.940e-05, train_time=0.548
[seoultech:0/4] 2024-01-24 07:51:22,191 (trainer:710) INFO: 21epoch:train:6709-7826batch: iter_time=1.264e-04, forward_time=0.113, loss_ctc=29.295, loss_att=12.989, acc=0.896, loss=17.881, backward_time=0.096, optim_step_time=0.063, optim0_lr0=5.933e-05, train_time=0.546
[seoultech:0/4] 2024-01-24 08:01:29,354 (trainer:710) INFO: 21epoch:train:7827-8944batch: iter_time=1.118e-04, forward_time=0.111, loss_ctc=29.485, loss_att=13.032, acc=0.899, loss=17.968, backward_time=0.095, optim_step_time=0.056, optim0_lr0=5.926e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 08:11:36,997 (trainer:710) INFO: 21epoch:train:8945-10062batch: iter_time=1.121e-04, forward_time=0.110, loss_ctc=29.956, loss_att=13.280, acc=0.901, loss=18.283, backward_time=0.097, optim_step_time=0.056, optim0_lr0=5.918e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 08:21:42,286 (trainer:710) INFO: 21epoch:train:10063-11180batch: iter_time=1.116e-04, forward_time=0.110, loss_ctc=29.592, loss_att=13.160, acc=0.895, loss=18.089, backward_time=0.098, optim_step_time=0.057, optim0_lr0=5.911e-05, train_time=0.541
[seoultech:0/4] 2024-01-24 08:31:22,210 (trainer:710) INFO: 21epoch:train:11181-12298batch: iter_time=1.117e-04, forward_time=0.104, loss_ctc=29.957, loss_att=13.212, acc=0.901, loss=18.235, backward_time=0.099, optim_step_time=0.060, optim0_lr0=5.904e-05, train_time=0.518
[seoultech:0/4] 2024-01-24 08:40:32,324 (trainer:710) INFO: 21epoch:train:12299-13416batch: iter_time=1.080e-04, forward_time=0.101, loss_ctc=29.454, loss_att=13.018, acc=0.894, loss=17.949, backward_time=0.102, optim_step_time=0.064, optim0_lr0=5.897e-05, train_time=0.492
[seoultech:0/4] 2024-01-24 08:50:33,174 (trainer:710) INFO: 21epoch:train:13417-14534batch: iter_time=1.090e-04, forward_time=0.105, loss_ctc=29.660, loss_att=13.171, acc=0.897, loss=18.118, backward_time=0.102, optim_step_time=0.058, optim0_lr0=5.890e-05, train_time=0.537
[seoultech:0/4] 2024-01-24 09:00:36,695 (trainer:710) INFO: 21epoch:train:14535-15652batch: iter_time=1.372e-04, forward_time=0.126, loss_ctc=28.954, loss_att=12.759, acc=0.894, loss=17.617, backward_time=0.101, optim_step_time=0.109, optim0_lr0=5.883e-05, train_time=0.539
[seoultech:0/4] 2024-01-24 09:10:44,248 (trainer:710) INFO: 21epoch:train:15653-16770batch: iter_time=1.398e-04, forward_time=0.126, loss_ctc=29.234, loss_att=12.954, acc=0.895, loss=17.838, backward_time=0.097, optim_step_time=0.108, optim0_lr0=5.875e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 09:20:47,812 (trainer:710) INFO: 21epoch:train:16771-17888batch: iter_time=1.373e-04, forward_time=0.125, loss_ctc=29.473, loss_att=13.065, acc=0.899, loss=17.988, backward_time=0.097, optim_step_time=0.107, optim0_lr0=5.868e-05, train_time=0.539
[seoultech:0/4] 2024-01-24 09:30:13,793 (trainer:710) INFO: 21epoch:train:17889-19006batch: iter_time=1.438e-04, forward_time=0.107, loss_ctc=29.148, loss_att=12.936, acc=0.896, loss=17.800, backward_time=0.108, optim_step_time=0.101, optim0_lr0=5.861e-05, train_time=0.506
[seoultech:0/4] 2024-01-24 09:39:53,318 (trainer:710) INFO: 21epoch:train:19007-20124batch: iter_time=1.323e-04, forward_time=0.091, loss_ctc=29.583, loss_att=13.072, acc=0.897, loss=18.026, backward_time=0.180, optim_step_time=0.068, optim0_lr0=5.854e-05, train_time=0.518
[seoultech:0/4] 2024-01-24 09:49:41,097 (trainer:710) INFO: 21epoch:train:20125-21242batch: iter_time=1.541e-04, forward_time=0.087, loss_ctc=29.253, loss_att=12.974, acc=0.897, loss=17.858, backward_time=0.164, optim_step_time=0.092, optim0_lr0=5.847e-05, train_time=0.525
[seoultech:0/4] 2024-01-24 09:59:13,855 (trainer:710) INFO: 21epoch:train:21243-22360batch: iter_time=2.275e-04, forward_time=0.133, loss_ctc=29.277, loss_att=12.962, acc=0.895, loss=17.857, backward_time=0.104, optim_step_time=0.117, optim0_lr0=5.840e-05, train_time=0.512
[seoultech:0/4] 2024-01-24 10:11:29,385 (trainer:330) INFO: 21epoch results: [train] iter_time=1.373e-04, forward_time=0.107, loss_ctc=29.429, loss_att=13.032, acc=0.897, loss=17.951, backward_time=0.107, optim_step_time=0.076, optim0_lr0=5.908e-05, train_time=0.524, time=3 hours, 15 minutes and 18.97 seconds, total_count=469644, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.620, cer_ctc=0.121, loss_att=7.947, acc=0.946, cer=0.072, wer=0.211, loss=11.449, time=11 minutes and 3.79 seconds, total_count=59808, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 7.58 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 10:11:37,032 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 10:11:37,042 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/11epoch.pth
[seoultech:0/4] 2024-01-24 10:11:37,042 (trainer:264) INFO: 22/35epoch started. Estimated time to finish: 1 day, 5 hours and 50 minutes
[seoultech:0/4] 2024-01-24 10:21:42,527 (trainer:710) INFO: 22epoch:train:1-1118batch: iter_time=5.166e-04, forward_time=0.129, loss_ctc=29.249, loss_att=12.990, acc=0.899, loss=17.868, backward_time=0.147, optim_step_time=0.117, optim0_lr0=5.833e-05, train_time=0.541
[seoultech:0/4] 2024-01-24 10:32:04,627 (trainer:710) INFO: 22epoch:train:1119-2236batch: iter_time=2.107e-04, forward_time=0.126, loss_ctc=29.449, loss_att=13.067, acc=0.901, loss=17.982, backward_time=0.180, optim_step_time=0.116, optim0_lr0=5.826e-05, train_time=0.556
[seoultech:0/4] 2024-01-24 10:41:49,442 (trainer:710) INFO: 22epoch:train:2237-3354batch: iter_time=1.264e-04, forward_time=0.085, loss_ctc=28.867, loss_att=12.832, acc=0.899, loss=17.642, backward_time=0.172, optim_step_time=0.084, optim0_lr0=5.820e-05, train_time=0.523
[seoultech:0/4] 2024-01-24 10:50:58,808 (trainer:710) INFO: 22epoch:train:3355-4472batch: iter_time=1.080e-04, forward_time=0.103, loss_ctc=28.856, loss_att=12.765, acc=0.895, loss=17.592, backward_time=0.101, optim_step_time=0.077, optim0_lr0=5.813e-05, train_time=0.491
[seoultech:0/4] 2024-01-24 10:59:56,291 (trainer:710) INFO: 22epoch:train:4473-5590batch: iter_time=1.363e-04, forward_time=0.109, loss_ctc=30.247, loss_att=13.342, acc=0.904, loss=18.414, backward_time=0.097, optim_step_time=0.092, optim0_lr0=5.806e-05, train_time=0.480
[seoultech:0/4] 2024-01-24 11:09:12,144 (trainer:710) INFO: 22epoch:train:5591-6708batch: iter_time=1.980e-04, forward_time=0.125, loss_ctc=29.230, loss_att=12.966, acc=0.900, loss=17.845, backward_time=0.098, optim_step_time=0.111, optim0_lr0=5.799e-05, train_time=0.496
[seoultech:0/4] 2024-01-24 11:18:25,620 (trainer:710) INFO: 22epoch:train:6709-7826batch: iter_time=1.613e-04, forward_time=0.114, loss_ctc=28.548, loss_att=12.707, acc=0.896, loss=17.459, backward_time=0.100, optim_step_time=0.095, optim0_lr0=5.792e-05, train_time=0.495
[seoultech:0/4] 2024-01-24 11:27:38,303 (trainer:710) INFO: 22epoch:train:7827-8944batch: iter_time=1.661e-04, forward_time=0.118, loss_ctc=28.650, loss_att=12.784, acc=0.894, loss=17.544, backward_time=0.105, optim_step_time=0.104, optim0_lr0=5.785e-05, train_time=0.494
[seoultech:0/4] 2024-01-24 11:37:03,116 (trainer:710) INFO: 22epoch:train:8945-10062batch: iter_time=1.944e-04, forward_time=0.125, loss_ctc=29.341, loss_att=13.071, acc=0.898, loss=17.952, backward_time=0.101, optim_step_time=0.111, optim0_lr0=5.779e-05, train_time=0.504
[seoultech:0/4] 2024-01-24 11:46:19,408 (trainer:710) INFO: 22epoch:train:10063-11180batch: iter_time=1.558e-04, forward_time=0.117, loss_ctc=28.917, loss_att=12.848, acc=0.897, loss=17.669, backward_time=0.100, optim_step_time=0.098, optim0_lr0=5.772e-05, train_time=0.497
[seoultech:0/4] 2024-01-24 11:55:24,451 (trainer:710) INFO: 22epoch:train:11181-12298batch: iter_time=1.298e-04, forward_time=0.109, loss_ctc=29.758, loss_att=13.210, acc=0.900, loss=18.175, backward_time=0.100, optim_step_time=0.094, optim0_lr0=5.765e-05, train_time=0.487
[seoultech:0/4] 2024-01-24 12:05:10,102 (trainer:710) INFO: 22epoch:train:12299-13416batch: iter_time=2.237e-04, forward_time=0.129, loss_ctc=28.675, loss_att=12.773, acc=0.896, loss=17.544, backward_time=0.099, optim_step_time=0.116, optim0_lr0=5.759e-05, train_time=0.523
[seoultech:0/4] 2024-01-24 12:14:42,617 (trainer:710) INFO: 22epoch:train:13417-14534batch: iter_time=1.486e-04, forward_time=0.107, loss_ctc=29.185, loss_att=12.915, acc=0.895, loss=17.796, backward_time=0.108, optim_step_time=0.083, optim0_lr0=5.752e-05, train_time=0.512
[seoultech:0/4] 2024-01-24 12:24:01,803 (trainer:710) INFO: 22epoch:train:14535-15652batch: iter_time=1.100e-04, forward_time=0.091, loss_ctc=28.535, loss_att=12.659, acc=0.896, loss=17.422, backward_time=0.108, optim_step_time=0.065, optim0_lr0=5.745e-05, train_time=0.500
[seoultech:0/4] 2024-01-24 12:34:10,207 (trainer:710) INFO: 22epoch:train:15653-16770batch: iter_time=1.128e-04, forward_time=0.121, loss_ctc=29.978, loss_att=13.209, acc=0.903, loss=18.240, backward_time=0.103, optim_step_time=0.069, optim0_lr0=5.739e-05, train_time=0.544
[seoultech:0/4] 2024-01-24 12:44:06,023 (trainer:710) INFO: 22epoch:train:16771-17888batch: iter_time=1.735e-04, forward_time=0.127, loss_ctc=28.861, loss_att=12.785, acc=0.896, loss=17.608, backward_time=0.100, optim_step_time=0.099, optim0_lr0=5.732e-05, train_time=0.532
[seoultech:0/4] 2024-01-24 12:53:47,271 (trainer:710) INFO: 22epoch:train:17889-19006batch: iter_time=1.163e-04, forward_time=0.118, loss_ctc=29.183, loss_att=12.910, acc=0.899, loss=17.792, backward_time=0.100, optim_step_time=0.084, optim0_lr0=5.725e-05, train_time=0.520
[seoultech:0/4] 2024-01-24 13:03:04,313 (trainer:710) INFO: 22epoch:train:19007-20124batch: iter_time=1.690e-04, forward_time=0.119, loss_ctc=29.357, loss_att=13.035, acc=0.897, loss=17.932, backward_time=0.101, optim_step_time=0.099, optim0_lr0=5.719e-05, train_time=0.498
[seoultech:0/4] 2024-01-24 13:12:39,222 (trainer:710) INFO: 22epoch:train:20125-21242batch: iter_time=2.345e-04, forward_time=0.129, loss_ctc=28.794, loss_att=12.788, acc=0.897, loss=17.590, backward_time=0.102, optim_step_time=0.117, optim0_lr0=5.712e-05, train_time=0.513
[seoultech:0/4] 2024-01-24 13:22:37,249 (trainer:710) INFO: 22epoch:train:21243-22360batch: iter_time=2.026e-04, forward_time=0.126, loss_ctc=28.615, loss_att=12.614, acc=0.893, loss=17.414, backward_time=0.098, optim_step_time=0.102, optim0_lr0=5.706e-05, train_time=0.534
[seoultech:0/4] 2024-01-24 13:34:48,576 (trainer:330) INFO: 22epoch results: [train] iter_time=1.797e-04, forward_time=0.116, loss_ctc=29.104, loss_att=12.909, acc=0.898, loss=17.767, backward_time=0.111, optim_step_time=0.097, optim0_lr0=5.769e-05, train_time=0.512, time=3 hours, 11 minutes and 4.57 seconds, total_count=492008, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.455, cer_ctc=0.119, loss_att=7.918, acc=0.946, cer=0.072, wer=0.211, loss=11.379, time=11 minutes and 1.55 seconds, total_count=62656, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 5.41 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 13:34:55,392 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 13:34:55,402 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/12epoch.pth
[seoultech:0/4] 2024-01-24 13:34:55,402 (trainer:264) INFO: 23/35epoch started. Estimated time to finish: 1 day, 4 hours and 27 minutes
[seoultech:0/4] 2024-01-24 13:44:55,957 (trainer:710) INFO: 23epoch:train:1-1118batch: iter_time=3.751e-04, forward_time=0.128, loss_ctc=28.602, loss_att=12.683, acc=0.898, loss=17.459, backward_time=0.112, optim_step_time=0.103, optim0_lr0=5.699e-05, train_time=0.536
[seoultech:0/4] 2024-01-24 13:55:17,682 (trainer:710) INFO: 23epoch:train:1119-2236batch: iter_time=2.294e-04, forward_time=0.132, loss_ctc=29.024, loss_att=12.855, acc=0.898, loss=17.706, backward_time=0.171, optim_step_time=0.118, optim0_lr0=5.693e-05, train_time=0.555
[seoultech:0/4] 2024-01-24 14:05:09,276 (trainer:710) INFO: 23epoch:train:2237-3354batch: iter_time=1.946e-04, forward_time=0.132, loss_ctc=28.762, loss_att=12.843, acc=0.900, loss=17.619, backward_time=0.098, optim_step_time=0.112, optim0_lr0=5.686e-05, train_time=0.529
[seoultech:0/4] 2024-01-24 14:15:29,949 (trainer:710) INFO: 23epoch:train:3355-4472batch: iter_time=2.337e-04, forward_time=0.135, loss_ctc=28.243, loss_att=12.538, acc=0.894, loss=17.250, backward_time=0.099, optim_step_time=0.116, optim0_lr0=5.680e-05, train_time=0.554
[seoultech:0/4] 2024-01-24 14:25:53,357 (trainer:710) INFO: 23epoch:train:4473-5590batch: iter_time=2.374e-04, forward_time=0.134, loss_ctc=28.876, loss_att=12.844, acc=0.901, loss=17.654, backward_time=0.099, optim_step_time=0.117, optim0_lr0=5.674e-05, train_time=0.557
[seoultech:0/4] 2024-01-24 14:35:56,103 (trainer:710) INFO: 23epoch:train:5591-6708batch: iter_time=2.241e-04, forward_time=0.131, loss_ctc=28.677, loss_att=12.735, acc=0.898, loss=17.517, backward_time=0.097, optim_step_time=0.117, optim0_lr0=5.667e-05, train_time=0.538
[seoultech:0/4] 2024-01-24 14:45:46,263 (trainer:710) INFO: 23epoch:train:6709-7826batch: iter_time=2.286e-04, forward_time=0.131, loss_ctc=28.726, loss_att=12.789, acc=0.900, loss=17.570, backward_time=0.097, optim_step_time=0.116, optim0_lr0=5.661e-05, train_time=0.527
[seoultech:0/4] 2024-01-24 14:54:44,868 (trainer:710) INFO: 23epoch:train:7827-8944batch: iter_time=1.333e-04, forward_time=0.102, loss_ctc=29.291, loss_att=12.982, acc=0.900, loss=17.875, backward_time=0.097, optim_step_time=0.066, optim0_lr0=5.655e-05, train_time=0.481
[seoultech:0/4] 2024-01-24 15:04:31,659 (trainer:710) INFO: 23epoch:train:8945-10062batch: iter_time=1.853e-04, forward_time=0.126, loss_ctc=28.208, loss_att=12.586, acc=0.895, loss=17.273, backward_time=0.094, optim_step_time=0.099, optim0_lr0=5.648e-05, train_time=0.524
[seoultech:0/4] 2024-01-24 15:14:39,683 (trainer:710) INFO: 23epoch:train:10063-11180batch: iter_time=2.262e-04, forward_time=0.132, loss_ctc=29.601, loss_att=13.120, acc=0.901, loss=18.064, backward_time=0.101, optim_step_time=0.117, optim0_lr0=5.642e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 15:24:27,640 (trainer:710) INFO: 23epoch:train:11181-12298batch: iter_time=2.343e-04, forward_time=0.129, loss_ctc=28.879, loss_att=12.869, acc=0.899, loss=17.672, backward_time=0.099, optim_step_time=0.114, optim0_lr0=5.636e-05, train_time=0.525
[seoultech:0/4] 2024-01-24 15:33:58,512 (trainer:710) INFO: 23epoch:train:12299-13416batch: iter_time=2.241e-04, forward_time=0.130, loss_ctc=28.746, loss_att=12.729, acc=0.900, loss=17.534, backward_time=0.101, optim_step_time=0.117, optim0_lr0=5.630e-05, train_time=0.510
[seoultech:0/4] 2024-01-24 15:43:36,463 (trainer:710) INFO: 23epoch:train:13417-14534batch: iter_time=1.380e-04, forward_time=0.117, loss_ctc=28.521, loss_att=12.581, acc=0.895, loss=17.363, backward_time=0.101, optim_step_time=0.065, optim0_lr0=5.623e-05, train_time=0.517
[seoultech:0/4] 2024-01-24 15:53:05,190 (trainer:710) INFO: 23epoch:train:14535-15652batch: iter_time=1.213e-04, forward_time=0.114, loss_ctc=28.608, loss_att=12.732, acc=0.895, loss=17.495, backward_time=0.102, optim_step_time=0.057, optim0_lr0=5.617e-05, train_time=0.508
[seoultech:0/4] 2024-01-24 16:02:16,271 (trainer:710) INFO: 23epoch:train:15653-16770batch: iter_time=1.145e-04, forward_time=0.088, loss_ctc=28.873, loss_att=12.785, acc=0.900, loss=17.611, backward_time=0.102, optim_step_time=0.063, optim0_lr0=5.611e-05, train_time=0.493
[seoultech:0/4] 2024-01-24 16:12:01,211 (trainer:710) INFO: 23epoch:train:16771-17888batch: iter_time=2.176e-04, forward_time=0.129, loss_ctc=28.587, loss_att=12.646, acc=0.897, loss=17.428, backward_time=0.101, optim_step_time=0.114, optim0_lr0=5.605e-05, train_time=0.522
[seoultech:0/4] 2024-01-24 16:21:17,745 (trainer:710) INFO: 23epoch:train:17889-19006batch: iter_time=2.244e-04, forward_time=0.129, loss_ctc=28.977, loss_att=12.891, acc=0.898, loss=17.717, backward_time=0.100, optim_step_time=0.117, optim0_lr0=5.599e-05, train_time=0.497
[seoultech:0/4] 2024-01-24 16:30:38,908 (trainer:710) INFO: 23epoch:train:19007-20124batch: iter_time=1.678e-04, forward_time=0.113, loss_ctc=28.666, loss_att=12.754, acc=0.898, loss=17.528, backward_time=0.101, optim_step_time=0.086, optim0_lr0=5.592e-05, train_time=0.501
[seoultech:0/4] 2024-01-24 16:40:08,520 (trainer:710) INFO: 23epoch:train:20125-21242batch: iter_time=2.019e-04, forward_time=0.126, loss_ctc=29.509, loss_att=13.044, acc=0.901, loss=17.984, backward_time=0.094, optim_step_time=0.113, optim0_lr0=5.586e-05, train_time=0.509
[seoultech:0/4] 2024-01-24 16:50:01,773 (trainer:710) INFO: 23epoch:train:21243-22360batch: iter_time=1.646e-04, forward_time=0.127, loss_ctc=28.949, loss_att=12.844, acc=0.900, loss=17.676, backward_time=0.094, optim_step_time=0.107, optim0_lr0=5.580e-05, train_time=0.530
[seoultech:0/4] 2024-01-24 17:02:14,831 (trainer:330) INFO: 23epoch results: [train] iter_time=2.038e-04, forward_time=0.124, loss_ctc=28.812, loss_att=12.791, acc=0.898, loss=17.597, backward_time=0.103, optim_step_time=0.102, optim0_lr0=5.639e-05, train_time=0.523, time=3 hours, 15 minutes and 10.54 seconds, total_count=514372, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.323, cer_ctc=0.120, loss_att=7.839, acc=0.947, cer=0.072, wer=0.210, loss=11.284, time=11 minutes and 2.26 seconds, total_count=65504, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 6.63 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 17:02:22,251 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 17:02:22,261 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/13epoch.pth
[seoultech:0/4] 2024-01-24 17:02:22,261 (trainer:264) INFO: 24/35epoch started. Estimated time to finish: 1 day, 2 hours and 55 minutes
[seoultech:0/4] 2024-01-24 17:12:19,871 (trainer:710) INFO: 24epoch:train:1-1118batch: iter_time=3.155e-04, forward_time=0.116, loss_ctc=28.601, loss_att=12.737, acc=0.903, loss=17.496, backward_time=0.101, optim_step_time=0.077, optim0_lr0=5.574e-05, train_time=0.534
[seoultech:0/4] 2024-01-24 17:22:35,017 (trainer:710) INFO: 24epoch:train:1119-2236batch: iter_time=1.170e-04, forward_time=0.130, loss_ctc=28.381, loss_att=12.630, acc=0.899, loss=17.356, backward_time=0.096, optim_step_time=0.078, optim0_lr0=5.568e-05, train_time=0.550
[seoultech:0/4] 2024-01-24 17:32:55,170 (trainer:710) INFO: 24epoch:train:2237-3354batch: iter_time=1.114e-04, forward_time=0.120, loss_ctc=27.829, loss_att=12.363, acc=0.897, loss=17.003, backward_time=0.096, optim_step_time=0.057, optim0_lr0=5.562e-05, train_time=0.554
[seoultech:0/4] 2024-01-24 17:43:11,270 (trainer:710) INFO: 24epoch:train:3355-4472batch: iter_time=1.074e-04, forward_time=0.117, loss_ctc=28.599, loss_att=12.704, acc=0.903, loss=17.473, backward_time=0.099, optim_step_time=0.055, optim0_lr0=5.556e-05, train_time=0.551
[seoultech:0/4] 2024-01-24 17:52:22,118 (trainer:710) INFO: 24epoch:train:4473-5590batch: iter_time=1.118e-04, forward_time=0.099, loss_ctc=28.552, loss_att=12.729, acc=0.897, loss=17.476, backward_time=0.100, optim_step_time=0.053, optim0_lr0=5.550e-05, train_time=0.492
[seoultech:0/4] 2024-01-24 18:02:29,397 (trainer:710) INFO: 24epoch:train:5591-6708batch: iter_time=1.152e-04, forward_time=0.117, loss_ctc=28.756, loss_att=12.734, acc=0.902, loss=17.540, backward_time=0.101, optim_step_time=0.058, optim0_lr0=5.544e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 18:12:32,272 (trainer:710) INFO: 24epoch:train:6709-7826batch: iter_time=1.132e-04, forward_time=0.115, loss_ctc=28.215, loss_att=12.591, acc=0.900, loss=17.278, backward_time=0.097, optim_step_time=0.059, optim0_lr0=5.538e-05, train_time=0.539
[seoultech:0/4] 2024-01-24 18:22:20,209 (trainer:710) INFO: 24epoch:train:7827-8944batch: iter_time=1.137e-04, forward_time=0.108, loss_ctc=28.996, loss_att=12.915, acc=0.903, loss=17.739, backward_time=0.098, optim_step_time=0.060, optim0_lr0=5.532e-05, train_time=0.526
[seoultech:0/4] 2024-01-24 18:32:11,286 (trainer:710) INFO: 24epoch:train:8945-10062batch: iter_time=1.124e-04, forward_time=0.109, loss_ctc=27.984, loss_att=12.500, acc=0.897, loss=17.145, backward_time=0.097, optim_step_time=0.063, optim0_lr0=5.526e-05, train_time=0.528
[seoultech:0/4] 2024-01-24 18:42:16,985 (trainer:710) INFO: 24epoch:train:10063-11180batch: iter_time=1.129e-04, forward_time=0.112, loss_ctc=28.313, loss_att=12.554, acc=0.897, loss=17.282, backward_time=0.097, optim_step_time=0.061, optim0_lr0=5.521e-05, train_time=0.541
[seoultech:0/4] 2024-01-24 18:51:43,556 (trainer:710) INFO: 24epoch:train:11181-12298batch: iter_time=1.173e-04, forward_time=0.109, loss_ctc=28.596, loss_att=12.640, acc=0.898, loss=17.427, backward_time=0.095, optim_step_time=0.077, optim0_lr0=5.515e-05, train_time=0.506
[seoultech:0/4] 2024-01-24 19:01:35,252 (trainer:710) INFO: 24epoch:train:12299-13416batch: iter_time=1.115e-04, forward_time=0.105, loss_ctc=28.324, loss_att=12.596, acc=0.895, loss=17.314, backward_time=0.095, optim_step_time=0.055, optim0_lr0=5.509e-05, train_time=0.529
[seoultech:0/4] 2024-01-24 19:11:42,658 (trainer:710) INFO: 24epoch:train:13417-14534batch: iter_time=1.164e-04, forward_time=0.110, loss_ctc=28.877, loss_att=12.859, acc=0.900, loss=17.665, backward_time=0.097, optim_step_time=0.060, optim0_lr0=5.503e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 19:21:21,304 (trainer:710) INFO: 24epoch:train:14535-15652batch: iter_time=1.144e-04, forward_time=0.105, loss_ctc=28.306, loss_att=12.614, acc=0.896, loss=17.322, backward_time=0.096, optim_step_time=0.067, optim0_lr0=5.497e-05, train_time=0.517
[seoultech:0/4] 2024-01-24 19:31:19,012 (trainer:710) INFO: 24epoch:train:15653-16770batch: iter_time=9.677e-05, forward_time=0.113, loss_ctc=29.300, loss_att=13.037, acc=0.906, loss=17.916, backward_time=0.095, optim_step_time=0.057, optim0_lr0=5.491e-05, train_time=0.534
[seoultech:0/4] 2024-01-24 19:41:27,154 (trainer:710) INFO: 24epoch:train:16771-17888batch: iter_time=1.118e-04, forward_time=0.117, loss_ctc=27.627, loss_att=12.308, acc=0.892, loss=16.903, backward_time=0.095, optim_step_time=0.059, optim0_lr0=5.486e-05, train_time=0.544
[seoultech:0/4] 2024-01-24 19:51:39,977 (trainer:710) INFO: 24epoch:train:17889-19006batch: iter_time=1.121e-04, forward_time=0.112, loss_ctc=28.861, loss_att=12.800, acc=0.898, loss=17.618, backward_time=0.095, optim_step_time=0.053, optim0_lr0=5.480e-05, train_time=0.548
[seoultech:0/4] 2024-01-24 20:01:31,458 (trainer:710) INFO: 24epoch:train:19007-20124batch: iter_time=1.160e-04, forward_time=0.095, loss_ctc=29.083, loss_att=12.885, acc=0.902, loss=17.744, backward_time=0.121, optim_step_time=0.061, optim0_lr0=5.474e-05, train_time=0.529
[seoultech:0/4] 2024-01-24 20:11:15,167 (trainer:710) INFO: 24epoch:train:20125-21242batch: iter_time=1.147e-04, forward_time=0.097, loss_ctc=28.398, loss_att=12.660, acc=0.899, loss=17.382, backward_time=0.115, optim_step_time=0.059, optim0_lr0=5.468e-05, train_time=0.522
[seoultech:0/4] 2024-01-24 20:20:45,576 (trainer:710) INFO: 24epoch:train:21243-22360batch: iter_time=1.169e-04, forward_time=0.107, loss_ctc=28.630, loss_att=12.694, acc=0.899, loss=17.475, backward_time=0.099, optim_step_time=0.068, optim0_lr0=5.463e-05, train_time=0.510
[seoultech:0/4] 2024-01-24 20:32:57,082 (trainer:330) INFO: 24epoch results: [train] iter_time=1.229e-04, forward_time=0.111, loss_ctc=28.504, loss_att=12.674, acc=0.899, loss=17.423, backward_time=0.099, optim_step_time=0.062, optim0_lr0=5.518e-05, train_time=0.532, time=3 hours, 18 minutes and 27.31 seconds, total_count=536736, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.635, cer_ctc=0.118, loss_att=7.870, acc=0.947, cer=0.071, wer=0.209, loss=11.400, time=11 minutes and 3.57 seconds, total_count=68352, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 3.94 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-24 20:33:04,568 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-24 20:33:04,577 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/14epoch.pth
[seoultech:0/4] 2024-01-24 20:33:04,577 (trainer:264) INFO: 25/35epoch started. Estimated time to finish: 1 day, 1 hour and 16 minutes
[seoultech:0/4] 2024-01-24 20:43:15,687 (trainer:710) INFO: 25epoch:train:1-1118batch: iter_time=3.246e-04, forward_time=0.121, loss_ctc=28.062, loss_att=12.507, acc=0.900, loss=17.174, backward_time=0.114, optim_step_time=0.086, optim0_lr0=5.457e-05, train_time=0.546
[seoultech:0/4] 2024-01-24 20:53:23,044 (trainer:710) INFO: 25epoch:train:1119-2236batch: iter_time=1.191e-04, forward_time=0.110, loss_ctc=28.872, loss_att=12.844, acc=0.902, loss=17.652, backward_time=0.113, optim_step_time=0.060, optim0_lr0=5.451e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 21:03:29,047 (trainer:710) INFO: 25epoch:train:2237-3354batch: iter_time=1.190e-04, forward_time=0.118, loss_ctc=27.663, loss_att=12.348, acc=0.898, loss=16.942, backward_time=0.110, optim_step_time=0.066, optim0_lr0=5.446e-05, train_time=0.542
[seoultech:0/4] 2024-01-24 21:13:33,652 (trainer:710) INFO: 25epoch:train:3355-4472batch: iter_time=1.162e-04, forward_time=0.118, loss_ctc=27.926, loss_att=12.450, acc=0.898, loss=17.093, backward_time=0.096, optim_step_time=0.059, optim0_lr0=5.440e-05, train_time=0.540
[seoultech:0/4] 2024-01-24 21:23:54,127 (trainer:710) INFO: 25epoch:train:4473-5590batch: iter_time=1.189e-04, forward_time=0.116, loss_ctc=28.254, loss_att=12.590, acc=0.899, loss=17.289, backward_time=0.105, optim_step_time=0.057, optim0_lr0=5.434e-05, train_time=0.555
[seoultech:0/4] 2024-01-24 21:34:14,722 (trainer:710) INFO: 25epoch:train:5591-6708batch: iter_time=1.211e-04, forward_time=0.111, loss_ctc=28.853, loss_att=12.868, acc=0.904, loss=17.663, backward_time=0.112, optim_step_time=0.060, optim0_lr0=5.429e-05, train_time=0.555
[seoultech:0/4] 2024-01-24 21:44:31,433 (trainer:710) INFO: 25epoch:train:6709-7826batch: iter_time=1.173e-04, forward_time=0.116, loss_ctc=28.272, loss_att=12.544, acc=0.901, loss=17.263, backward_time=0.101, optim_step_time=0.055, optim0_lr0=5.423e-05, train_time=0.551
[seoultech:0/4] 2024-01-24 21:54:44,318 (trainer:710) INFO: 25epoch:train:7827-8944batch: iter_time=1.198e-04, forward_time=0.115, loss_ctc=27.675, loss_att=12.289, acc=0.897, loss=16.905, backward_time=0.104, optim_step_time=0.061, optim0_lr0=5.418e-05, train_time=0.548
[seoultech:0/4] 2024-01-24 22:04:53,237 (trainer:710) INFO: 25epoch:train:8945-10062batch: iter_time=1.155e-04, forward_time=0.113, loss_ctc=28.495, loss_att=12.677, acc=0.899, loss=17.423, backward_time=0.100, optim_step_time=0.056, optim0_lr0=5.412e-05, train_time=0.544
[seoultech:0/4] 2024-01-24 22:14:55,950 (trainer:710) INFO: 25epoch:train:10063-11180batch: iter_time=1.189e-04, forward_time=0.115, loss_ctc=27.623, loss_att=12.333, acc=0.896, loss=16.920, backward_time=0.101, optim_step_time=0.065, optim0_lr0=5.407e-05, train_time=0.539
[seoultech:0/4] 2024-01-24 22:24:46,899 (trainer:710) INFO: 25epoch:train:11181-12298batch: iter_time=1.245e-04, forward_time=0.124, loss_ctc=28.553, loss_att=12.714, acc=0.900, loss=17.465, backward_time=0.100, optim_step_time=0.081, optim0_lr0=5.401e-05, train_time=0.528
[seoultech:0/4] 2024-01-24 22:34:30,462 (trainer:710) INFO: 25epoch:train:12299-13416batch: iter_time=1.203e-04, forward_time=0.117, loss_ctc=28.430, loss_att=12.585, acc=0.901, loss=17.339, backward_time=0.100, optim_step_time=0.060, optim0_lr0=5.396e-05, train_time=0.522
[seoultech:0/4] 2024-01-24 22:44:38,183 (trainer:710) INFO: 25epoch:train:13417-14534batch: iter_time=1.201e-04, forward_time=0.115, loss_ctc=28.287, loss_att=12.578, acc=0.900, loss=17.291, backward_time=0.096, optim_step_time=0.056, optim0_lr0=5.390e-05, train_time=0.543
[seoultech:0/4] 2024-01-24 22:54:54,382 (trainer:710) INFO: 25epoch:train:14535-15652batch: iter_time=1.209e-04, forward_time=0.121, loss_ctc=28.718, loss_att=12.818, acc=0.902, loss=17.588, backward_time=0.102, optim_step_time=0.064, optim0_lr0=5.385e-05, train_time=0.551
[seoultech:0/4] 2024-01-24 23:05:21,622 (trainer:710) INFO: 25epoch:train:15653-16770batch: iter_time=1.233e-04, forward_time=0.128, loss_ctc=28.097, loss_att=12.480, acc=0.902, loss=17.165, backward_time=0.101, optim_step_time=0.068, optim0_lr0=5.379e-05, train_time=0.561
[seoultech:0/4] 2024-01-24 23:15:39,635 (trainer:710) INFO: 25epoch:train:16771-17888batch: iter_time=1.404e-04, forward_time=0.129, loss_ctc=28.114, loss_att=12.548, acc=0.899, loss=17.217, backward_time=0.100, optim_step_time=0.082, optim0_lr0=5.374e-05, train_time=0.552
[seoultech:0/4] 2024-01-24 23:25:52,034 (trainer:710) INFO: 25epoch:train:17889-19006batch: iter_time=1.499e-04, forward_time=0.135, loss_ctc=27.274, loss_att=12.180, acc=0.892, loss=16.708, backward_time=0.099, optim_step_time=0.095, optim0_lr0=5.368e-05, train_time=0.547
[seoultech:0/4] 2024-01-24 23:35:45,551 (trainer:710) INFO: 25epoch:train:19007-20124batch: iter_time=1.981e-04, forward_time=0.131, loss_ctc=28.712, loss_att=12.739, acc=0.897, loss=17.531, backward_time=0.101, optim_step_time=0.110, optim0_lr0=5.363e-05, train_time=0.530
[seoultech:0/4] 2024-01-24 23:45:36,696 (trainer:710) INFO: 25epoch:train:20125-21242batch: iter_time=1.240e-04, forward_time=0.115, loss_ctc=28.099, loss_att=12.547, acc=0.900, loss=17.213, backward_time=0.100, optim_step_time=0.060, optim0_lr0=5.358e-05, train_time=0.528
[seoultech:0/4] 2024-01-24 23:55:50,373 (trainer:710) INFO: 25epoch:train:21243-22360batch: iter_time=1.691e-04, forward_time=0.122, loss_ctc=28.993, loss_att=12.878, acc=0.901, loss=17.712, backward_time=0.101, optim_step_time=0.085, optim0_lr0=5.352e-05, train_time=0.548
[seoultech:0/4] 2024-01-25 00:08:24,930 (trainer:330) INFO: 25epoch results: [train] iter_time=1.391e-04, forward_time=0.119, loss_ctc=28.240, loss_att=12.572, acc=0.900, loss=17.272, backward_time=0.103, optim_step_time=0.069, optim0_lr0=5.404e-05, train_time=0.544, time=3 hours, 22 minutes and 50.24 seconds, total_count=559100, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.386, cer_ctc=0.118, loss_att=7.841, acc=0.947, cer=0.071, wer=0.209, loss=11.305, time=11 minutes and 2.55 seconds, total_count=71200, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 27.56 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-25 00:08:32,965 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-25 00:08:32,975 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/15epoch.pth
[seoultech:0/4] 2024-01-25 00:08:32,975 (trainer:264) INFO: 26/35epoch started. Estimated time to finish: 23 hours, 29 minutes and 21.52 seconds
[seoultech:0/4] 2024-01-25 00:17:45,954 (trainer:710) INFO: 26epoch:train:1-1118batch: iter_time=6.556e-04, forward_time=0.113, loss_ctc=27.697, loss_att=12.395, acc=0.901, loss=16.986, backward_time=0.101, optim_step_time=0.102, optim0_lr0=5.347e-05, train_time=0.494
[seoultech:0/4] 2024-01-25 00:26:51,091 (trainer:710) INFO: 26epoch:train:1119-2236batch: iter_time=1.398e-04, forward_time=0.112, loss_ctc=27.756, loss_att=12.396, acc=0.899, loss=17.004, backward_time=0.098, optim_step_time=0.095, optim0_lr0=5.342e-05, train_time=0.487
[seoultech:0/4] 2024-01-25 00:36:04,717 (trainer:710) INFO: 26epoch:train:2237-3354batch: iter_time=2.030e-04, forward_time=0.124, loss_ctc=28.319, loss_att=12.599, acc=0.901, loss=17.315, backward_time=0.102, optim_step_time=0.113, optim0_lr0=5.336e-05, train_time=0.494
[seoultech:0/4] 2024-01-25 00:46:00,039 (trainer:710) INFO: 26epoch:train:3355-4472batch: iter_time=2.233e-04, forward_time=0.133, loss_ctc=27.502, loss_att=12.273, acc=0.900, loss=16.841, backward_time=0.109, optim_step_time=0.117, optim0_lr0=5.331e-05, train_time=0.532
[seoultech:0/4] 2024-01-25 00:56:12,829 (trainer:710) INFO: 26epoch:train:4473-5590batch: iter_time=1.820e-04, forward_time=0.106, loss_ctc=27.715, loss_att=12.398, acc=0.900, loss=16.993, backward_time=0.168, optim_step_time=0.108, optim0_lr0=5.326e-05, train_time=0.548
[seoultech:0/4] 2024-01-25 01:06:34,514 (trainer:710) INFO: 26epoch:train:5591-6708batch: iter_time=2.218e-04, forward_time=0.131, loss_ctc=28.314, loss_att=12.606, acc=0.900, loss=17.318, backward_time=0.177, optim_step_time=0.118, optim0_lr0=5.320e-05, train_time=0.555
[seoultech:0/4] 2024-01-25 01:16:58,440 (trainer:710) INFO: 26epoch:train:6709-7826batch: iter_time=2.162e-04, forward_time=0.128, loss_ctc=27.479, loss_att=12.195, acc=0.898, loss=16.780, backward_time=0.179, optim_step_time=0.118, optim0_lr0=5.315e-05, train_time=0.557
[seoultech:0/4] 2024-01-25 01:26:56,691 (trainer:710) INFO: 26epoch:train:7827-8944batch: iter_time=2.249e-04, forward_time=0.126, loss_ctc=28.395, loss_att=12.682, acc=0.904, loss=17.396, backward_time=0.157, optim_step_time=0.117, optim0_lr0=5.310e-05, train_time=0.534
[seoultech:0/4] 2024-01-25 01:36:40,372 (trainer:710) INFO: 26epoch:train:8945-10062batch: iter_time=2.310e-04, forward_time=0.130, loss_ctc=28.305, loss_att=12.643, acc=0.902, loss=17.342, backward_time=0.104, optim_step_time=0.118, optim0_lr0=5.305e-05, train_time=0.521
[seoultech:0/4] 2024-01-25 01:46:57,532 (trainer:710) INFO: 26epoch:train:10063-11180batch: iter_time=2.372e-04, forward_time=0.130, loss_ctc=28.086, loss_att=12.536, acc=0.903, loss=17.201, backward_time=0.134, optim_step_time=0.117, optim0_lr0=5.299e-05, train_time=0.551
[seoultech:0/4] 2024-01-25 01:57:25,610 (trainer:710) INFO: 26epoch:train:11181-12298batch: iter_time=2.314e-04, forward_time=0.132, loss_ctc=27.827, loss_att=12.324, acc=0.897, loss=16.975, backward_time=0.177, optim_step_time=0.119, optim0_lr0=5.294e-05, train_time=0.561
[seoultech:0/4] 2024-01-25 02:07:56,121 (trainer:710) INFO: 26epoch:train:12299-13416batch: iter_time=2.285e-04, forward_time=0.135, loss_ctc=27.890, loss_att=12.413, acc=0.901, loss=17.056, backward_time=0.178, optim_step_time=0.119, optim0_lr0=5.289e-05, train_time=0.563
[seoultech:0/4] 2024-01-25 02:18:16,611 (trainer:710) INFO: 26epoch:train:13417-14534batch: iter_time=2.207e-04, forward_time=0.131, loss_ctc=28.454, loss_att=12.691, acc=0.902, loss=17.420, backward_time=0.179, optim_step_time=0.118, optim0_lr0=5.284e-05, train_time=0.554
[seoultech:0/4] 2024-01-25 02:28:23,809 (trainer:710) INFO: 26epoch:train:14535-15652batch: iter_time=2.020e-04, forward_time=0.110, loss_ctc=27.654, loss_att=12.354, acc=0.898, loss=16.944, backward_time=0.177, optim_step_time=0.103, optim0_lr0=5.279e-05, train_time=0.542
[seoultech:0/4] 2024-01-25 02:38:46,832 (trainer:710) INFO: 26epoch:train:15653-16770batch: iter_time=2.384e-04, forward_time=0.128, loss_ctc=27.651, loss_att=12.368, acc=0.897, loss=16.953, backward_time=0.177, optim_step_time=0.118, optim0_lr0=5.274e-05, train_time=0.556
[seoultech:0/4] 2024-01-25 02:49:08,592 (trainer:710) INFO: 26epoch:train:16771-17888batch: iter_time=2.442e-04, forward_time=0.130, loss_ctc=28.269, loss_att=12.532, acc=0.902, loss=17.254, backward_time=0.178, optim_step_time=0.118, optim0_lr0=5.268e-05, train_time=0.555
[seoultech:0/4] 2024-01-25 02:59:25,132 (trainer:710) INFO: 26epoch:train:17889-19006batch: iter_time=2.279e-04, forward_time=0.129, loss_ctc=27.968, loss_att=12.455, acc=0.901, loss=17.109, backward_time=0.176, optim_step_time=0.116, optim0_lr0=5.263e-05, train_time=0.551
[seoultech:0/4] 2024-01-25 03:09:22,539 (trainer:710) INFO: 26epoch:train:19007-20124batch: iter_time=2.288e-04, forward_time=0.131, loss_ctc=28.035, loss_att=12.504, acc=0.902, loss=17.163, backward_time=0.157, optim_step_time=0.117, optim0_lr0=5.258e-05, train_time=0.534
[seoultech:0/4] 2024-01-25 03:18:14,136 (trainer:710) INFO: 26epoch:train:20125-21242batch: iter_time=1.292e-04, forward_time=0.080, loss_ctc=28.249, loss_att=12.620, acc=0.901, loss=17.309, backward_time=0.117, optim_step_time=0.075, optim0_lr0=5.253e-05, train_time=0.475
[seoultech:0/4] 2024-01-25 03:27:52,686 (trainer:710) INFO: 26epoch:train:21243-22360batch: iter_time=1.243e-04, forward_time=0.072, loss_ctc=27.666, loss_att=12.310, acc=0.897, loss=16.917, backward_time=0.175, optim_step_time=0.075, optim0_lr0=5.248e-05, train_time=0.517
[seoultech:0/4] 2024-01-25 03:40:45,692 (trainer:330) INFO: 26epoch results: [train] iter_time=2.305e-04, forward_time=0.121, loss_ctc=27.953, loss_att=12.461, acc=0.900, loss=17.108, backward_time=0.151, optim_step_time=0.110, optim0_lr0=5.297e-05, train_time=0.534, time=3 hours, 19 minutes and 23.86 seconds, total_count=581464, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.742, cer_ctc=0.117, loss_att=7.926, acc=0.947, cer=0.071, wer=0.208, loss=11.471, time=11 minutes and 15.55 seconds, total_count=74048, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 33.3 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-25 03:40:55,346 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-25 03:40:55,356 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/16epoch.pth
[seoultech:0/4] 2024-01-25 03:40:55,357 (trainer:264) INFO: 27/35epoch started. Estimated time to finish: 21 hours, 33 minutes and 9.06 seconds
[seoultech:0/4] 2024-01-25 03:51:31,232 (trainer:710) INFO: 27epoch:train:1-1118batch: iter_time=3.792e-04, forward_time=0.111, loss_ctc=27.565, loss_att=12.295, acc=0.901, loss=16.876, backward_time=0.178, optim_step_time=0.103, optim0_lr0=5.243e-05, train_time=0.568
[seoultech:0/4] 2024-01-25 04:00:56,413 (trainer:710) INFO: 27epoch:train:1119-2236batch: iter_time=1.150e-04, forward_time=0.100, loss_ctc=27.581, loss_att=12.304, acc=0.900, loss=16.887, backward_time=0.115, optim_step_time=0.073, optim0_lr0=5.238e-05, train_time=0.505
[seoultech:0/4] 2024-01-25 04:10:32,648 (trainer:710) INFO: 27epoch:train:2237-3354batch: iter_time=1.137e-04, forward_time=0.104, loss_ctc=27.750, loss_att=12.404, acc=0.903, loss=17.008, backward_time=0.101, optim_step_time=0.063, optim0_lr0=5.233e-05, train_time=0.515
[seoultech:0/4] 2024-01-25 04:20:38,695 (trainer:710) INFO: 27epoch:train:3355-4472batch: iter_time=1.123e-04, forward_time=0.110, loss_ctc=27.542, loss_att=12.228, acc=0.900, loss=16.822, backward_time=0.111, optim_step_time=0.060, optim0_lr0=5.228e-05, train_time=0.542
[seoultech:0/4] 2024-01-25 04:31:02,316 (trainer:710) INFO: 27epoch:train:4473-5590batch: iter_time=1.109e-04, forward_time=0.115, loss_ctc=27.732, loss_att=12.392, acc=0.903, loss=16.994, backward_time=0.094, optim_step_time=0.053, optim0_lr0=5.223e-05, train_time=0.557
[seoultech:0/4] 2024-01-25 04:41:26,699 (trainer:710) INFO: 27epoch:train:5591-6708batch: iter_time=1.184e-04, forward_time=0.088, loss_ctc=27.623, loss_att=12.326, acc=0.901, loss=16.915, backward_time=0.154, optim_step_time=0.069, optim0_lr0=5.218e-05, train_time=0.558
[seoultech:0/4] 2024-01-25 04:51:33,933 (trainer:710) INFO: 27epoch:train:6709-7826batch: iter_time=1.006e-04, forward_time=0.111, loss_ctc=27.003, loss_att=12.045, acc=0.897, loss=16.532, backward_time=0.094, optim_step_time=0.052, optim0_lr0=5.213e-05, train_time=0.543
[seoultech:0/4] 2024-01-25 05:01:16,451 (trainer:710) INFO: 27epoch:train:7827-8944batch: iter_time=1.087e-04, forward_time=0.116, loss_ctc=28.220, loss_att=12.595, acc=0.905, loss=17.282, backward_time=0.093, optim_step_time=0.057, optim0_lr0=5.208e-05, train_time=0.521
[seoultech:0/4] 2024-01-25 05:10:34,276 (trainer:710) INFO: 27epoch:train:8945-10062batch: iter_time=1.099e-04, forward_time=0.102, loss_ctc=27.617, loss_att=12.331, acc=0.901, loss=16.917, backward_time=0.093, optim_step_time=0.061, optim0_lr0=5.203e-05, train_time=0.499
[seoultech:0/4] 2024-01-25 05:19:37,322 (trainer:710) INFO: 27epoch:train:10063-11180batch: iter_time=1.116e-04, forward_time=0.087, loss_ctc=27.932, loss_att=12.481, acc=0.902, loss=17.116, backward_time=0.100, optim_step_time=0.067, optim0_lr0=5.198e-05, train_time=0.485
[seoultech:0/4] 2024-01-25 05:28:50,945 (trainer:710) INFO: 27epoch:train:11181-12298batch: iter_time=1.100e-04, forward_time=0.099, loss_ctc=27.972, loss_att=12.547, acc=0.902, loss=17.174, backward_time=0.106, optim_step_time=0.062, optim0_lr0=5.193e-05, train_time=0.495
[seoultech:0/4] 2024-01-25 05:37:56,589 (trainer:710) INFO: 27epoch:train:12299-13416batch: iter_time=1.127e-04, forward_time=0.100, loss_ctc=27.531, loss_att=12.232, acc=0.898, loss=16.822, backward_time=0.096, optim_step_time=0.067, optim0_lr0=5.189e-05, train_time=0.488
[seoultech:0/4] 2024-01-25 05:47:15,945 (trainer:710) INFO: 27epoch:train:13417-14534batch: iter_time=1.133e-04, forward_time=0.107, loss_ctc=27.646, loss_att=12.309, acc=0.900, loss=16.910, backward_time=0.096, optim_step_time=0.066, optim0_lr0=5.184e-05, train_time=0.500
[seoultech:0/4] 2024-01-25 05:55:58,175 (trainer:710) INFO: 27epoch:train:14535-15652batch: iter_time=1.117e-04, forward_time=0.086, loss_ctc=27.648, loss_att=12.355, acc=0.899, loss=16.943, backward_time=0.096, optim_step_time=0.066, optim0_lr0=5.179e-05, train_time=0.467
[seoultech:0/4] 2024-01-25 06:05:30,486 (trainer:710) INFO: 27epoch:train:15653-16770batch: iter_time=1.163e-04, forward_time=0.106, loss_ctc=27.943, loss_att=12.428, acc=0.901, loss=17.083, backward_time=0.110, optim_step_time=0.069, optim0_lr0=5.174e-05, train_time=0.512
[seoultech:0/4] 2024-01-25 06:15:16,375 (trainer:710) INFO: 27epoch:train:16771-17888batch: iter_time=1.182e-04, forward_time=0.071, loss_ctc=27.865, loss_att=12.436, acc=0.900, loss=17.065, backward_time=0.180, optim_step_time=0.074, optim0_lr0=5.169e-05, train_time=0.524
[seoultech:0/4] 2024-01-25 06:25:22,383 (trainer:710) INFO: 27epoch:train:17889-19006batch: iter_time=1.180e-04, forward_time=0.074, loss_ctc=28.081, loss_att=12.520, acc=0.901, loss=17.188, backward_time=0.180, optim_step_time=0.074, optim0_lr0=5.164e-05, train_time=0.542
[seoultech:0/4] 2024-01-25 06:35:08,480 (trainer:710) INFO: 27epoch:train:19007-20124batch: iter_time=1.058e-04, forward_time=0.074, loss_ctc=28.285, loss_att=12.650, acc=0.901, loss=17.340, backward_time=0.168, optim_step_time=0.071, optim0_lr0=5.160e-05, train_time=0.524
[seoultech:0/4] 2024-01-25 06:44:17,929 (trainer:710) INFO: 27epoch:train:20125-21242batch: iter_time=1.107e-04, forward_time=0.104, loss_ctc=27.581, loss_att=12.309, acc=0.899, loss=16.891, backward_time=0.099, optim_step_time=0.062, optim0_lr0=5.155e-05, train_time=0.491
[seoultech:0/4] 2024-01-25 06:53:39,306 (trainer:710) INFO: 27epoch:train:21243-22360batch: iter_time=1.079e-04, forward_time=0.112, loss_ctc=27.783, loss_att=12.403, acc=0.901, loss=17.017, backward_time=0.098, optim_step_time=0.058, optim0_lr0=5.150e-05, train_time=0.502
[seoultech:0/4] 2024-01-25 07:05:55,882 (trainer:330) INFO: 27epoch results: [train] iter_time=1.252e-04, forward_time=0.099, loss_ctc=27.741, loss_att=12.378, acc=0.901, loss=16.987, backward_time=0.118, optim_step_time=0.066, optim0_lr0=5.196e-05, train_time=0.517, time=3 hours, 12 minutes and 47.95 seconds, total_count=603828, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.598, cer_ctc=0.117, loss_att=7.792, acc=0.947, cer=0.071, wer=0.208, loss=11.334, time=11 minutes and 3.57 seconds, total_count=76896, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 9 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-25 07:06:03,535 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-25 07:06:03,545 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/17epoch.pth
[seoultech:0/4] 2024-01-25 07:06:03,546 (trainer:264) INFO: 28/35epoch started. Estimated time to finish: 19 hours, 27 minutes and 40.56 seconds
[seoultech:0/4] 2024-01-25 07:15:35,728 (trainer:710) INFO: 28epoch:train:1-1118batch: iter_time=3.082e-04, forward_time=0.106, loss_ctc=27.117, loss_att=12.160, acc=0.903, loss=16.647, backward_time=0.101, optim_step_time=0.071, optim0_lr0=5.145e-05, train_time=0.511
[seoultech:0/4] 2024-01-25 07:25:02,742 (trainer:710) INFO: 28epoch:train:1119-2236batch: iter_time=1.001e-04, forward_time=0.110, loss_ctc=27.073, loss_att=12.126, acc=0.900, loss=16.610, backward_time=0.102, optim_step_time=0.072, optim0_lr0=5.140e-05, train_time=0.507
[seoultech:0/4] 2024-01-25 07:34:26,431 (trainer:710) INFO: 28epoch:train:2237-3354batch: iter_time=1.044e-04, forward_time=0.100, loss_ctc=27.370, loss_att=12.247, acc=0.904, loss=16.784, backward_time=0.100, optim_step_time=0.057, optim0_lr0=5.136e-05, train_time=0.504
[seoultech:0/4] 2024-01-25 07:44:08,032 (trainer:710) INFO: 28epoch:train:3355-4472batch: iter_time=1.106e-04, forward_time=0.104, loss_ctc=27.351, loss_att=12.262, acc=0.900, loss=16.789, backward_time=0.100, optim_step_time=0.059, optim0_lr0=5.131e-05, train_time=0.520
[seoultech:0/4] 2024-01-25 07:53:36,203 (trainer:710) INFO: 28epoch:train:4473-5590batch: iter_time=1.168e-04, forward_time=0.104, loss_ctc=28.027, loss_att=12.499, acc=0.905, loss=17.157, backward_time=0.099, optim_step_time=0.057, optim0_lr0=5.126e-05, train_time=0.508
[seoultech:0/4] 2024-01-25 08:02:47,547 (trainer:710) INFO: 28epoch:train:5591-6708batch: iter_time=1.115e-04, forward_time=0.094, loss_ctc=27.546, loss_att=12.302, acc=0.904, loss=16.875, backward_time=0.098, optim_step_time=0.065, optim0_lr0=5.122e-05, train_time=0.493
[seoultech:0/4] 2024-01-25 08:12:08,297 (trainer:710) INFO: 28epoch:train:6709-7826batch: iter_time=1.172e-04, forward_time=0.082, loss_ctc=27.080, loss_att=12.171, acc=0.900, loss=16.643, backward_time=0.131, optim_step_time=0.070, optim0_lr0=5.117e-05, train_time=0.501
[seoultech:0/4] 2024-01-25 08:21:33,742 (trainer:710) INFO: 28epoch:train:7827-8944batch: iter_time=1.679e-04, forward_time=0.110, loss_ctc=26.722, loss_att=11.944, acc=0.898, loss=16.377, backward_time=0.103, optim_step_time=0.088, optim0_lr0=5.112e-05, train_time=0.505
[seoultech:0/4] 2024-01-25 08:30:54,788 (trainer:710) INFO: 28epoch:train:8945-10062batch: iter_time=1.171e-04, forward_time=0.093, loss_ctc=27.600, loss_att=12.281, acc=0.900, loss=16.876, backward_time=0.112, optim_step_time=0.069, optim0_lr0=5.108e-05, train_time=0.502
[seoultech:0/4] 2024-01-25 08:40:43,558 (trainer:710) INFO: 28epoch:train:10063-11180batch: iter_time=1.429e-04, forward_time=0.107, loss_ctc=27.552, loss_att=12.353, acc=0.901, loss=16.912, backward_time=0.130, optim_step_time=0.080, optim0_lr0=5.103e-05, train_time=0.526
[seoultech:0/4] 2024-01-25 08:50:54,122 (trainer:710) INFO: 28epoch:train:11181-12298batch: iter_time=2.236e-04, forward_time=0.128, loss_ctc=27.928, loss_att=12.425, acc=0.901, loss=17.076, backward_time=0.152, optim_step_time=0.118, optim0_lr0=5.098e-05, train_time=0.545
[seoultech:0/4] 2024-01-25 09:01:13,242 (trainer:710) INFO: 28epoch:train:12299-13416batch: iter_time=2.341e-04, forward_time=0.129, loss_ctc=27.144, loss_att=12.149, acc=0.900, loss=16.647, backward_time=0.103, optim_step_time=0.117, optim0_lr0=5.094e-05, train_time=0.553
[seoultech:0/4] 2024-01-25 09:11:24,338 (trainer:710) INFO: 28epoch:train:13417-14534batch: iter_time=2.315e-04, forward_time=0.129, loss_ctc=27.357, loss_att=12.160, acc=0.900, loss=16.719, backward_time=0.125, optim_step_time=0.118, optim0_lr0=5.089e-05, train_time=0.546
[seoultech:0/4] 2024-01-25 09:21:32,226 (trainer:710) INFO: 28epoch:train:14535-15652batch: iter_time=2.030e-04, forward_time=0.125, loss_ctc=27.948, loss_att=12.479, acc=0.902, loss=17.120, backward_time=0.102, optim_step_time=0.104, optim0_lr0=5.084e-05, train_time=0.543
[seoultech:0/4] 2024-01-25 09:31:20,731 (trainer:710) INFO: 28epoch:train:15653-16770batch: iter_time=2.244e-04, forward_time=0.129, loss_ctc=27.216, loss_att=12.166, acc=0.898, loss=16.681, backward_time=0.097, optim_step_time=0.116, optim0_lr0=5.080e-05, train_time=0.526
[seoultech:0/4] 2024-01-25 09:41:00,578 (trainer:710) INFO: 28epoch:train:16771-17888batch: iter_time=2.229e-04, forward_time=0.127, loss_ctc=27.239, loss_att=12.166, acc=0.900, loss=16.688, backward_time=0.096, optim_step_time=0.116, optim0_lr0=5.075e-05, train_time=0.518
[seoultech:0/4] 2024-01-25 09:50:08,284 (trainer:710) INFO: 28epoch:train:17889-19006batch: iter_time=1.809e-04, forward_time=0.110, loss_ctc=27.946, loss_att=12.480, acc=0.903, loss=17.120, backward_time=0.098, optim_step_time=0.096, optim0_lr0=5.071e-05, train_time=0.489
[seoultech:0/4] 2024-01-25 09:59:38,033 (trainer:710) INFO: 28epoch:train:19007-20124batch: iter_time=2.288e-04, forward_time=0.128, loss_ctc=28.016, loss_att=12.526, acc=0.905, loss=17.173, backward_time=0.097, optim_step_time=0.116, optim0_lr0=5.066e-05, train_time=0.509
[seoultech:0/4] 2024-01-25 10:09:15,106 (trainer:710) INFO: 28epoch:train:20125-21242batch: iter_time=2.195e-04, forward_time=0.127, loss_ctc=28.167, loss_att=12.527, acc=0.905, loss=17.219, backward_time=0.096, optim_step_time=0.116, optim0_lr0=5.062e-05, train_time=0.515
[seoultech:0/4] 2024-01-25 10:18:54,285 (trainer:710) INFO: 28epoch:train:21243-22360batch: iter_time=2.163e-04, forward_time=0.128, loss_ctc=27.281, loss_att=12.144, acc=0.899, loss=16.685, backward_time=0.095, optim_step_time=0.116, optim0_lr0=5.057e-05, train_time=0.517
[seoultech:0/4] 2024-01-25 10:30:56,858 (trainer:330) INFO: 28epoch results: [train] iter_time=1.791e-04, forward_time=0.114, loss_ctc=27.478, loss_att=12.276, acc=0.901, loss=16.836, backward_time=0.107, optim_step_time=0.091, optim0_lr0=5.101e-05, train_time=0.517, time=3 hours, 12 minutes and 55.14 seconds, total_count=626192, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.340, cer_ctc=0.117, loss_att=7.756, acc=0.947, cer=0.070, wer=0.207, loss=11.232, time=10 minutes and 45.14 seconds, total_count=79744, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 13.03 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-25 10:31:04,197 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-25 10:31:04,211 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/18epoch.pth
[seoultech:0/4] 2024-01-25 10:31:04,211 (trainer:264) INFO: 29/35epoch started. Estimated time to finish: 17 hours, 16 minutes and 28.76 seconds
[seoultech:0/4] 2024-01-25 10:40:29,816 (trainer:710) INFO: 29epoch:train:1-1118batch: iter_time=4.822e-04, forward_time=0.101, loss_ctc=27.197, loss_att=12.197, acc=0.904, loss=16.697, backward_time=0.096, optim_step_time=0.069, optim0_lr0=5.053e-05, train_time=0.505
[seoultech:0/4] 2024-01-25 10:50:08,117 (trainer:710) INFO: 29epoch:train:1119-2236batch: iter_time=1.098e-04, forward_time=0.111, loss_ctc=27.227, loss_att=12.194, acc=0.900, loss=16.704, backward_time=0.094, optim_step_time=0.053, optim0_lr0=5.048e-05, train_time=0.517
[seoultech:0/4] 2024-01-25 11:00:02,521 (trainer:710) INFO: 29epoch:train:2237-3354batch: iter_time=1.169e-04, forward_time=0.116, loss_ctc=26.803, loss_att=11.908, acc=0.900, loss=16.377, backward_time=0.095, optim_step_time=0.073, optim0_lr0=5.044e-05, train_time=0.531
[seoultech:0/4] 2024-01-25 11:10:01,019 (trainer:710) INFO: 29epoch:train:3355-4472batch: iter_time=1.295e-04, forward_time=0.085, loss_ctc=27.177, loss_att=12.240, acc=0.900, loss=16.721, backward_time=0.166, optim_step_time=0.077, optim0_lr0=5.039e-05, train_time=0.535
[seoultech:0/4] 2024-01-25 11:19:36,857 (trainer:710) INFO: 29epoch:train:4473-5590batch: iter_time=2.120e-04, forward_time=0.127, loss_ctc=27.100, loss_att=12.158, acc=0.902, loss=16.641, backward_time=0.096, optim_step_time=0.114, optim0_lr0=5.035e-05, train_time=0.514
[seoultech:0/4] 2024-01-25 11:29:02,481 (trainer:710) INFO: 29epoch:train:5591-6708batch: iter_time=1.887e-04, forward_time=0.118, loss_ctc=26.828, loss_att=12.048, acc=0.901, loss=16.482, backward_time=0.098, optim_step_time=0.100, optim0_lr0=5.030e-05, train_time=0.505
[seoultech:0/4] 2024-01-25 11:39:01,909 (trainer:710) INFO: 29epoch:train:6709-7826batch: iter_time=1.217e-04, forward_time=0.079, loss_ctc=27.745, loss_att=12.417, acc=0.904, loss=17.015, backward_time=0.160, optim_step_time=0.072, optim0_lr0=5.026e-05, train_time=0.536
[seoultech:0/4] 2024-01-25 11:48:47,327 (trainer:710) INFO: 29epoch:train:7827-8944batch: iter_time=1.599e-04, forward_time=0.091, loss_ctc=27.315, loss_att=12.240, acc=0.904, loss=16.763, backward_time=0.158, optim_step_time=0.084, optim0_lr0=5.021e-05, train_time=0.523
[seoultech:0/4] 2024-01-25 11:58:24,524 (trainer:710) INFO: 29epoch:train:8945-10062batch: iter_time=2.291e-04, forward_time=0.124, loss_ctc=26.410, loss_att=11.833, acc=0.897, loss=16.206, backward_time=0.111, optim_step_time=0.105, optim0_lr0=5.017e-05, train_time=0.516
[seoultech:0/4] 2024-01-25 12:08:32,954 (trainer:710) INFO: 29epoch:train:10063-11180batch: iter_time=2.098e-04, forward_time=0.130, loss_ctc=27.682, loss_att=12.376, acc=0.906, loss=16.968, backward_time=0.106, optim_step_time=0.107, optim0_lr0=5.012e-05, train_time=0.543
[seoultech:0/4] 2024-01-25 12:18:53,992 (trainer:710) INFO: 29epoch:train:11181-12298batch: iter_time=2.131e-04, forward_time=0.133, loss_ctc=27.733, loss_att=12.350, acc=0.903, loss=16.965, backward_time=0.099, optim_step_time=0.111, optim0_lr0=5.008e-05, train_time=0.555
[seoultech:0/4] 2024-01-25 12:28:50,869 (trainer:710) INFO: 29epoch:train:12299-13416batch: iter_time=1.510e-04, forward_time=0.123, loss_ctc=26.792, loss_att=11.969, acc=0.899, loss=16.416, backward_time=0.099, optim_step_time=0.076, optim0_lr0=5.004e-05, train_time=0.533
[seoultech:0/4] 2024-01-25 12:38:35,058 (trainer:710) INFO: 29epoch:train:13417-14534batch: iter_time=2.290e-04, forward_time=0.129, loss_ctc=27.242, loss_att=12.168, acc=0.905, loss=16.690, backward_time=0.102, optim_step_time=0.117, optim0_lr0=4.999e-05, train_time=0.522
[seoultech:0/4] 2024-01-25 12:48:31,182 (trainer:710) INFO: 29epoch:train:14535-15652batch: iter_time=2.207e-04, forward_time=0.127, loss_ctc=27.283, loss_att=12.148, acc=0.902, loss=16.689, backward_time=0.096, optim_step_time=0.116, optim0_lr0=4.995e-05, train_time=0.532
[seoultech:0/4] 2024-01-25 12:58:34,492 (trainer:710) INFO: 29epoch:train:15653-16770batch: iter_time=2.053e-04, forward_time=0.128, loss_ctc=27.269, loss_att=12.220, acc=0.902, loss=16.735, backward_time=0.099, optim_step_time=0.111, optim0_lr0=4.991e-05, train_time=0.539
[seoultech:0/4] 2024-01-25 13:08:25,133 (trainer:710) INFO: 29epoch:train:16771-17888batch: iter_time=2.031e-04, forward_time=0.128, loss_ctc=27.604, loss_att=12.389, acc=0.904, loss=16.954, backward_time=0.097, optim_step_time=0.106, optim0_lr0=4.986e-05, train_time=0.528
[seoultech:0/4] 2024-01-25 13:17:47,423 (trainer:710) INFO: 29epoch:train:17889-19006batch: iter_time=1.595e-04, forward_time=0.118, loss_ctc=27.098, loss_att=12.150, acc=0.899, loss=16.634, backward_time=0.093, optim_step_time=0.083, optim0_lr0=4.982e-05, train_time=0.502
[seoultech:0/4] 2024-01-25 13:27:15,143 (trainer:710) INFO: 29epoch:train:19007-20124batch: iter_time=1.414e-04, forward_time=0.114, loss_ctc=27.372, loss_att=12.214, acc=0.900, loss=16.761, backward_time=0.092, optim_step_time=0.069, optim0_lr0=4.978e-05, train_time=0.507
[seoultech:0/4] 2024-01-25 13:37:01,417 (trainer:710) INFO: 29epoch:train:20125-21242batch: iter_time=1.884e-04, forward_time=0.124, loss_ctc=27.662, loss_att=12.391, acc=0.904, loss=16.972, backward_time=0.093, optim_step_time=0.097, optim0_lr0=4.973e-05, train_time=0.524
[seoultech:0/4] 2024-01-25 13:46:37,176 (trainer:710) INFO: 29epoch:train:21243-22360batch: iter_time=1.614e-04, forward_time=0.112, loss_ctc=27.436, loss_att=12.197, acc=0.903, loss=16.769, backward_time=0.096, optim_step_time=0.089, optim0_lr0=4.969e-05, train_time=0.515
[seoultech:0/4] 2024-01-25 13:59:06,504 (trainer:330) INFO: 29epoch results: [train] iter_time=1.916e-04, forward_time=0.116, loss_ctc=27.244, loss_att=12.188, acc=0.902, loss=16.705, backward_time=0.107, optim_step_time=0.091, optim0_lr0=5.010e-05, train_time=0.524, time=3 hours, 15 minutes and 37.27 seconds, total_count=648556, gpu_max_cached_mem_GB=15.113, [valid] loss_ctc=19.304, cer_ctc=0.117, loss_att=7.717, acc=0.948, cer=0.070, wer=0.206, loss=11.193, time=11 minutes and 2.92 seconds, total_count=82592, gpu_max_cached_mem_GB=15.113, [att_plot] time=1 minute and 22.1 seconds, total_count=0, gpu_max_cached_mem_GB=15.113
[seoultech:0/4] 2024-01-25 13:59:15,659 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-25 13:59:15,673 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/19epoch.pth
[seoultech:0/4] 2024-01-25 13:59:15,673 (trainer:264) INFO: 30/35epoch started. Estimated time to finish: 15 hours and 51 seconds
[seoultech:0/4] 2024-01-25 14:09:40,868 (trainer:710) INFO: 30epoch:train:1-1118batch: iter_time=3.452e-04, forward_time=0.124, loss_ctc=25.822, loss_att=11.599, acc=0.898, loss=15.866, backward_time=0.093, optim_step_time=0.083, optim0_lr0=4.965e-05, train_time=0.559
[seoultech:0/4] 2024-01-25 14:19:57,654 (trainer:710) INFO: 30epoch:train:1119-2236batch: iter_time=2.251e-04, forward_time=0.132, loss_ctc=27.556, loss_att=12.411, acc=0.909, loss=16.955, backward_time=0.118, optim_step_time=0.117, optim0_lr0=4.960e-05, train_time=0.551
[seoultech:0/4] 2024-01-25 14:29:55,177 (trainer:710) INFO: 30epoch:train:2237-3354batch: iter_time=1.322e-04, forward_time=0.094, loss_ctc=26.362, loss_att=11.801, acc=0.899, loss=16.169, backward_time=0.154, optim_step_time=0.079, optim0_lr0=4.956e-05, train_time=0.534
[seoultech:0/4] 2024-01-25 14:39:45,044 (trainer:710) INFO: 30epoch:train:3355-4472batch: iter_time=2.041e-04, forward_time=0.124, loss_ctc=27.081, loss_att=12.114, acc=0.904, loss=16.604, backward_time=0.140, optim_step_time=0.109, optim0_lr0=4.952e-05, train_time=0.527
[seoultech:0/4] 2024-01-25 14:49:23,134 (trainer:710) INFO: 30epoch:train:4473-5590batch: iter_time=2.247e-04, forward_time=0.129, loss_ctc=26.917, loss_att=12.101, acc=0.902, loss=16.546, backward_time=0.108, optim_step_time=0.117, optim0_lr0=4.948e-05, train_time=0.516
[seoultech:0/4] 2024-01-25 14:59:23,488 (trainer:710) INFO: 30epoch:train:5591-6708batch: iter_time=2.244e-04, forward_time=0.130, loss_ctc=27.232, loss_att=12.265, acc=0.906, loss=16.755, backward_time=0.100, optim_step_time=0.116, optim0_lr0=4.944e-05, train_time=0.536
[seoultech:0/4] 2024-01-25 15:08:47,213 (trainer:710) INFO: 30epoch:train:6709-7826batch: iter_time=2.229e-04, forward_time=0.129, loss_ctc=27.268, loss_att=12.281, acc=0.905, loss=16.777, backward_time=0.096, optim_step_time=0.115, optim0_lr0=4.939e-05, train_time=0.503
[seoultech:0/4] 2024-01-25 15:19:04,091 (trainer:710) INFO: 30epoch:train:7827-8944batch: iter_time=2.256e-04, forward_time=0.133, loss_ctc=27.185, loss_att=12.171, acc=0.904, loss=16.675, backward_time=0.097, optim_step_time=0.117, optim0_lr0=4.935e-05, train_time=0.551
[seoultech:0/4] 2024-01-25 15:29:08,979 (trainer:710) INFO: 30epoch:train:8945-10062batch: iter_time=1.351e-04, forward_time=0.121, loss_ctc=27.301, loss_att=12.188, acc=0.904, loss=16.722, backward_time=0.096, optim_step_time=0.067, optim0_lr0=4.931e-05, train_time=0.541
[seoultech:0/4] 2024-01-25 15:39:12,220 (trainer:710) INFO: 30epoch:train:10063-11180batch: iter_time=1.119e-04, forward_time=0.114, loss_ctc=27.397, loss_att=12.242, acc=0.905, loss=16.789, backward_time=0.096, optim_step_time=0.058, optim0_lr0=4.927e-05, train_time=0.539
[seoultech:0/4] 2024-01-25 15:49:29,643 (trainer:710) INFO: 30epoch:train:11181-12298batch: iter_time=1.804e-04, forward_time=0.130, loss_ctc=26.980, loss_att=12.062, acc=0.903, loss=16.537, backward_time=0.099, optim_step_time=0.092, optim0_lr0=4.923e-05, train_time=0.552
[seoultech:0/4] 2024-01-25 15:58:58,206 (trainer:710) INFO: 30epoch:train:12299-13416batch: iter_time=2.025e-04, forward_time=0.126, loss_ctc=27.078, loss_att=12.142, acc=0.901, loss=16.623, backward_time=0.110, optim_step_time=0.106, optim0_lr0=4.918e-05, train_time=0.508
[seoultech:0/4] 2024-01-25 16:09:21,111 (trainer:710) INFO: 30epoch:train:13417-14534batch: iter_time=1.387e-04, forward_time=0.080, loss_ctc=26.850, loss_att=12.017, acc=0.897, loss=16.467, backward_time=0.182, optim_step_time=0.079, optim0_lr0=4.914e-05, train_time=0.557
[seoultech:0/4] 2024-01-25 16:19:24,928 (trainer:710) INFO: 30epoch:train:14535-15652batch: iter_time=1.288e-04, forward_time=0.077, loss_ctc=26.390, loss_att=11.805, acc=0.899, loss=16.181, backward_time=0.172, optim_step_time=0.074, optim0_lr0=4.910e-05, train_time=0.540
[seoultech:0/4] 2024-01-25 16:28:52,737 (trainer:710) INFO: 30epoch:train:15653-16770batch: iter_time=1.156e-04, forward_time=0.085, loss_ctc=26.917, loss_att=12.103, acc=0.900, loss=16.547, backward_time=0.129, optim_step_time=0.070, optim0_lr0=4.906e-05, train_time=0.508
[seoultech:0/4] 2024-01-25 16:38:06,552 (trainer:710) INFO: 30epoch:train:16771-17888batch: iter_time=1.704e-04, forward_time=0.107, loss_ctc=26.938, loss_att=12.098, acc=0.900, loss=16.550, backward_time=0.122, optim_step_time=0.094, optim0_lr0=4.902e-05, train_time=0.495
[seoultech:0/4] 2024-01-25 16:48:06,101 (trainer:710) INFO: 30epoch:train:17889-19006batch: iter_time=1.213e-04, forward_time=0.097, loss_ctc=27.489, loss_att=12.323, acc=0.907, loss=16.872, backward_time=0.136, optim_step_time=0.068, optim0_lr0=4.898e-05, train_time=0.536
[seoultech:0/4] 2024-01-25 16:57:59,643 (trainer:710) INFO: 30epoch:train:19007-20124batch: iter_time=1.722e-04, forward_time=0.126, loss_ctc=27.261, loss_att=12.142, acc=0.900, loss=16.678, backward_time=0.100, optim_step_time=0.092, optim0_lr0=4.894e-05, train_time=0.530
[seoultech:0/4] 2024-01-25 17:08:19,379 (trainer:710) INFO: 30epoch:train:20125-21242batch: iter_time=2.048e-04, forward_time=0.124, loss_ctc=27.368, loss_att=12.218, acc=0.904, loss=16.763, backward_time=0.169, optim_step_time=0.110, optim0_lr0=4.890e-05, train_time=0.554
[seoultech:0/4] 2024-01-25 17:18:34,598 (trainer:710) INFO: 30epoch:train:21243-22360batch: iter_time=2.039e-04, forward_time=0.116, loss_ctc=27.645, loss_att=12.307, acc=0.902, loss=16.909, backward_time=0.176, optim_step_time=0.112, optim0_lr0=4.885e-05, train_time=0.550
[seoultech:0/4] 2024-01-25 17:30:53,612 (trainer:330) INFO: 30epoch results: [train] iter_time=1.845e-04, forward_time=0.115, loss_ctc=27.043, loss_att=12.116, acc=0.902, loss=16.594, backward_time=0.125, optim_step_time=0.094, optim0_lr0=4.925e-05, train_time=0.534, time=3 hours, 19 minutes and 23.1 seconds, total_count=670920, gpu_max_cached_mem_GB=15.115, [valid] loss_ctc=19.619, cer_ctc=0.119, loss_att=7.739, acc=0.948, cer=0.070, wer=0.206, loss=11.303, time=10 minutes and 43.38 seconds, total_count=85440, gpu_max_cached_mem_GB=15.115, [att_plot] time=1 minute and 31.45 seconds, total_count=0, gpu_max_cached_mem_GB=15.115
[seoultech:0/4] 2024-01-25 17:31:03,954 (trainer:376) INFO: There are no improvements in this epoch
[seoultech:0/4] 2024-01-25 17:31:03,966 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/20epoch.pth
[seoultech:0/4] 2024-01-25 17:31:03,967 (trainer:264) INFO: 31/35epoch started. Estimated time to finish: 12 hours, 40 minutes and 59.13 seconds
[seoultech:0/4] 2024-01-25 17:41:34,793 (trainer:710) INFO: 31epoch:train:1-1118batch: iter_time=4.211e-04, forward_time=0.135, loss_ctc=26.147, loss_att=11.734, acc=0.899, loss=16.058, backward_time=0.178, optim_step_time=0.119, optim0_lr0=4.881e-05, train_time=0.563
[seoultech:0/4] 2024-01-25 17:51:58,834 (trainer:710) INFO: 31epoch:train:1119-2236batch: iter_time=2.177e-04, forward_time=0.128, loss_ctc=26.538, loss_att=11.859, acc=0.902, loss=16.263, backward_time=0.181, optim_step_time=0.118, optim0_lr0=4.877e-05, train_time=0.557
[seoultech:0/4] 2024-01-25 18:01:21,243 (trainer:710) INFO: 31epoch:train:2237-3354batch: iter_time=1.504e-04, forward_time=0.102, loss_ctc=26.374, loss_att=11.791, acc=0.902, loss=16.166, backward_time=0.132, optim_step_time=0.097, optim0_lr0=4.873e-05, train_time=0.503
[seoultech:0/4] 2024-01-25 18:11:42,729 (trainer:710) INFO: 31epoch:train:3355-4472batch: iter_time=2.214e-04, forward_time=0.126, loss_ctc=26.915, loss_att=12.037, acc=0.904, loss=16.500, backward_time=0.181, optim_step_time=0.117, optim0_lr0=4.869e-05, train_time=0.555
[seoultech:0/4] 2024-01-25 18:22:01,178 (trainer:710) INFO: 31epoch:train:4473-5590batch: iter_time=1.683e-04, forward_time=0.096, loss_ctc=27.323, loss_att=12.269, acc=0.906, loss=16.785, backward_time=0.181, optim_step_time=0.104, optim0_lr0=4.865e-05, train_time=0.553
[seoultech:0/4] 2024-01-25 18:32:10,388 (trainer:710) INFO: 31epoch:train:5591-6708batch: iter_time=1.740e-04, forward_time=0.125, loss_ctc=26.527, loss_att=11.931, acc=0.902, loss=16.310, backward_time=0.117, optim_step_time=0.103, optim0_lr0=4.861e-05, train_time=0.544
[seoultech:0/4] 2024-01-25 18:42:06,862 (trainer:710) INFO: 31epoch:train:6709-7826batch: iter_time=2.137e-04, forward_time=0.130, loss_ctc=26.843, loss_att=12.086, acc=0.900, loss=16.513, backward_time=0.097, optim_step_time=0.114, optim0_lr0=4.857e-05, train_time=0.533
[seoultech:0/4] 2024-01-25 18:51:45,051 (trainer:710) INFO: 31epoch:train:7827-8944batch: iter_time=2.161e-04, forward_time=0.127, loss_ctc=27.406, loss_att=12.369, acc=0.908, loss=16.880, backward_time=0.094, optim_step_time=0.115, optim0_lr0=4.853e-05, train_time=0.516
[seoultech:0/4] 2024-01-25 19:01:33,954 (trainer:710) INFO: 31epoch:train:8945-10062batch: iter_time=2.098e-04, forward_time=0.126, loss_ctc=26.765, loss_att=12.002, acc=0.903, loss=16.431, backward_time=0.147, optim_step_time=0.116, optim0_lr0=4.849e-05, train_time=0.526
[seoultech:0/4] 2024-01-25 19:11:48,851 (trainer:710) INFO: 31epoch:train:10063-11180batch: iter_time=2.256e-04, forward_time=0.128, loss_ctc=26.673, loss_att=11.955, acc=0.905, loss=16.370, backward_time=0.177, optim_step_time=0.118, optim0_lr0=4.845e-05, train_time=0.549
[seoultech:0/4] 2024-01-25 19:21:13,331 (trainer:710) INFO: 31epoch:train:11181-12298batch: iter_time=1.700e-04, forward_time=0.111, loss_ctc=26.969, loss_att=12.084, acc=0.901, loss=16.550, backward_time=0.112, optim_step_time=0.097, optim0_lr0=4.841e-05, train_time=0.504
[seoultech:0/4] 2024-01-25 19:30:15,877 (trainer:710) INFO: 31epoch:train:12299-13416batch: iter_time=1.582e-04, forward_time=0.102, loss_ctc=26.633, loss_att=11.946, acc=0.903, loss=16.352, backward_time=0.106, optim_step_time=0.086, optim0_lr0=4.837e-05, train_time=0.485
[seoultech:0/4] 2024-01-25 19:40:09,660 (trainer:710) INFO: 31epoch:train:13417-14534batch: iter_time=1.402e-04, forward_time=0.115, loss_ctc=26.508, loss_att=11.921, acc=0.902, loss=16.297, backward_time=0.096, optim_step_time=0.075, optim0_lr0=4.833e-05, train_time=0.531
[seoultech:0/4] 2024-01-25 19:49:35,371 (trainer:710) INFO: 31epoch:train:14535-15652batch: iter_time=2.080e-04, forward_time=0.125, loss_ctc=26.914, loss_att=12.043, acc=0.903, loss=16.505, backward_time=0.095, optim_step_time=0.109, optim0_lr0=4.829e-05, train_time=0.505
[seoultech:0/4] 2024-01-25 19:59:43,762 (trainer:710) INFO: 31epoch:train:15653-16770batch: iter_time=1.461e-04, forward_time=0.120, loss_ctc=26.591, loss_att=11.908, acc=0.902, loss=16.313, backward_time=0.103, optim_step_time=0.080, optim0_lr0=4.825e-05, train_time=0.544
[seoultech:0/4] 2024-01-25 20:08:55,448 (trainer:710) INFO: 31epoch:train:16771-17888batch: iter_time=1.574e-04, forward_time=0.107, loss_ctc=27.028, loss_att=12.070, acc=0.903, loss=16.557, backward_time=0.103, optim_step_time=0.089, optim0_lr0=4.822e-05, train_time=0.493
[seoultech:0/4] 2024-01-25 20:17:51,063 (trainer:710) INFO: 31epoch:train:17889-19006batch: iter_time=1.406e-04, forward_time=0.101, loss_ctc=26.527, loss_att=11.920, acc=0.901, loss=16.302, backward_time=0.098, optim_step_time=0.078, optim0_lr0=4.818e-05, train_time=0.479
[seoultech:0/4] 2024-01-25 20:26:36,707 (trainer:710) INFO: 31epoch:train:19007-20124batch: iter_time=1.128e-04, forward_time=0.098, loss_ctc=27.533, loss_att=12.316, acc=0.906, loss=16.881, backward_time=0.100, optim_step_time=0.062, optim0_lr0=4.814e-05, train_time=0.470
[seoultech:0/4] 2024-01-25 20:35:58,899 (trainer:710) INFO: 31epoch:train:20125-21242batch: iter_time=1.592e-04, forward_time=0.099, loss_ctc=27.249, loss_att=12.223, acc=0.902, loss=16.731, backward_time=0.131, optim_step_time=0.088, optim0_lr0=4.810e-05, train_time=0.502
[seoultech:0/4] 2024-01-25 20:45:32,694 (trainer:710) INFO: 31epoch:train:21243-22360batch: iter_time=1.865e-04, forward_time=0.109, loss_ctc=27.519, loss_att=12.337, acc=0.904, loss=16.891, backward_time=0.127, optim_step_time=0.102, optim0_lr0=4.806e-05, train_time=0.513
[seoultech:0/4] 2024-01-25 20:58:04,231 (trainer:330) INFO: 31epoch results: [train] iter_time=1.899e-04, forward_time=0.116, loss_ctc=26.841, loss_att=12.036, acc=0.903, loss=16.478, backward_time=0.128, optim_step_time=0.099, optim0_lr0=4.843e-05, train_time=0.521, time=3 hours, 14 minutes and 33.14 seconds, total_count=693284, gpu_max_cached_mem_GB=15.115, [valid] loss_ctc=19.532, cer_ctc=0.116, loss_att=7.768, acc=0.948, cer=0.070, wer=0.206, loss=11.297, time=10 minutes and 52.81 seconds, total_count=88288, gpu_max_cached_mem_GB=15.115, [att_plot] time=1 minute and 34.31 seconds, total_count=0, gpu_max_cached_mem_GB=15.115
[seoultech:0/4] 2024-01-25 20:58:13,916 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-25 20:58:13,926 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/21epoch.pth
[seoultech:0/4] 2024-01-25 20:58:13,927 (trainer:264) INFO: 32/35epoch started. Estimated time to finish: 10 hours, 15 minutes and 52.87 seconds
[seoultech:0/4] 2024-01-25 21:07:55,092 (trainer:710) INFO: 32epoch:train:1-1118batch: iter_time=3.624e-04, forward_time=0.127, loss_ctc=26.802, loss_att=12.065, acc=0.906, loss=16.486, backward_time=0.097, optim_step_time=0.099, optim0_lr0=4.802e-05, train_time=0.519
[seoultech:0/4] 2024-01-25 21:17:29,003 (trainer:710) INFO: 32epoch:train:1119-2236batch: iter_time=1.728e-04, forward_time=0.123, loss_ctc=26.283, loss_att=11.768, acc=0.903, loss=16.123, backward_time=0.095, optim_step_time=0.094, optim0_lr0=4.798e-05, train_time=0.513
[seoultech:0/4] 2024-01-25 21:27:39,364 (trainer:710) INFO: 32epoch:train:2237-3354batch: iter_time=1.884e-04, forward_time=0.129, loss_ctc=26.385, loss_att=11.846, acc=0.903, loss=16.208, backward_time=0.096, optim_step_time=0.096, optim0_lr0=4.794e-05, train_time=0.545
[seoultech:0/4] 2024-01-25 21:37:52,930 (trainer:710) INFO: 32epoch:train:3355-4472batch: iter_time=1.725e-04, forward_time=0.127, loss_ctc=27.023, loss_att=12.137, acc=0.904, loss=16.603, backward_time=0.097, optim_step_time=0.092, optim0_lr0=4.791e-05, train_time=0.548
[seoultech:0/4] 2024-01-25 21:47:32,981 (trainer:710) INFO: 32epoch:train:4473-5590batch: iter_time=1.523e-04, forward_time=0.114, loss_ctc=26.526, loss_att=11.899, acc=0.906, loss=16.287, backward_time=0.098, optim_step_time=0.081, optim0_lr0=4.787e-05, train_time=0.518
[seoultech:0/4] 2024-01-25 21:56:50,808 (trainer:710) INFO: 32epoch:train:5591-6708batch: iter_time=1.130e-04, forward_time=0.101, loss_ctc=26.520, loss_att=11.881, acc=0.902, loss=16.272, backward_time=0.100, optim_step_time=0.059, optim0_lr0=4.783e-05, train_time=0.499
[seoultech:0/4] 2024-01-25 22:05:41,490 (trainer:710) INFO: 32epoch:train:6709-7826batch: iter_time=1.121e-04, forward_time=0.100, loss_ctc=26.405, loss_att=11.884, acc=0.904, loss=16.240, backward_time=0.100, optim_step_time=0.058, optim0_lr0=4.779e-05, train_time=0.474
[seoultech:0/4] 2024-01-25 22:14:41,827 (trainer:710) INFO: 32epoch:train:7827-8944batch: iter_time=1.134e-04, forward_time=0.098, loss_ctc=26.608, loss_att=11.985, acc=0.905, loss=16.372, backward_time=0.099, optim_step_time=0.054, optim0_lr0=4.775e-05, train_time=0.483
[seoultech:0/4] 2024-01-25 22:24:03,534 (trainer:710) INFO: 32epoch:train:8945-10062batch: iter_time=1.115e-04, forward_time=0.112, loss_ctc=26.266, loss_att=11.759, acc=0.901, loss=16.111, backward_time=0.096, optim_step_time=0.053, optim0_lr0=4.771e-05, train_time=0.502
[seoultech:0/4] 2024-01-25 22:33:56,188 (trainer:710) INFO: 32epoch:train:10063-11180batch: iter_time=1.153e-04, forward_time=0.117, loss_ctc=26.937, loss_att=12.028, acc=0.901, loss=16.501, backward_time=0.100, optim_step_time=0.056, optim0_lr0=4.768e-05, train_time=0.530
[seoultech:0/4] 2024-01-25 22:43:13,105 (trainer:710) INFO: 32epoch:train:11181-12298batch: iter_time=1.346e-04, forward_time=0.107, loss_ctc=26.848, loss_att=12.017, acc=0.905, loss=16.466, backward_time=0.097, optim_step_time=0.072, optim0_lr0=4.764e-05, train_time=0.498
[seoultech:0/4] 2024-01-25 22:52:17,684 (trainer:710) INFO: 32epoch:train:12299-13416batch: iter_time=1.155e-04, forward_time=0.092, loss_ctc=26.869, loss_att=11.987, acc=0.903, loss=16.452, backward_time=0.100, optim_step_time=0.066, optim0_lr0=4.760e-05, train_time=0.487
[seoultech:0/4] 2024-01-25 23:01:42,412 (trainer:710) INFO: 32epoch:train:13417-14534batch: iter_time=1.168e-04, forward_time=0.099, loss_ctc=26.475, loss_att=11.831, acc=0.900, loss=16.224, backward_time=0.100, optim_step_time=0.063, optim0_lr0=4.756e-05, train_time=0.505
[seoultech:0/4] 2024-01-25 23:10:58,556 (trainer:710) INFO: 32epoch:train:14535-15652batch: iter_time=1.179e-04, forward_time=0.093, loss_ctc=26.633, loss_att=11.965, acc=0.902, loss=16.365, backward_time=0.101, optim_step_time=0.066, optim0_lr0=4.753e-05, train_time=0.497
[seoultech:0/4] 2024-01-25 23:20:19,129 (trainer:710) INFO: 32epoch:train:15653-16770batch: iter_time=1.258e-04, forward_time=0.101, loss_ctc=26.608, loss_att=11.993, acc=0.902, loss=16.377, backward_time=0.100, optim_step_time=0.070, optim0_lr0=4.749e-05, train_time=0.501
[seoultech:0/4] 2024-01-25 23:30:05,534 (trainer:710) INFO: 32epoch:train:16771-17888batch: iter_time=2.263e-04, forward_time=0.133, loss_ctc=26.530, loss_att=11.895, acc=0.905, loss=16.286, backward_time=0.099, optim_step_time=0.117, optim0_lr0=4.745e-05, train_time=0.524
[seoultech:0/4] 2024-01-25 23:39:39,039 (trainer:710) INFO: 32epoch:train:17889-19006batch: iter_time=1.709e-04, forward_time=0.113, loss_ctc=26.532, loss_att=11.902, acc=0.903, loss=16.291, backward_time=0.097, optim_step_time=0.091, optim0_lr0=4.741e-05, train_time=0.512
[seoultech:0/4] 2024-01-25 23:48:29,991 (trainer:710) INFO: 32epoch:train:19007-20124batch: iter_time=1.142e-04, forward_time=0.087, loss_ctc=26.832, loss_att=12.055, acc=0.902, loss=16.488, backward_time=0.095, optim_step_time=0.066, optim0_lr0=4.738e-05, train_time=0.475
[seoultech:0/4] 2024-01-25 23:58:25,729 (trainer:710) INFO: 32epoch:train:20125-21242batch: iter_time=1.657e-04, forward_time=0.121, loss_ctc=27.127, loss_att=12.168, acc=0.904, loss=16.656, backward_time=0.095, optim_step_time=0.087, optim0_lr0=4.734e-05, train_time=0.532
[seoultech:0/4] 2024-01-26 00:08:00,325 (trainer:710) INFO: 32epoch:train:21243-22360batch: iter_time=1.783e-04, forward_time=0.118, loss_ctc=26.945, loss_att=12.083, acc=0.904, loss=16.542, backward_time=0.094, optim_step_time=0.096, optim0_lr0=4.730e-05, train_time=0.513
[seoultech:0/4] 2024-01-26 00:20:07,556 (trainer:330) INFO: 32epoch results: [train] iter_time=1.540e-04, forward_time=0.111, loss_ctc=26.655, loss_att=11.956, acc=0.903, loss=16.366, backward_time=0.098, optim_step_time=0.077, optim0_lr0=4.766e-05, train_time=0.509, time=3 hours, 9 minutes and 50.41 seconds, total_count=715648, gpu_max_cached_mem_GB=15.115, [valid] loss_ctc=19.423, cer_ctc=0.115, loss_att=7.739, acc=0.948, cer=0.070, wer=0.206, loss=11.244, time=10 minutes and 53.22 seconds, total_count=91136, gpu_max_cached_mem_GB=15.115, [att_plot] time=1 minute and 10 seconds, total_count=0, gpu_max_cached_mem_GB=15.115
[seoultech:0/4] 2024-01-26 00:20:15,855 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-26 00:20:15,862 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/22epoch.pth
[seoultech:0/4] 2024-01-26 00:20:15,862 (trainer:264) INFO: 33/35epoch started. Estimated time to finish: 7 hours, 46 minutes and 25 seconds
[seoultech:0/4] 2024-01-26 00:30:31,666 (trainer:710) INFO: 33epoch:train:1-1118batch: iter_time=3.495e-04, forward_time=0.131, loss_ctc=26.009, loss_att=11.708, acc=0.902, loss=15.998, backward_time=0.099, optim_step_time=0.088, optim0_lr0=4.727e-05, train_time=0.550
[seoultech:0/4] 2024-01-26 00:40:40,550 (trainer:710) INFO: 33epoch:train:1119-2236batch: iter_time=1.614e-04, forward_time=0.130, loss_ctc=25.860, loss_att=11.623, acc=0.900, loss=15.894, backward_time=0.103, optim_step_time=0.094, optim0_lr0=4.723e-05, train_time=0.544
[seoultech:0/4] 2024-01-26 00:50:27,610 (trainer:710) INFO: 33epoch:train:2237-3354batch: iter_time=1.428e-04, forward_time=0.119, loss_ctc=26.577, loss_att=11.957, acc=0.905, loss=16.343, backward_time=0.096, optim_step_time=0.075, optim0_lr0=4.719e-05, train_time=0.525
[seoultech:0/4] 2024-01-26 01:00:01,549 (trainer:710) INFO: 33epoch:train:3355-4472batch: iter_time=1.082e-04, forward_time=0.103, loss_ctc=26.185, loss_att=11.751, acc=0.903, loss=16.081, backward_time=0.116, optim_step_time=0.058, optim0_lr0=4.715e-05, train_time=0.513
[seoultech:0/4] 2024-01-26 01:10:29,649 (trainer:710) INFO: 33epoch:train:4473-5590batch: iter_time=1.700e-04, forward_time=0.119, loss_ctc=26.509, loss_att=11.907, acc=0.905, loss=16.288, backward_time=0.138, optim_step_time=0.097, optim0_lr0=4.712e-05, train_time=0.561
[seoultech:0/4] 2024-01-26 01:20:33,751 (trainer:710) INFO: 33epoch:train:5591-6708batch: iter_time=1.867e-04, forward_time=0.121, loss_ctc=25.902, loss_att=11.655, acc=0.902, loss=15.929, backward_time=0.134, optim_step_time=0.107, optim0_lr0=4.708e-05, train_time=0.540
[seoultech:0/4] 2024-01-26 01:30:22,446 (trainer:710) INFO: 33epoch:train:6709-7826batch: iter_time=1.727e-04, forward_time=0.123, loss_ctc=26.376, loss_att=11.868, acc=0.904, loss=16.220, backward_time=0.113, optim_step_time=0.096, optim0_lr0=4.705e-05, train_time=0.526
[seoultech:0/4] 2024-01-26 01:40:04,262 (trainer:710) INFO: 33epoch:train:7827-8944batch: iter_time=2.242e-04, forward_time=0.133, loss_ctc=26.491, loss_att=11.878, acc=0.904, loss=16.262, backward_time=0.108, optim_step_time=0.117, optim0_lr0=4.701e-05, train_time=0.520
[seoultech:0/4] 2024-01-26 01:49:30,724 (trainer:710) INFO: 33epoch:train:8945-10062batch: iter_time=2.216e-04, forward_time=0.129, loss_ctc=26.489, loss_att=11.859, acc=0.904, loss=16.248, backward_time=0.105, optim_step_time=0.117, optim0_lr0=4.697e-05, train_time=0.506
[seoultech:0/4] 2024-01-26 01:59:05,298 (trainer:710) INFO: 33epoch:train:10063-11180batch: iter_time=2.287e-04, forward_time=0.130, loss_ctc=26.298, loss_att=11.803, acc=0.901, loss=16.151, backward_time=0.102, optim_step_time=0.118, optim0_lr0=4.694e-05, train_time=0.513
[seoultech:0/4] 2024-01-26 02:09:28,992 (trainer:710) INFO: 33epoch:train:11181-12298batch: iter_time=2.323e-04, forward_time=0.131, loss_ctc=26.911, loss_att=12.042, acc=0.908, loss=16.503, backward_time=0.104, optim_step_time=0.117, optim0_lr0=4.690e-05, train_time=0.557
[seoultech:0/4] 2024-01-26 02:19:37,112 (trainer:710) INFO: 33epoch:train:12299-13416batch: iter_time=2.366e-04, forward_time=0.125, loss_ctc=26.407, loss_att=11.853, acc=0.902, loss=16.220, backward_time=0.102, optim_step_time=0.111, optim0_lr0=4.686e-05, train_time=0.543
[seoultech:0/4] 2024-01-26 02:29:52,514 (trainer:710) INFO: 33epoch:train:13417-14534batch: iter_time=2.414e-04, forward_time=0.133, loss_ctc=26.432, loss_att=11.847, acc=0.902, loss=16.223, backward_time=0.102, optim_step_time=0.117, optim0_lr0=4.683e-05, train_time=0.550
[seoultech:0/4] 2024-01-26 02:39:55,459 (trainer:710) INFO: 33epoch:train:14535-15652batch: iter_time=2.311e-04, forward_time=0.129, loss_ctc=26.509, loss_att=11.893, acc=0.904, loss=16.277, backward_time=0.102, optim_step_time=0.113, optim0_lr0=4.679e-05, train_time=0.539
[seoultech:0/4] 2024-01-26 02:50:05,222 (trainer:710) INFO: 33epoch:train:15653-16770batch: iter_time=1.850e-04, forward_time=0.125, loss_ctc=26.579, loss_att=11.940, acc=0.904, loss=16.332, backward_time=0.102, optim_step_time=0.096, optim0_lr0=4.676e-05, train_time=0.545
[seoultech:0/4] 2024-01-26 03:00:00,814 (trainer:710) INFO: 33epoch:train:16771-17888batch: iter_time=1.143e-04, forward_time=0.113, loss_ctc=26.670, loss_att=11.942, acc=0.902, loss=16.360, backward_time=0.100, optim_step_time=0.058, optim0_lr0=4.672e-05, train_time=0.532
[seoultech:0/4] 2024-01-26 03:09:36,244 (trainer:710) INFO: 33epoch:train:17889-19006batch: iter_time=1.503e-04, forward_time=0.115, loss_ctc=27.241, loss_att=12.214, acc=0.907, loss=16.722, backward_time=0.102, optim_step_time=0.080, optim0_lr0=4.669e-05, train_time=0.514
[seoultech:0/4] 2024-01-26 03:19:12,977 (trainer:710) INFO: 33epoch:train:19007-20124batch: iter_time=1.273e-04, forward_time=0.113, loss_ctc=26.548, loss_att=11.884, acc=0.903, loss=16.284, backward_time=0.103, optim_step_time=0.065, optim0_lr0=4.665e-05, train_time=0.515
[seoultech:0/4] 2024-01-26 03:28:59,762 (trainer:710) INFO: 33epoch:train:20125-21242batch: iter_time=1.800e-04, forward_time=0.113, loss_ctc=27.140, loss_att=12.140, acc=0.906, loss=16.640, backward_time=0.124, optim_step_time=0.096, optim0_lr0=4.661e-05, train_time=0.524
[seoultech:0/4] 2024-01-26 03:39:00,179 (trainer:710) INFO: 33epoch:train:21243-22360batch: iter_time=1.105e-04, forward_time=0.112, loss_ctc=26.736, loss_att=12.044, acc=0.906, loss=16.452, backward_time=0.109, optim_step_time=0.060, optim0_lr0=4.658e-05, train_time=0.537
[seoultech:0/4] 2024-01-26 03:51:21,201 (trainer:330) INFO: 33epoch results: [train] iter_time=1.887e-04, forward_time=0.122, loss_ctc=26.490, loss_att=11.889, acc=0.904, loss=16.269, backward_time=0.108, optim_step_time=0.094, optim0_lr0=4.692e-05, train_time=0.533, time=3 hours, 18 minutes and 48.66 seconds, total_count=738012, gpu_max_cached_mem_GB=15.115, [valid] loss_ctc=19.756, cer_ctc=0.116, loss_att=7.713, acc=0.948, cer=0.070, wer=0.206, loss=11.326, time=10 minutes and 48.46 seconds, total_count=93984, gpu_max_cached_mem_GB=15.115, [att_plot] time=1 minute and 28.21 seconds, total_count=0, gpu_max_cached_mem_GB=15.115
[seoultech:0/4] 2024-01-26 03:51:30,798 (trainer:376) INFO: There are no improvements in this epoch
[seoultech:0/4] 2024-01-26 03:51:30,808 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/23epoch.pth
[seoultech:0/4] 2024-01-26 03:51:30,809 (trainer:264) INFO: 34/35epoch started. Estimated time to finish: 5 hours, 14 minutes and 19.49 seconds
[seoultech:0/4] 2024-01-26 04:01:45,234 (trainer:710) INFO: 34epoch:train:1-1118batch: iter_time=5.896e-04, forward_time=0.116, loss_ctc=25.987, loss_att=11.709, acc=0.904, loss=15.992, backward_time=0.106, optim_step_time=0.067, optim0_lr0=4.654e-05, train_time=0.549
[seoultech:0/4] 2024-01-26 04:12:04,522 (trainer:710) INFO: 34epoch:train:1119-2236batch: iter_time=1.328e-04, forward_time=0.079, loss_ctc=26.055, loss_att=11.719, acc=0.904, loss=16.020, backward_time=0.170, optim_step_time=0.074, optim0_lr0=4.651e-05, train_time=0.554
[seoultech:0/4] 2024-01-26 04:22:22,074 (trainer:710) INFO: 34epoch:train:2237-3354batch: iter_time=1.250e-04, forward_time=0.099, loss_ctc=26.162, loss_att=11.739, acc=0.904, loss=16.066, backward_time=0.137, optim_step_time=0.068, optim0_lr0=4.647e-05, train_time=0.552
[seoultech:0/4] 2024-01-26 04:32:34,334 (trainer:710) INFO: 34epoch:train:3355-4472batch: iter_time=1.397e-04, forward_time=0.131, loss_ctc=26.104, loss_att=11.866, acc=0.904, loss=16.138, backward_time=0.098, optim_step_time=0.108, optim0_lr0=4.644e-05, train_time=0.547
[seoultech:0/4] 2024-01-26 04:42:18,484 (trainer:710) INFO: 34epoch:train:4473-5590batch: iter_time=1.496e-04, forward_time=0.114, loss_ctc=26.350, loss_att=11.840, acc=0.907, loss=16.193, backward_time=0.099, optim_step_time=0.085, optim0_lr0=4.640e-05, train_time=0.522
[seoultech:0/4] 2024-01-26 04:52:42,159 (trainer:710) INFO: 34epoch:train:5591-6708batch: iter_time=1.440e-04, forward_time=0.130, loss_ctc=26.218, loss_att=11.775, acc=0.904, loss=16.108, backward_time=0.100, optim_step_time=0.083, optim0_lr0=4.637e-05, train_time=0.557
[seoultech:0/4] 2024-01-26 05:03:03,615 (trainer:710) INFO: 34epoch:train:6709-7826batch: iter_time=1.192e-04, forward_time=0.120, loss_ctc=26.430, loss_att=11.943, acc=0.903, loss=16.289, backward_time=0.102, optim_step_time=0.065, optim0_lr0=4.633e-05, train_time=0.556
[seoultech:0/4] 2024-01-26 05:13:11,982 (trainer:710) INFO: 34epoch:train:7827-8944batch: iter_time=1.235e-04, forward_time=0.091, loss_ctc=26.108, loss_att=11.776, acc=0.903, loss=16.076, backward_time=0.145, optim_step_time=0.066, optim0_lr0=4.630e-05, train_time=0.544
[seoultech:0/4] 2024-01-26 05:23:16,579 (trainer:710) INFO: 34epoch:train:8945-10062batch: iter_time=1.249e-04, forward_time=0.075, loss_ctc=26.715, loss_att=12.030, acc=0.907, loss=16.436, backward_time=0.179, optim_step_time=0.088, optim0_lr0=4.626e-05, train_time=0.540
[seoultech:0/4] 2024-01-26 05:33:22,930 (trainer:710) INFO: 34epoch:train:10063-11180batch: iter_time=1.235e-04, forward_time=0.108, loss_ctc=25.542, loss_att=11.478, acc=0.900, loss=15.697, backward_time=0.121, optim_step_time=0.079, optim0_lr0=4.623e-05, train_time=0.542
[seoultech:0/4] 2024-01-26 05:43:38,790 (trainer:710) INFO: 34epoch:train:11181-12298batch: iter_time=1.255e-04, forward_time=0.080, loss_ctc=26.773, loss_att=12.082, acc=0.908, loss=16.489, backward_time=0.180, optim_step_time=0.096, optim0_lr0=4.620e-05, train_time=0.551
[seoultech:0/4] 2024-01-26 05:53:18,288 (trainer:710) INFO: 34epoch:train:12299-13416batch: iter_time=1.211e-04, forward_time=0.077, loss_ctc=26.745, loss_att=11.994, acc=0.905, loss=16.419, backward_time=0.181, optim_step_time=0.076, optim0_lr0=4.616e-05, train_time=0.518
[seoultech:0/4] 2024-01-26 06:02:43,676 (trainer:710) INFO: 34epoch:train:13417-14534batch: iter_time=1.109e-04, forward_time=0.103, loss_ctc=26.463, loss_att=11.872, acc=0.906, loss=16.249, backward_time=0.118, optim_step_time=0.058, optim0_lr0=4.613e-05, train_time=0.505
[seoultech:0/4] 2024-01-26 06:12:48,449 (trainer:710) INFO: 34epoch:train:14535-15652batch: iter_time=1.259e-04, forward_time=0.074, loss_ctc=26.294, loss_att=11.816, acc=0.904, loss=16.159, backward_time=0.181, optim_step_time=0.075, optim0_lr0=4.609e-05, train_time=0.541
[seoultech:0/4] 2024-01-26 06:22:57,820 (trainer:710) INFO: 34epoch:train:15653-16770batch: iter_time=1.231e-04, forward_time=0.086, loss_ctc=26.510, loss_att=11.835, acc=0.903, loss=16.237, backward_time=0.162, optim_step_time=0.072, optim0_lr0=4.606e-05, train_time=0.545
[seoultech:0/4] 2024-01-26 06:32:40,538 (trainer:710) INFO: 34epoch:train:16771-17888batch: iter_time=1.129e-04, forward_time=0.100, loss_ctc=26.160, loss_att=11.740, acc=0.904, loss=16.066, backward_time=0.109, optim_step_time=0.064, optim0_lr0=4.602e-05, train_time=0.521
[seoultech:0/4] 2024-01-26 06:42:14,250 (trainer:710) INFO: 34epoch:train:17889-19006batch: iter_time=1.123e-04, forward_time=0.103, loss_ctc=26.000, loss_att=11.648, acc=0.902, loss=15.954, backward_time=0.101, optim_step_time=0.059, optim0_lr0=4.599e-05, train_time=0.513
[seoultech:0/4] 2024-01-26 06:51:53,513 (trainer:710) INFO: 34epoch:train:19007-20124batch: iter_time=1.103e-04, forward_time=0.107, loss_ctc=26.427, loss_att=11.919, acc=0.905, loss=16.271, backward_time=0.093, optim_step_time=0.054, optim0_lr0=4.596e-05, train_time=0.518
[seoultech:0/4] 2024-01-26 07:01:00,316 (trainer:710) INFO: 34epoch:train:20125-21242batch: iter_time=1.116e-04, forward_time=0.091, loss_ctc=26.078, loss_att=11.696, acc=0.902, loss=16.011, backward_time=0.100, optim_step_time=0.061, optim0_lr0=4.592e-05, train_time=0.489
[seoultech:0/4] 2024-01-26 07:10:46,390 (trainer:710) INFO: 34epoch:train:21243-22360batch: iter_time=1.988e-04, forward_time=0.119, loss_ctc=26.726, loss_att=12.028, acc=0.906, loss=16.437, backward_time=0.115, optim_step_time=0.108, optim0_lr0=4.589e-05, train_time=0.523
[seoultech:0/4] 2024-01-26 07:23:01,214 (trainer:330) INFO: 34epoch results: [train] iter_time=1.512e-04, forward_time=0.100, loss_ctc=26.288, loss_att=11.823, acc=0.904, loss=16.162, backward_time=0.130, optim_step_time=0.075, optim0_lr0=4.621e-05, train_time=0.534, time=3 hours, 19 minutes and 19.92 seconds, total_count=760376, gpu_max_cached_mem_GB=15.115, [valid] loss_ctc=19.711, cer_ctc=0.115, loss_att=7.664, acc=0.948, cer=0.070, wer=0.205, loss=11.278, time=11 minutes and 4.64 seconds, total_count=96832, gpu_max_cached_mem_GB=15.115, [att_plot] time=1 minute and 5.84 seconds, total_count=0, gpu_max_cached_mem_GB=15.115
[seoultech:0/4] 2024-01-26 07:23:08,704 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-26 07:23:08,714 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/24epoch.pth
[seoultech:0/4] 2024-01-26 07:23:08,715 (trainer:264) INFO: 35/35epoch started. Estimated time to finish: 2 hours, 38 minutes and 45.87 seconds
[seoultech:0/4] 2024-01-26 07:33:31,117 (trainer:710) INFO: 35epoch:train:1-1118batch: iter_time=3.181e-04, forward_time=0.119, loss_ctc=26.146, loss_att=11.771, acc=0.908, loss=16.084, backward_time=0.109, optim_step_time=0.065, optim0_lr0=4.585e-05, train_time=0.556
[seoultech:0/4] 2024-01-26 07:43:43,935 (trainer:710) INFO: 35epoch:train:1119-2236batch: iter_time=1.695e-04, forward_time=0.128, loss_ctc=26.189, loss_att=11.766, acc=0.909, loss=16.093, backward_time=0.097, optim_step_time=0.084, optim0_lr0=4.582e-05, train_time=0.548
[seoultech:0/4] 2024-01-26 07:53:38,340 (trainer:710) INFO: 35epoch:train:2237-3354batch: iter_time=1.369e-04, forward_time=0.113, loss_ctc=25.878, loss_att=11.639, acc=0.904, loss=15.911, backward_time=0.114, optim_step_time=0.068, optim0_lr0=4.579e-05, train_time=0.531
[seoultech:0/4] 2024-01-26 08:03:41,850 (trainer:710) INFO: 35epoch:train:3355-4472batch: iter_time=1.892e-04, forward_time=0.125, loss_ctc=25.569, loss_att=11.502, acc=0.901, loss=15.722, backward_time=0.121, optim_step_time=0.096, optim0_lr0=4.575e-05, train_time=0.539
[seoultech:0/4] 2024-01-26 08:13:36,055 (trainer:710) INFO: 35epoch:train:4473-5590batch: iter_time=1.634e-04, forward_time=0.123, loss_ctc=26.845, loss_att=12.088, acc=0.909, loss=16.515, backward_time=0.112, optim_step_time=0.093, optim0_lr0=4.572e-05, train_time=0.531
[seoultech:0/4] 2024-01-26 08:23:21,253 (trainer:710) INFO: 35epoch:train:5591-6708batch: iter_time=1.272e-04, forward_time=0.119, loss_ctc=26.262, loss_att=11.780, acc=0.908, loss=16.125, backward_time=0.101, optim_step_time=0.086, optim0_lr0=4.569e-05, train_time=0.523
[seoultech:0/4] 2024-01-26 08:33:14,288 (trainer:710) INFO: 35epoch:train:6709-7826batch: iter_time=1.255e-04, forward_time=0.081, loss_ctc=25.764, loss_att=11.658, acc=0.902, loss=15.890, backward_time=0.163, optim_step_time=0.089, optim0_lr0=4.565e-05, train_time=0.530
[seoultech:0/4] 2024-01-26 08:43:20,090 (trainer:710) INFO: 35epoch:train:7827-8944batch: iter_time=1.863e-04, forward_time=0.110, loss_ctc=26.031, loss_att=11.697, acc=0.904, loss=15.998, backward_time=0.177, optim_step_time=0.102, optim0_lr0=4.562e-05, train_time=0.541
[seoultech:0/4] 2024-01-26 08:53:36,169 (trainer:710) INFO: 35epoch:train:8945-10062batch: iter_time=2.406e-04, forward_time=0.131, loss_ctc=25.961, loss_att=11.693, acc=0.907, loss=15.974, backward_time=0.169, optim_step_time=0.118, optim0_lr0=4.559e-05, train_time=0.550
[seoultech:0/4] 2024-01-26 09:03:57,161 (trainer:710) INFO: 35epoch:train:10063-11180batch: iter_time=2.318e-04, forward_time=0.131, loss_ctc=26.082, loss_att=11.766, acc=0.906, loss=16.061, backward_time=0.177, optim_step_time=0.118, optim0_lr0=4.555e-05, train_time=0.555
[seoultech:0/4] 2024-01-26 09:14:21,857 (trainer:710) INFO: 35epoch:train:11181-12298batch: iter_time=2.299e-04, forward_time=0.130, loss_ctc=26.072, loss_att=11.779, acc=0.905, loss=16.067, backward_time=0.179, optim_step_time=0.118, optim0_lr0=4.552e-05, train_time=0.558
[seoultech:0/4] 2024-01-26 09:24:49,436 (trainer:710) INFO: 35epoch:train:12299-13416batch: iter_time=2.200e-04, forward_time=0.129, loss_ctc=25.771, loss_att=11.642, acc=0.901, loss=15.881, backward_time=0.180, optim_step_time=0.118, optim0_lr0=4.549e-05, train_time=0.561
[seoultech:0/4] 2024-01-26 09:34:41,400 (trainer:710) INFO: 35epoch:train:13417-14534batch: iter_time=2.225e-04, forward_time=0.131, loss_ctc=25.645, loss_att=11.544, acc=0.900, loss=15.774, backward_time=0.129, optim_step_time=0.117, optim0_lr0=4.546e-05, train_time=0.529
[seoultech:0/4] 2024-01-26 09:44:18,306 (trainer:710) INFO: 35epoch:train:14535-15652batch: iter_time=1.322e-04, forward_time=0.080, loss_ctc=26.027, loss_att=11.672, acc=0.905, loss=15.978, backward_time=0.170, optim_step_time=0.073, optim0_lr0=4.542e-05, train_time=0.516
[seoultech:0/4] 2024-01-26 09:54:31,414 (trainer:710) INFO: 35epoch:train:15653-16770batch: iter_time=1.954e-04, forward_time=0.111, loss_ctc=26.312, loss_att=11.807, acc=0.905, loss=16.158, backward_time=0.180, optim_step_time=0.107, optim0_lr0=4.539e-05, train_time=0.548
[seoultech:0/4] 2024-01-26 10:04:54,244 (trainer:710) INFO: 35epoch:train:16771-17888batch: iter_time=2.213e-04, forward_time=0.125, loss_ctc=26.897, loss_att=12.071, acc=0.909, loss=16.519, backward_time=0.179, optim_step_time=0.115, optim0_lr0=4.536e-05, train_time=0.556
[seoultech:0/4] 2024-01-26 10:15:26,827 (trainer:710) INFO: 35epoch:train:17889-19006batch: iter_time=2.216e-04, forward_time=0.127, loss_ctc=26.477, loss_att=11.884, acc=0.906, loss=16.262, backward_time=0.179, optim_step_time=0.114, optim0_lr0=4.533e-05, train_time=0.565
[seoultech:0/4] 2024-01-26 10:25:47,028 (trainer:710) INFO: 35epoch:train:19007-20124batch: iter_time=2.585e-04, forward_time=0.128, loss_ctc=25.673, loss_att=11.589, acc=0.901, loss=15.814, backward_time=0.178, optim_step_time=0.117, optim0_lr0=4.529e-05, train_time=0.554
[seoultech:0/4] 2024-01-26 10:36:06,175 (trainer:710) INFO: 35epoch:train:20125-21242batch: iter_time=2.383e-04, forward_time=0.127, loss_ctc=26.219, loss_att=11.793, acc=0.902, loss=16.121, backward_time=0.178, optim_step_time=0.117, optim0_lr0=4.526e-05, train_time=0.553
[seoultech:0/4] 2024-01-26 10:46:22,060 (trainer:710) INFO: 35epoch:train:21243-22360batch: iter_time=2.400e-04, forward_time=0.126, loss_ctc=26.249, loss_att=11.836, acc=0.904, loss=16.160, backward_time=0.177, optim_step_time=0.117, optim0_lr0=4.523e-05, train_time=0.550
[seoultech:0/4] 2024-01-26 10:59:08,127 (trainer:330) INFO: 35epoch results: [train] iter_time=2.034e-04, forward_time=0.120, loss_ctc=26.099, loss_att=11.747, acc=0.905, loss=16.052, backward_time=0.154, optim_step_time=0.102, optim0_lr0=4.554e-05, train_time=0.545, time=3 hours, 23 minutes and 17.58 seconds, total_count=782740, gpu_max_cached_mem_GB=15.115, [valid] loss_ctc=19.797, cer_ctc=0.114, loss_att=7.648, acc=0.948, cer=0.069, wer=0.205, loss=11.292, time=11 minutes and 8.19 seconds, total_count=99680, gpu_max_cached_mem_GB=15.115, [att_plot] time=1 minute and 33.64 seconds, total_count=0, gpu_max_cached_mem_GB=15.115
[seoultech:0/4] 2024-01-26 10:59:16,927 (trainer:378) INFO: The best model has been updated: valid.acc
[seoultech:0/4] 2024-01-26 10:59:16,937 (trainer:432) INFO: The model files were removed: exp/asr_train_asr_conformer_raw_kr_char/25epoch.pth
[seoultech:0/4] 2024-01-26 10:59:16,938 (trainer:450) INFO: The training was finished at 35 epochs 
[seoultech:0/4] 2024-01-26 10:59:16,966 (average_nbest_models:69) INFO: Averaging 10best models: criterion="valid.acc": exp/asr_train_asr_conformer_raw_kr_char/valid.acc.ave_10best.pth
# Accounting: time=336886 threads=1
# Ended (code 0) at Fri Jan 26 10:59:30 KST 2024, elapsed time 336886 seconds
